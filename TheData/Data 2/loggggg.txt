C:\Users\DELL\Anaconda3\python.exe "D:/OneDrive/My Research/Dr_Mosaad/Data 2/program/cnn_regression.py"
2019-10-29 16:11:22.768377: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
[INFO] loading attributes...
[INFO] loading house images...
1.jpg
10.jpg
11.jpg
12.jpg
13.jpg
18.jpg
19.jpg
2.jpg
20.jpg
21.jpg
22.jpg
23.jpg
24.jpg
25.jpg
26.jpg
3.jpg
4.jpg
5.jpg
6.jpg
---------------- Train Y  --------------------
    distance        C2        Cm        RL
6       0.00  0.718310  0.708511  0.177836
2       0.50  0.718310  0.708511  0.249850
10      0.50  0.859155  0.708511  0.177836
13      0.50  0.000000  0.708511  0.177836
8       0.75  0.718310  0.708511  0.177836
14      0.50  0.718310  0.806383  0.177836
16      0.50  0.718310  0.468085  0.177836
18      0.50  0.718310  1.000000  0.177836
12      0.50  0.295775  0.708511  0.177836
11      0.50  1.000000  0.708511  0.177836
1       0.50  0.718310  0.708511  0.083817
0       0.50  0.718310  0.708511  0.177836
15      0.50  0.718310  0.853191  0.177836
4       0.50  0.718310  0.708511  0.000000
9       1.00  0.718310  0.708511  0.177836
---------------- Test Y  --------------------
    distance       C2        Cm        RL
3       0.50  0.71831  0.708511  1.000000
7       0.25  0.71831  0.708511  0.177836
17      0.50  0.71831  0.000000  0.177836
5       0.50  0.71831  0.708511  0.177836
##############################################
   Model8_filters_1_dense_0_denseSize_16_Dropout_0_20191029-161127
##############################################
2019-10-29 16:11:27.503381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2019-10-29 16:11:28.323199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.493
pciBusID: 0000:01:00.0
2019-10-29 16:11:28.323528: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-10-29 16:11:28.324355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-29 16:11:28.324768: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-10-29 16:11:28.326244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.493
pciBusID: 0000:01:00.0
2019-10-29 16:11:28.326567: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-10-29 16:11:28.327386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-29 16:11:29.176479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-29 16:11:29.176704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-10-29 16:11:29.176842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-10-29 16:11:29.177725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3003 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d (Conv2D)              (None, 567, 756, 16)      448       
_________________________________________________________________
activation (Activation)      (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization (BatchNo (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 283, 378, 16)      0         
_________________________________________________________________
flatten (Flatten)            (None, 1711584)           0         
_________________________________________________________________
dense (Dense)                (None, 4)                 6846340   
=================================================================
Total params: 6,846,852
Trainable params: 6,846,820
Non-trainable params: 32
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/300
2019-10-29 16:11:30.338002: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2019-10-29 16:11:30.768541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2019-10-29 16:11:32.106770: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Internal: Invoking ptxas not supported on Windows
Relying on driver to perform ptx compilation. This message will be only logged once.
2019-10-29 16:11:32.848023: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 16:11:32.850508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cupti64_100.dll
2019-10-29 16:11:33.766883: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 1597 kernel records, 22 memcpy records.

Epoch 00001: val_loss improved from inf to 5100.85547, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0_20191029-161127_best_model.h5
15/15 - 5s - loss: 13412.0661 - val_loss: 5100.8555
Epoch 2/300

Epoch 00002: val_loss did not improve from 5100.85547
15/15 - 0s - loss: 3078.0959 - val_loss: 37405.2812
Epoch 3/300

Epoch 00003: val_loss did not improve from 5100.85547
15/15 - 0s - loss: 13755.5593 - val_loss: 5362.2739
Epoch 4/300

Epoch 00004: val_loss did not improve from 5100.85547
15/15 - 0s - loss: 1579.1597 - val_loss: 11270.3105
Epoch 5/300

Epoch 00005: val_loss did not improve from 5100.85547
15/15 - 0s - loss: 5812.6229 - val_loss: 16806.4414
Epoch 6/300

Epoch 00006: val_loss improved from 5100.85547 to 1432.51575, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0_20191029-161127_best_model.h5
15/15 - 1s - loss: 5134.4542 - val_loss: 1432.5157
Epoch 7/300

Epoch 00007: val_loss did not improve from 1432.51575
15/15 - 0s - loss: 461.8849 - val_loss: 2727.9849
Epoch 8/300

Epoch 00008: val_loss did not improve from 1432.51575
15/15 - 0s - loss: 2914.1803 - val_loss: 4409.4272
Epoch 9/300

Epoch 00009: val_loss improved from 1432.51575 to 463.69455, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0_20191029-161127_best_model.h5
15/15 - 1s - loss: 2628.2573 - val_loss: 463.6945
Epoch 10/300

Epoch 00010: val_loss did not improve from 463.69455
15/15 - 0s - loss: 685.0674 - val_loss: 3133.5938
Epoch 11/300

Epoch 00011: val_loss did not improve from 463.69455
15/15 - 0s - loss: 1285.2329 - val_loss: 5146.8164
Epoch 12/300

Epoch 00012: val_loss did not improve from 463.69455
15/15 - 0s - loss: 1463.0319 - val_loss: 1685.4209
Epoch 13/300

Epoch 00013: val_loss improved from 463.69455 to 53.27345, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0_20191029-161127_best_model.h5
15/15 - 1s - loss: 330.7927 - val_loss: 53.2734
Epoch 14/300

Epoch 00014: val_loss did not improve from 53.27345
15/15 - 0s - loss: 463.6384 - val_loss: 460.0974
Epoch 15/300

Epoch 00015: val_loss did not improve from 53.27345
15/15 - 0s - loss: 791.7875 - val_loss: 160.2190
Epoch 16/300

Epoch 00016: val_loss did not improve from 53.27345
15/15 - 0s - loss: 272.3900 - val_loss: 541.9357
Epoch 17/300

Epoch 00017: val_loss did not improve from 53.27345
15/15 - 0s - loss: 160.9894 - val_loss: 1338.0978
Epoch 18/300

Epoch 00018: val_loss did not improve from 53.27345
15/15 - 0s - loss: 399.7490 - val_loss: 910.5646
Epoch 19/300

Epoch 00019: val_loss did not improve from 53.27345
15/15 - 0s - loss: 191.9626 - val_loss: 143.5207
Epoch 20/300

Epoch 00020: val_loss improved from 53.27345 to 11.37495, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0_20191029-161127_best_model.h5
15/15 - 1s - loss: 107.7272 - val_loss: 11.3749
Epoch 21/300

Epoch 00021: val_loss did not improve from 11.37495
15/15 - 0s - loss: 208.3000 - val_loss: 31.4593
Epoch 22/300

Epoch 00022: val_loss did not improve from 11.37495
15/15 - 0s - loss: 113.5799 - val_loss: 176.1916
Epoch 23/300

Epoch 00023: val_loss did not improve from 11.37495
15/15 - 0s - loss: 38.1025 - val_loss: 451.2585
Epoch 24/300

Epoch 00024: val_loss did not improve from 11.37495
15/15 - 0s - loss: 102.5424 - val_loss: 398.7345
Epoch 25/300

Epoch 00025: val_loss did not improve from 11.37495
15/15 - 0s - loss: 66.8249 - val_loss: 129.1934
Epoch 26/300

Epoch 00026: val_loss improved from 11.37495 to 8.68459, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0_20191029-161127_best_model.h5
15/15 - 1s - loss: 25.4914 - val_loss: 8.6846
Epoch 27/300

Epoch 00027: val_loss did not improve from 8.68459
15/15 - 0s - loss: 55.4316 - val_loss: 20.6568
Epoch 28/300

Epoch 00028: val_loss did not improve from 8.68459
15/15 - 0s - loss: 40.8745 - val_loss: 109.5394
Epoch 29/300

Epoch 00029: val_loss did not improve from 8.68459
15/15 - 0s - loss: 17.2209 - val_loss: 213.2930
Epoch 30/300

Epoch 00030: val_loss did not improve from 8.68459
15/15 - 0s - loss: 31.2159 - val_loss: 184.3811
Epoch 31/300

Epoch 00031: val_loss did not improve from 8.68459
15/15 - 0s - loss: 19.7215 - val_loss: 73.0022
Epoch 32/300

Epoch 00032: val_loss did not improve from 8.68459
15/15 - 0s - loss: 12.5550 - val_loss: 21.9090
Epoch 33/300

Epoch 00033: val_loss did not improve from 8.68459
15/15 - 0s - loss: 18.5015 - val_loss: 40.7797
Epoch 34/300

Epoch 00034: val_loss did not improve from 8.68459
15/15 - 0s - loss: 9.9115 - val_loss: 99.6590
Epoch 35/300

Epoch 00035: val_loss did not improve from 8.68459
15/15 - 0s - loss: 7.8667 - val_loss: 130.6185
Epoch 36/300

Epoch 00036: val_loss did not improve from 8.68459
15/15 - 0s - loss: 9.3120 - val_loss: 92.7189
Epoch 37/300

Epoch 00037: val_loss did not improve from 8.68459
15/15 - 0s - loss: 4.4145 - val_loss: 47.0079
Epoch 38/300

Epoch 00038: val_loss did not improve from 8.68459
15/15 - 0s - loss: 5.2220 - val_loss: 37.1778
Epoch 39/300

Epoch 00039: val_loss did not improve from 8.68459
15/15 - 0s - loss: 4.4646 - val_loss: 61.8560
Epoch 40/300

Epoch 00040: val_loss did not improve from 8.68459
15/15 - 0s - loss: 2.4259 - val_loss: 85.9545
Epoch 41/300

Epoch 00041: val_loss did not improve from 8.68459
15/15 - 0s - loss: 3.2747 - val_loss: 80.7626
Epoch 42/300

Epoch 00042: val_loss did not improve from 8.68459
15/15 - 0s - loss: 2.2242 - val_loss: 56.2727
Epoch 43/300

Epoch 00043: val_loss did not improve from 8.68459
15/15 - 0s - loss: 1.8376 - val_loss: 42.2294
Epoch 44/300

Epoch 00044: val_loss did not improve from 8.68459
15/15 - 0s - loss: 1.9310 - val_loss: 49.2436
Epoch 45/300

Epoch 00045: val_loss did not improve from 8.68459
15/15 - 0s - loss: 1.2217 - val_loss: 63.3511
Epoch 46/300

Epoch 00046: val_loss did not improve from 8.68459
15/15 - 0s - loss: 1.1842 - val_loss: 65.2367
Epoch 47/300

Epoch 00047: val_loss did not improve from 8.68459
15/15 - 0s - loss: 0.9482 - val_loss: 54.5486
Epoch 48/300

Epoch 00048: val_loss did not improve from 8.68459
15/15 - 0s - loss: 0.8903 - val_loss: 43.1680
Epoch 49/300

Epoch 00049: val_loss did not improve from 8.68459
15/15 - 0s - loss: 0.7639 - val_loss: 45.1091
Epoch 50/300

Epoch 00050: val_loss did not improve from 8.68459
15/15 - 0s - loss: 0.5222 - val_loss: 52.5778
Epoch 51/300

Epoch 00051: val_loss did not improve from 8.68459
15/15 - 0s - loss: 0.5984 - val_loss: 53.9220
Epoch 52/300

Epoch 00052: val_loss did not improve from 8.68459
15/15 - 0s - loss: 0.4202 - val_loss: 47.5093
Epoch 53/300

Epoch 00053: val_loss did not improve from 8.68459
15/15 - 0s - loss: 0.4841 - val_loss: 41.3522
Epoch 54/300

Epoch 00054: val_loss did not improve from 8.68459
15/15 - 0s - loss: 0.4200 - val_loss: 42.9044
Epoch 55/300

Epoch 00055: val_loss did not improve from 8.68459
15/15 - 0s - loss: 0.2362 - val_loss: 47.2211
Epoch 56/300

Epoch 00056: val_loss did not improve from 8.68459
15/15 - 0s - loss: 0.3438 - val_loss: 46.8894
Epoch 00056: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      477.784545
Mean squared error (MSE):       490209.823583
Root mean squared error (RMSE): 700.149858
R square (R^2):                 -228.442888
[1.64504077e+05 2.84767796e+02 3.01078856e+04 1.76594256e+06]
##############################################
   Model8_filters_1_dense_0_denseSize_16_Dropout_0.4_20191029-161201
##############################################
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 567, 756, 16)      448       
_________________________________________________________________
activation_1 (Activation)    (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 283, 378, 16)      0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1711584)           0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 6846340   
=================================================================
Total params: 6,846,852
Trainable params: 6,846,820
Non-trainable params: 32
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/300
2019-10-29 16:12:02.058838: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 16:12:02.187735: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 72 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 5205.97266, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0.4_20191029-161201_best_model.h5
15/15 - 2s - loss: 16804.6637 - val_loss: 5205.9727
Epoch 2/300

Epoch 00002: val_loss did not improve from 5205.97266
15/15 - 0s - loss: 4910.9155 - val_loss: 30860.6680
Epoch 3/300

Epoch 00003: val_loss did not improve from 5205.97266
15/15 - 0s - loss: 13595.3739 - val_loss: 6675.5234
Epoch 4/300

Epoch 00004: val_loss improved from 5205.97266 to 3655.72070, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0.4_20191029-161201_best_model.h5
15/15 - 1s - loss: 1959.2527 - val_loss: 3655.7207
Epoch 5/300

Epoch 00005: val_loss did not improve from 3655.72070
15/15 - 0s - loss: 3499.4877 - val_loss: 9659.5879
Epoch 6/300

Epoch 00006: val_loss improved from 3655.72070 to 2376.61328, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0.4_20191029-161201_best_model.h5
15/15 - 1s - loss: 4746.7055 - val_loss: 2376.6133
Epoch 7/300

Epoch 00007: val_loss improved from 2376.61328 to 700.17828, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0.4_20191029-161201_best_model.h5
15/15 - 1s - loss: 875.6480 - val_loss: 700.1783
Epoch 8/300

Epoch 00008: val_loss did not improve from 700.17828
15/15 - 1s - loss: 785.6684 - val_loss: 4828.7310
Epoch 9/300

Epoch 00009: val_loss did not improve from 700.17828
15/15 - 0s - loss: 2249.7704 - val_loss: 3415.9216
Epoch 10/300

Epoch 00010: val_loss improved from 700.17828 to 365.86615, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0.4_20191029-161201_best_model.h5
15/15 - 1s - loss: 1241.7993 - val_loss: 365.8661
Epoch 11/300

Epoch 00011: val_loss did not improve from 365.86615
15/15 - 0s - loss: 176.0045 - val_loss: 2270.5879
Epoch 12/300

Epoch 00012: val_loss did not improve from 365.86615
15/15 - 0s - loss: 640.3317 - val_loss: 4321.4141
Epoch 13/300

Epoch 00013: val_loss did not improve from 365.86615
15/15 - 0s - loss: 962.6394 - val_loss: 2297.6743
Epoch 14/300

Epoch 00014: val_loss improved from 365.86615 to 163.53098, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0.4_20191029-161201_best_model.h5
15/15 - 2s - loss: 342.2205 - val_loss: 163.5310
Epoch 15/300

Epoch 00015: val_loss did not improve from 163.53098
15/15 - 0s - loss: 82.2944 - val_loss: 250.2160
Epoch 16/300

Epoch 00016: val_loss did not improve from 163.53098
15/15 - 0s - loss: 397.2585 - val_loss: 503.2412
Epoch 17/300

Epoch 00017: val_loss did not improve from 163.53098
15/15 - 0s - loss: 388.4190 - val_loss: 167.1172
Epoch 18/300

Epoch 00018: val_loss did not improve from 163.53098
15/15 - 0s - loss: 101.9481 - val_loss: 411.6974
Epoch 19/300

Epoch 00019: val_loss did not improve from 163.53098
15/15 - 0s - loss: 77.3503 - val_loss: 969.3036
Epoch 20/300

Epoch 00020: val_loss did not improve from 163.53098
15/15 - 0s - loss: 211.3504 - val_loss: 780.3632
Epoch 21/300

Epoch 00021: val_loss did not improve from 163.53098
15/15 - 0s - loss: 133.8012 - val_loss: 172.9155
Epoch 22/300

Epoch 00022: val_loss improved from 163.53098 to 4.42618, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0.4_20191029-161201_best_model.h5
15/15 - 1s - loss: 32.3544 - val_loss: 4.4262
Epoch 23/300

Epoch 00023: val_loss did not improve from 4.42618
15/15 - 1s - loss: 73.6204 - val_loss: 74.8629
Epoch 24/300

Epoch 00024: val_loss did not improve from 4.42618
15/15 - 0s - loss: 96.0519 - val_loss: 62.4427
Epoch 25/300

Epoch 00025: val_loss did not improve from 4.42618
15/15 - 0s - loss: 30.8222 - val_loss: 127.1774
Epoch 26/300

Epoch 00026: val_loss did not improve from 4.42618
15/15 - 0s - loss: 20.1263 - val_loss: 258.4978
Epoch 27/300

Epoch 00027: val_loss did not improve from 4.42618
15/15 - 0s - loss: 50.5180 - val_loss: 206.8770
Epoch 28/300

Epoch 00028: val_loss did not improve from 4.42618
15/15 - 0s - loss: 34.1630 - val_loss: 53.4687
Epoch 29/300

Epoch 00029: val_loss improved from 4.42618 to 2.88716, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0.4_20191029-161201_best_model.h5
15/15 - 1s - loss: 9.6669 - val_loss: 2.8872
Epoch 30/300

Epoch 00030: val_loss did not improve from 2.88716
15/15 - 0s - loss: 19.7322 - val_loss: 20.3645
Epoch 31/300

Epoch 00031: val_loss did not improve from 2.88716
15/15 - 0s - loss: 22.9341 - val_loss: 35.5564
Epoch 32/300

Epoch 00032: val_loss did not improve from 2.88716
15/15 - 0s - loss: 6.8619 - val_loss: 69.0508
Epoch 33/300

Epoch 00033: val_loss did not improve from 2.88716
15/15 - 0s - loss: 9.0339 - val_loss: 95.8833
Epoch 34/300

Epoch 00034: val_loss did not improve from 2.88716
15/15 - 0s - loss: 14.4461 - val_loss: 59.9632
Epoch 35/300

Epoch 00035: val_loss did not improve from 2.88716
15/15 - 0s - loss: 8.1320 - val_loss: 16.4956
Epoch 36/300

Epoch 00036: val_loss did not improve from 2.88716
15/15 - 0s - loss: 3.7611 - val_loss: 9.3736
Epoch 37/300

Epoch 00037: val_loss did not improve from 2.88716
15/15 - 0s - loss: 6.5488 - val_loss: 20.0499
Epoch 38/300

Epoch 00038: val_loss did not improve from 2.88716
15/15 - 0s - loss: 4.8688 - val_loss: 34.1208
Epoch 39/300

Epoch 00039: val_loss did not improve from 2.88716
15/15 - 0s - loss: 2.6294 - val_loss: 44.0321
Epoch 40/300

Epoch 00040: val_loss did not improve from 2.88716
15/15 - 0s - loss: 3.0344 - val_loss: 35.9139
Epoch 41/300

Epoch 00041: val_loss did not improve from 2.88716
15/15 - 0s - loss: 2.8699 - val_loss: 21.8384
Epoch 42/300

Epoch 00042: val_loss did not improve from 2.88716
15/15 - 0s - loss: 1.4731 - val_loss: 14.6035
Epoch 43/300

Epoch 00043: val_loss did not improve from 2.88716
15/15 - 0s - loss: 1.8664 - val_loss: 16.7717
Epoch 44/300

Epoch 00044: val_loss did not improve from 2.88716
15/15 - 0s - loss: 2.1454 - val_loss: 23.5409
Epoch 45/300

Epoch 00045: val_loss did not improve from 2.88716
15/15 - 0s - loss: 1.3359 - val_loss: 27.3103
Epoch 46/300

Epoch 00046: val_loss did not improve from 2.88716
15/15 - 0s - loss: 1.1477 - val_loss: 25.5317
Epoch 47/300

Epoch 00047: val_loss did not improve from 2.88716
15/15 - 0s - loss: 1.3221 - val_loss: 19.1694
Epoch 48/300

Epoch 00048: val_loss did not improve from 2.88716
15/15 - 0s - loss: 0.9379 - val_loss: 15.6562
Epoch 49/300

Epoch 00049: val_loss did not improve from 2.88716
15/15 - 0s - loss: 0.7783 - val_loss: 16.2983
Epoch 50/300

Epoch 00050: val_loss did not improve from 2.88716
15/15 - 0s - loss: 0.9446 - val_loss: 18.7324
Epoch 51/300

Epoch 00051: val_loss did not improve from 2.88716
15/15 - 0s - loss: 0.8519 - val_loss: 20.4967
Epoch 52/300

Epoch 00052: val_loss did not improve from 2.88716
15/15 - 0s - loss: 0.6414 - val_loss: 19.0838
Epoch 53/300

Epoch 00053: val_loss did not improve from 2.88716
15/15 - 0s - loss: 0.7145 - val_loss: 16.2472
Epoch 54/300

Epoch 00054: val_loss did not improve from 2.88716
15/15 - 0s - loss: 0.6625 - val_loss: 14.4118
Epoch 55/300

Epoch 00055: val_loss did not improve from 2.88716
15/15 - 0s - loss: 0.5790 - val_loss: 15.0958
Epoch 56/300

Epoch 00056: val_loss did not improve from 2.88716
15/15 - 0s - loss: 0.5648 - val_loss: 16.3590
Epoch 57/300

Epoch 00057: val_loss did not improve from 2.88716
15/15 - 0s - loss: 0.4702 - val_loss: 16.7809
Epoch 58/300

Epoch 00058: val_loss did not improve from 2.88716
15/15 - 0s - loss: 0.4682 - val_loss: 15.6068
Epoch 59/300

Epoch 00059: val_loss did not improve from 2.88716
15/15 - 0s - loss: 0.4962 - val_loss: 13.9452
Epoch 00059: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      246.956515
Mean squared error (MSE):       121490.469637
Root mean squared error (RMSE): 348.554830
R square (R^2):                 -203.928480
[1.83819987e+05 6.45801178e+00 1.85639012e+03 3.00279043e+05]
##############################################
   Model8_filters_1_dense_0_denseSize_16_Dropout_0.6_20191029-161233
##############################################
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 567, 756, 16)      448       
_________________________________________________________________
activation_2 (Activation)    (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 283, 378, 16)      0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 1711584)           0         
_________________________________________________________________
dense_2 (Dense)              (None, 4)                 6846340   
=================================================================
Total params: 6,846,852
Trainable params: 6,846,820
Non-trainable params: 32
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/300
2019-10-29 16:12:34.675672: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 16:12:34.805602: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 72 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 3801.26025, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0.6_20191029-161233_best_model.h5
15/15 - 2s - loss: 23426.3326 - val_loss: 3801.2603
Epoch 2/300

Epoch 00002: val_loss did not improve from 3801.26025
15/15 - 0s - loss: 6018.5651 - val_loss: 43726.0195
Epoch 3/300

Epoch 00003: val_loss did not improve from 3801.26025
15/15 - 0s - loss: 17263.0781 - val_loss: 11892.6162
Epoch 4/300

Epoch 00004: val_loss improved from 3801.26025 to 2154.05859, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0.6_20191029-161233_best_model.h5
15/15 - 1s - loss: 2189.5847 - val_loss: 2154.0586
Epoch 5/300

Epoch 00005: val_loss did not improve from 2154.05859
15/15 - 0s - loss: 3873.4744 - val_loss: 9216.2637
Epoch 6/300

Epoch 00006: val_loss did not improve from 2154.05859
15/15 - 0s - loss: 4921.8977 - val_loss: 3253.7300
Epoch 7/300

Epoch 00007: val_loss improved from 2154.05859 to 85.19485, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0.6_20191029-161233_best_model.h5
15/15 - 1s - loss: 888.1057 - val_loss: 85.1949
Epoch 8/300

Epoch 00008: val_loss did not improve from 85.19485
15/15 - 0s - loss: 819.4835 - val_loss: 2269.3403
Epoch 9/300

Epoch 00009: val_loss did not improve from 85.19485
15/15 - 0s - loss: 2331.9680 - val_loss: 1214.1401
Epoch 10/300

Epoch 00010: val_loss did not improve from 85.19485
15/15 - 0s - loss: 1061.9749 - val_loss: 118.9066
Epoch 11/300

Epoch 00011: val_loss did not improve from 85.19485
15/15 - 0s - loss: 102.8119 - val_loss: 2425.0530
Epoch 12/300

Epoch 00012: val_loss did not improve from 85.19485
15/15 - 0s - loss: 658.7827 - val_loss: 3769.1411
Epoch 13/300

Epoch 00013: val_loss did not improve from 85.19485
15/15 - 0s - loss: 904.3257 - val_loss: 1838.3171
Epoch 14/300

Epoch 00014: val_loss did not improve from 85.19485
15/15 - 0s - loss: 290.4871 - val_loss: 106.5869
Epoch 15/300

Epoch 00015: val_loss did not improve from 85.19485
15/15 - 0s - loss: 52.7067 - val_loss: 221.8906
Epoch 16/300

Epoch 00016: val_loss did not improve from 85.19485
15/15 - 0s - loss: 379.3549 - val_loss: 414.8058
Epoch 17/300

Epoch 00017: val_loss improved from 85.19485 to 54.05126, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0.6_20191029-161233_best_model.h5
15/15 - 1s - loss: 364.6022 - val_loss: 54.0513
Epoch 18/300

Epoch 00018: val_loss did not improve from 54.05126
15/15 - 0s - loss: 70.9453 - val_loss: 221.7944
Epoch 19/300

Epoch 00019: val_loss did not improve from 54.05126
15/15 - 0s - loss: 72.3587 - val_loss: 741.6559
Epoch 20/300

Epoch 00020: val_loss did not improve from 54.05126
15/15 - 0s - loss: 209.6262 - val_loss: 582.3815
Epoch 21/300

Epoch 00021: val_loss did not improve from 54.05126
15/15 - 0s - loss: 126.9681 - val_loss: 97.9717
Epoch 22/300

Epoch 00022: val_loss improved from 54.05126 to 19.01704, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0.6_20191029-161233_best_model.h5
15/15 - 1s - loss: 14.6237 - val_loss: 19.0170
Epoch 23/300

Epoch 00023: val_loss did not improve from 19.01704
15/15 - 0s - loss: 67.4784 - val_loss: 83.3793
Epoch 24/300

Epoch 00024: val_loss improved from 19.01704 to 18.45180, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0.6_20191029-161233_best_model.h5
15/15 - 1s - loss: 95.5520 - val_loss: 18.4518
Epoch 25/300

Epoch 00025: val_loss did not improve from 18.45180
15/15 - 0s - loss: 30.9687 - val_loss: 47.4927
Epoch 26/300

Epoch 00026: val_loss did not improve from 18.45180
15/15 - 0s - loss: 19.9699 - val_loss: 173.0816
Epoch 27/300

Epoch 00027: val_loss did not improve from 18.45180
15/15 - 0s - loss: 51.3279 - val_loss: 136.5781
Epoch 28/300

Epoch 00028: val_loss did not improve from 18.45180
15/15 - 0s - loss: 28.7946 - val_loss: 25.7613
Epoch 29/300

Epoch 00029: val_loss improved from 18.45180 to 1.91823, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0.6_20191029-161233_best_model.h5
15/15 - 2s - loss: 7.1921 - val_loss: 1.9182
Epoch 30/300

Epoch 00030: val_loss did not improve from 1.91823
15/15 - 0s - loss: 22.5354 - val_loss: 6.8206
Epoch 31/300

Epoch 00031: val_loss did not improve from 1.91823
15/15 - 0s - loss: 22.1234 - val_loss: 3.0831
Epoch 32/300

Epoch 00032: val_loss did not improve from 1.91823
15/15 - 0s - loss: 6.0406 - val_loss: 38.5916
Epoch 33/300

Epoch 00033: val_loss did not improve from 1.91823
15/15 - 0s - loss: 10.4115 - val_loss: 65.7289
Epoch 34/300

Epoch 00034: val_loss did not improve from 1.91823
15/15 - 0s - loss: 14.0641 - val_loss: 35.6337
Epoch 35/300

Epoch 00035: val_loss did not improve from 1.91823
15/15 - 0s - loss: 4.7717 - val_loss: 5.9409
Epoch 36/300

Epoch 00036: val_loss improved from 1.91823 to 0.32388, saving model to Models\Model8_filters_1_dense_0_denseSize_16_Dropout_0.6_20191029-161233_best_model.h5
15/15 - 1s - loss: 4.9925 - val_loss: 0.3239
Epoch 37/300

Epoch 00037: val_loss did not improve from 0.32388
15/15 - 0s - loss: 8.0541 - val_loss: 3.0896
Epoch 38/300

Epoch 00038: val_loss did not improve from 0.32388
15/15 - 0s - loss: 3.7324 - val_loss: 16.6868
Epoch 39/300

Epoch 00039: val_loss did not improve from 0.32388
15/15 - 0s - loss: 2.7683 - val_loss: 30.8918
Epoch 40/300

Epoch 00040: val_loss did not improve from 0.32388
15/15 - 0s - loss: 4.3597 - val_loss: 24.8361
Epoch 41/300

Epoch 00041: val_loss did not improve from 0.32388
15/15 - 0s - loss: 2.9096 - val_loss: 10.9178
Epoch 42/300

Epoch 00042: val_loss did not improve from 0.32388
15/15 - 0s - loss: 1.9229 - val_loss: 5.3819
Epoch 43/300

Epoch 00043: val_loss did not improve from 0.32388
15/15 - 0s - loss: 2.4636 - val_loss: 7.4141
Epoch 44/300

Epoch 00044: val_loss did not improve from 0.32388
15/15 - 0s - loss: 1.6363 - val_loss: 14.1918
Epoch 45/300

Epoch 00045: val_loss did not improve from 0.32388
15/15 - 0s - loss: 1.3374 - val_loss: 19.3950
Epoch 46/300

Epoch 00046: val_loss did not improve from 0.32388
15/15 - 0s - loss: 1.5908 - val_loss: 16.8474
Epoch 47/300

Epoch 00047: val_loss did not improve from 0.32388
15/15 - 0s - loss: 1.1059 - val_loss: 11.7380
Epoch 48/300

Epoch 00048: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.9104 - val_loss: 8.8822
Epoch 49/300

Epoch 00049: val_loss did not improve from 0.32388
15/15 - 0s - loss: 1.1195 - val_loss: 9.5257
Epoch 50/300

Epoch 00050: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.8860 - val_loss: 13.5281
Epoch 51/300

Epoch 00051: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.7131 - val_loss: 15.6424
Epoch 52/300

Epoch 00052: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.8329 - val_loss: 15.0177
Epoch 53/300

Epoch 00053: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.6129 - val_loss: 11.8937
Epoch 54/300

Epoch 00054: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.6050 - val_loss: 9.9456
Epoch 55/300

Epoch 00055: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.6371 - val_loss: 11.2873
Epoch 56/300

Epoch 00056: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.4741 - val_loss: 13.6944
Epoch 57/300

Epoch 00057: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.5103 - val_loss: 15.3633
Epoch 58/300

Epoch 00058: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.4777 - val_loss: 13.8302
Epoch 59/300

Epoch 00059: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.3976 - val_loss: 11.8505
Epoch 60/300

Epoch 00060: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.3846 - val_loss: 11.8224
Epoch 61/300

Epoch 00061: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.3596 - val_loss: 13.5724
Epoch 62/300

Epoch 00062: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.2996 - val_loss: 14.5292
Epoch 63/300

Epoch 00063: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.3227 - val_loss: 13.8007
Epoch 64/300

Epoch 00064: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.2585 - val_loss: 13.7754
Epoch 65/300

Epoch 00065: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.2432 - val_loss: 13.3321
Epoch 66/300

Epoch 00066: val_loss did not improve from 0.32388
15/15 - 0s - loss: 0.2298 - val_loss: 13.4769
Epoch 00066: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      78.165969
Mean squared error (MSE):       11206.176589
Root mean squared error (RMSE): 105.859230
R square (R^2):                 -12.450305
[1.03916749e+04 9.99644547e-01 1.35441151e+03 3.30776203e+04]
##############################################
   Model8_filters_1_dense_0_denseSize_32_Dropout_0_20191029-161308
##############################################
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_4 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 567, 756, 16)      448       
_________________________________________________________________
activation_3 (Activation)    (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 283, 378, 16)      0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 1711584)           0         
_________________________________________________________________
dense_3 (Dense)              (None, 4)                 6846340   
=================================================================
Total params: 6,846,852
Trainable params: 6,846,820
Non-trainable params: 32
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/300
2019-10-29 16:13:10.516400: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 16:13:10.649323: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 72 kernel records, 11 memcpy records.
WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.142120). Check your callbacks.

Epoch 00001: val_loss improved from inf to 6620.81934, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0_20191029-161308_best_model.h5
15/15 - 2s - loss: 22385.8021 - val_loss: 6620.8193
Epoch 2/300

Epoch 00002: val_loss did not improve from 6620.81934
15/15 - 0s - loss: 5738.3497 - val_loss: 53250.1562
Epoch 3/300

Epoch 00003: val_loss did not improve from 6620.81934
15/15 - 0s - loss: 21121.7871 - val_loss: 10033.7373
Epoch 4/300

Epoch 00004: val_loss improved from 6620.81934 to 6545.25293, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0_20191029-161308_best_model.h5
15/15 - 1s - loss: 2336.4944 - val_loss: 6545.2529
Epoch 5/300

Epoch 00005: val_loss did not improve from 6545.25293
15/15 - 0s - loss: 6894.9783 - val_loss: 10717.1104
Epoch 6/300

Epoch 00006: val_loss improved from 6545.25293 to 667.51385, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0_20191029-161308_best_model.h5
15/15 - 1s - loss: 4523.5898 - val_loss: 667.5139
Epoch 7/300

Epoch 00007: val_loss did not improve from 667.51385
15/15 - 0s - loss: 632.3974 - val_loss: 1884.6494
Epoch 8/300

Epoch 00008: val_loss did not improve from 667.51385
15/15 - 0s - loss: 2859.7699 - val_loss: 1766.8749
Epoch 9/300

Epoch 00009: val_loss improved from 667.51385 to 186.06073, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0_20191029-161308_best_model.h5
15/15 - 1s - loss: 2150.8934 - val_loss: 186.0607
Epoch 10/300

Epoch 00010: val_loss did not improve from 186.06073
15/15 - 0s - loss: 240.7237 - val_loss: 5247.4443
Epoch 11/300

Epoch 00011: val_loss did not improve from 186.06073
15/15 - 0s - loss: 1279.2737 - val_loss: 7748.2100
Epoch 12/300

Epoch 00012: val_loss did not improve from 186.06073
15/15 - 0s - loss: 1365.4641 - val_loss: 3178.6660
Epoch 13/300

Epoch 00013: val_loss did not improve from 186.06073
15/15 - 0s - loss: 149.2092 - val_loss: 193.8200
Epoch 14/300

Epoch 00014: val_loss improved from 186.06073 to 13.23682, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0_20191029-161308_best_model.h5
15/15 - 1s - loss: 526.0460 - val_loss: 13.2368
Epoch 15/300

Epoch 00015: val_loss did not improve from 13.23682
15/15 - 0s - loss: 823.6541 - val_loss: 234.2131
Epoch 16/300

Epoch 00016: val_loss did not improve from 13.23682
15/15 - 0s - loss: 159.5807 - val_loss: 2187.2041
Epoch 17/300

Epoch 00017: val_loss did not improve from 13.23682
15/15 - 0s - loss: 222.6837 - val_loss: 3843.9575
Epoch 18/300

Epoch 00018: val_loss did not improve from 13.23682
15/15 - 0s - loss: 453.1732 - val_loss: 2495.2576
Epoch 19/300

Epoch 00019: val_loss did not improve from 13.23682
15/15 - 0s - loss: 108.3525 - val_loss: 671.9679
Epoch 20/300

Epoch 00020: val_loss did not improve from 13.23682
15/15 - 0s - loss: 109.5846 - val_loss: 163.3582
Epoch 21/300

Epoch 00021: val_loss did not improve from 13.23682
15/15 - 0s - loss: 253.1579 - val_loss: 391.1620
Epoch 22/300

Epoch 00022: val_loss did not improve from 13.23682
15/15 - 0s - loss: 65.2571 - val_loss: 1318.6118
Epoch 23/300

Epoch 00023: val_loss did not improve from 13.23682
15/15 - 0s - loss: 66.9609 - val_loss: 2024.4707
Epoch 24/300

Epoch 00024: val_loss did not improve from 13.23682
15/15 - 0s - loss: 138.7418 - val_loss: 1426.8997
Epoch 25/300

Epoch 00025: val_loss did not improve from 13.23682
15/15 - 0s - loss: 30.4677 - val_loss: 585.3406
Epoch 26/300

Epoch 00026: val_loss did not improve from 13.23682
15/15 - 0s - loss: 40.0404 - val_loss: 326.5837
Epoch 27/300

Epoch 00027: val_loss did not improve from 13.23682
15/15 - 0s - loss: 71.8998 - val_loss: 544.6696
Epoch 28/300

Epoch 00028: val_loss did not improve from 13.23682
15/15 - 0s - loss: 11.7280 - val_loss: 1033.0594
Epoch 29/300

Epoch 00029: val_loss did not improve from 13.23682
15/15 - 0s - loss: 27.6197 - val_loss: 1183.2544
Epoch 30/300

Epoch 00030: val_loss did not improve from 13.23682
15/15 - 0s - loss: 34.8471 - val_loss: 823.0845
Epoch 31/300

Epoch 00031: val_loss did not improve from 13.23682
15/15 - 0s - loss: 5.3320 - val_loss: 477.5100
Epoch 32/300

Epoch 00032: val_loss did not improve from 13.23682
15/15 - 0s - loss: 21.6935 - val_loss: 435.7022
Epoch 33/300

Epoch 00033: val_loss did not improve from 13.23682
15/15 - 0s - loss: 16.2290 - val_loss: 644.9680
Epoch 34/300

Epoch 00034: val_loss did not improve from 13.23682
15/15 - 0s - loss: 3.5922 - val_loss: 831.3699
Epoch 35/300

Epoch 00035: val_loss did not improve from 13.23682
15/15 - 0s - loss: 13.2203 - val_loss: 756.2564
Epoch 36/300

Epoch 00036: val_loss did not improve from 13.23682
15/15 - 0s - loss: 4.3768 - val_loss: 555.0758
Epoch 37/300

Epoch 00037: val_loss did not improve from 13.23682
15/15 - 0s - loss: 3.7893 - val_loss: 453.4738
Epoch 38/300

Epoch 00038: val_loss did not improve from 13.23682
15/15 - 0s - loss: 7.6237 - val_loss: 517.1594
Epoch 39/300

Epoch 00039: val_loss did not improve from 13.23682
15/15 - 0s - loss: 1.9031 - val_loss: 641.1521
Epoch 40/300

Epoch 00040: val_loss did not improve from 13.23682
15/15 - 0s - loss: 4.0885 - val_loss: 647.6324
Epoch 41/300

Epoch 00041: val_loss did not improve from 13.23682
15/15 - 0s - loss: 3.5170 - val_loss: 535.1436
Epoch 42/300

Epoch 00042: val_loss did not improve from 13.23682
15/15 - 0s - loss: 1.0406 - val_loss: 462.5229
Epoch 43/300

Epoch 00043: val_loss did not improve from 13.23682
15/15 - 0s - loss: 2.8191 - val_loss: 479.8957
Epoch 44/300

Epoch 00044: val_loss did not improve from 13.23682
15/15 - 0s - loss: 1.2011 - val_loss: 539.8434
Epoch 00044: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      778.639802
Mean squared error (MSE):       1543911.208113
Root mean squared error (RMSE): 1242.542236
R square (R^2):                 -368.435012
[2.56988094e+05 4.65912987e+00 3.57910341e+04 5.88286105e+06]
##############################################
   Model8_filters_1_dense_0_denseSize_32_Dropout_0.4_20191029-161332
##############################################
Model: "model_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 567, 756, 16)      448       
_________________________________________________________________
activation_4 (Activation)    (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_4 (Batch (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 283, 378, 16)      0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 1711584)           0         
_________________________________________________________________
dense_4 (Dense)              (None, 4)                 6846340   
=================================================================
Total params: 6,846,852
Trainable params: 6,846,820
Non-trainable params: 32
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/300
2019-10-29 16:13:33.503240: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 16:13:33.633218: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 72 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 13065.99902, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0.4_20191029-161332_best_model.h5
15/15 - 2s - loss: 28850.2716 - val_loss: 13065.9990
Epoch 2/300

Epoch 00002: val_loss did not improve from 13065.99902
15/15 - 0s - loss: 7500.5249 - val_loss: 115275.0312
Epoch 3/300

Epoch 00003: val_loss did not improve from 13065.99902
15/15 - 1s - loss: 28941.4868 - val_loss: 25664.2461
Epoch 4/300

Epoch 00004: val_loss did not improve from 13065.99902
15/15 - 0s - loss: 4255.9325 - val_loss: 15052.2578
Epoch 5/300

Epoch 00005: val_loss did not improve from 13065.99902
15/15 - 0s - loss: 9903.5868 - val_loss: 35266.1445
Epoch 6/300

Epoch 00006: val_loss improved from 13065.99902 to 4913.91504, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0.4_20191029-161332_best_model.h5
15/15 - 1s - loss: 10912.1496 - val_loss: 4913.9150
Epoch 7/300

Epoch 00007: val_loss improved from 4913.91504 to 3977.73364, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0.4_20191029-161332_best_model.h5
15/15 - 1s - loss: 1383.5320 - val_loss: 3977.7336
Epoch 8/300

Epoch 00008: val_loss did not improve from 3977.73364
15/15 - 0s - loss: 4616.0652 - val_loss: 8811.9189
Epoch 9/300

Epoch 00009: val_loss improved from 3977.73364 to 396.06488, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0.4_20191029-161332_best_model.h5
15/15 - 1s - loss: 5410.1415 - val_loss: 396.0649
Epoch 10/300

Epoch 00010: val_loss did not improve from 396.06488
15/15 - 0s - loss: 567.9654 - val_loss: 6473.4902
Epoch 11/300

Epoch 00011: val_loss did not improve from 396.06488
15/15 - 1s - loss: 1643.6580 - val_loss: 16433.9473
Epoch 12/300

Epoch 00012: val_loss did not improve from 396.06488
15/15 - 0s - loss: 3136.9784 - val_loss: 8516.1758
Epoch 13/300

Epoch 00013: val_loss did not improve from 396.06488
15/15 - 0s - loss: 881.8704 - val_loss: 425.0657
Epoch 14/300

Epoch 00014: val_loss did not improve from 396.06488
15/15 - 0s - loss: 495.6085 - val_loss: 568.9168
Epoch 15/300

Epoch 00015: val_loss improved from 396.06488 to 207.83713, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0.4_20191029-161332_best_model.h5
15/15 - 1s - loss: 1601.7463 - val_loss: 207.8371
Epoch 16/300

Epoch 00016: val_loss did not improve from 207.83713
15/15 - 0s - loss: 758.4415 - val_loss: 885.8033
Epoch 17/300

Epoch 00017: val_loss did not improve from 207.83713
15/15 - 0s - loss: 145.1246 - val_loss: 4402.2900
Epoch 18/300

Epoch 00018: val_loss did not improve from 207.83713
15/15 - 0s - loss: 752.2365 - val_loss: 4314.6055
Epoch 19/300

Epoch 00019: val_loss did not improve from 207.83713
15/15 - 0s - loss: 518.7266 - val_loss: 1238.2886
Epoch 20/300

Epoch 00020: val_loss improved from 207.83713 to 25.71746, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0.4_20191029-161332_best_model.h5
15/15 - 1s - loss: 30.2068 - val_loss: 25.7175
Epoch 21/300

Epoch 00021: val_loss improved from 25.71746 to 5.93688, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0.4_20191029-161332_best_model.h5
15/15 - 1s - loss: 344.0760 - val_loss: 5.9369
Epoch 22/300

Epoch 00022: val_loss did not improve from 5.93688
15/15 - 0s - loss: 349.3326 - val_loss: 224.6563
Epoch 23/300

Epoch 00023: val_loss did not improve from 5.93688
15/15 - 0s - loss: 22.3228 - val_loss: 1314.8162
Epoch 24/300

Epoch 00024: val_loss did not improve from 5.93688
15/15 - 0s - loss: 163.8721 - val_loss: 1865.8680
Epoch 25/300

Epoch 00025: val_loss did not improve from 5.93688
15/15 - 0s - loss: 218.3800 - val_loss: 920.9882
Epoch 26/300

Epoch 00026: val_loss did not improve from 5.93688
15/15 - 0s - loss: 31.3917 - val_loss: 179.0822
Epoch 27/300

Epoch 00027: val_loss did not improve from 5.93688
15/15 - 0s - loss: 85.9505 - val_loss: 46.9772
Epoch 28/300

Epoch 00028: val_loss did not improve from 5.93688
15/15 - 0s - loss: 113.9043 - val_loss: 209.7431
Epoch 29/300

Epoch 00029: val_loss did not improve from 5.93688
15/15 - 0s - loss: 25.7658 - val_loss: 700.3400
Epoch 30/300

Epoch 00030: val_loss did not improve from 5.93688
15/15 - 0s - loss: 48.9348 - val_loss: 882.7888
Epoch 31/300

Epoch 00031: val_loss did not improve from 5.93688
15/15 - 0s - loss: 60.3353 - val_loss: 520.2220
Epoch 32/300

Epoch 00032: val_loss did not improve from 5.93688
15/15 - 0s - loss: 11.3402 - val_loss: 191.1680
Epoch 33/300

Epoch 00033: val_loss did not improve from 5.93688
15/15 - 0s - loss: 34.1036 - val_loss: 131.3909
Epoch 34/300

Epoch 00034: val_loss did not improve from 5.93688
15/15 - 0s - loss: 32.2211 - val_loss: 285.3749
Epoch 35/300

Epoch 00035: val_loss did not improve from 5.93688
15/15 - 0s - loss: 3.9054 - val_loss: 501.1954
Epoch 36/300

Epoch 00036: val_loss did not improve from 5.93688
15/15 - 0s - loss: 20.8670 - val_loss: 512.2836
Epoch 37/300

Epoch 00037: val_loss did not improve from 5.93688
15/15 - 0s - loss: 15.0028 - val_loss: 317.6462
Epoch 38/300

Epoch 00038: val_loss did not improve from 5.93688
15/15 - 0s - loss: 5.0894 - val_loss: 184.8981
Epoch 39/300

Epoch 00039: val_loss did not improve from 5.93688
15/15 - 0s - loss: 13.4717 - val_loss: 202.9767
Epoch 40/300

Epoch 00040: val_loss did not improve from 5.93688
15/15 - 0s - loss: 6.4180 - val_loss: 313.5437
Epoch 41/300

Epoch 00041: val_loss did not improve from 5.93688
15/15 - 0s - loss: 3.3666 - val_loss: 380.8676
Epoch 42/300

Epoch 00042: val_loss did not improve from 5.93688
15/15 - 0s - loss: 7.8629 - val_loss: 327.2634
Epoch 43/300

Epoch 00043: val_loss did not improve from 5.93688
15/15 - 0s - loss: 2.9863 - val_loss: 231.4939
Epoch 44/300

Epoch 00044: val_loss did not improve from 5.93688
15/15 - 0s - loss: 3.7828 - val_loss: 200.0912
Epoch 45/300

Epoch 00045: val_loss did not improve from 5.93688
15/15 - 0s - loss: 4.5609 - val_loss: 238.7130
Epoch 46/300

Epoch 00046: val_loss did not improve from 5.93688
15/15 - 0s - loss: 1.4320 - val_loss: 293.1716
Epoch 47/300

Epoch 00047: val_loss did not improve from 5.93688
15/15 - 0s - loss: 4.2354 - val_loss: 295.8296
Epoch 48/300

Epoch 00048: val_loss did not improve from 5.93688
15/15 - 0s - loss: 2.6753 - val_loss: 232.9259
Epoch 49/300

Epoch 00049: val_loss did not improve from 5.93688
15/15 - 0s - loss: 1.9634 - val_loss: 192.1295
Epoch 50/300

Epoch 00050: val_loss did not improve from 5.93688
15/15 - 0s - loss: 3.3570 - val_loss: 207.0957
Epoch 51/300

Epoch 00051: val_loss did not improve from 5.93688
15/15 - 0s - loss: 1.6820 - val_loss: 254.0966
Epoch 00051: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      167.692545
Mean squared error (MSE):       57060.174787
Root mean squared error (RMSE): 238.872717
R square (R^2):                 -203.526933
[175779.14520351    497.03986779  10500.13923357  41464.37484196]
##############################################
   Model8_filters_1_dense_0_denseSize_32_Dropout_0.6_20191029-161359
##############################################
Model: "model_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 567, 756, 16)      448       
_________________________________________________________________
activation_5 (Activation)    (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_5 (Batch (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 283, 378, 16)      0         
_________________________________________________________________
flatten_5 (Flatten)          (None, 1711584)           0         
_________________________________________________________________
dense_5 (Dense)              (None, 4)                 6846340   
=================================================================
Total params: 6,846,852
Trainable params: 6,846,820
Non-trainable params: 32
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/300
2019-10-29 16:14:00.841151: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 16:14:00.977810: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 72 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 1957.91077, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0.6_20191029-161359_best_model.h5
15/15 - 2s - loss: 5217.8680 - val_loss: 1957.9108
Epoch 2/300

Epoch 00002: val_loss did not improve from 1957.91077
15/15 - 0s - loss: 1394.1586 - val_loss: 14460.1309
Epoch 3/300

Epoch 00003: val_loss did not improve from 1957.91077
15/15 - 0s - loss: 4825.7821 - val_loss: 3623.8110
Epoch 4/300

Epoch 00004: val_loss improved from 1957.91077 to 211.68484, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0.6_20191029-161359_best_model.h5
15/15 - 1s - loss: 548.9526 - val_loss: 211.6848
Epoch 5/300

Epoch 00005: val_loss did not improve from 211.68484
15/15 - 0s - loss: 1217.6869 - val_loss: 480.6617
Epoch 6/300

Epoch 00006: val_loss improved from 211.68484 to 44.76389, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0.6_20191029-161359_best_model.h5
15/15 - 1s - loss: 717.0713 - val_loss: 44.7639
Epoch 7/300

Epoch 00007: val_loss did not improve from 44.76389
15/15 - 0s - loss: 78.5603 - val_loss: 1161.9329
Epoch 8/300

Epoch 00008: val_loss did not improve from 44.76389
15/15 - 0s - loss: 456.1958 - val_loss: 1292.7053
Epoch 9/300

Epoch 00009: val_loss did not improve from 44.76389
15/15 - 0s - loss: 415.3481 - val_loss: 236.4335
Epoch 10/300

Epoch 00010: val_loss did not improve from 44.76389
15/15 - 0s - loss: 51.8178 - val_loss: 86.7928
Epoch 11/300

Epoch 00011: val_loss did not improve from 44.76389
15/15 - 0s - loss: 137.1215 - val_loss: 438.8416
Epoch 12/300

Epoch 00012: val_loss did not improve from 44.76389
15/15 - 1s - loss: 263.0020 - val_loss: 249.5285
Epoch 13/300

Epoch 00013: val_loss improved from 44.76389 to 2.38314, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0.6_20191029-161359_best_model.h5
15/15 - 1s - loss: 104.2310 - val_loss: 2.3831
Epoch 14/300

Epoch 00014: val_loss did not improve from 2.38314
15/15 - 0s - loss: 15.8101 - val_loss: 103.9747
Epoch 15/300

Epoch 00015: val_loss did not improve from 2.38314
15/15 - 0s - loss: 110.8804 - val_loss: 137.2172
Epoch 16/300

Epoch 00016: val_loss did not improve from 2.38314
15/15 - 0s - loss: 98.1856 - val_loss: 16.9843
Epoch 17/300

Epoch 00017: val_loss did not improve from 2.38314
15/15 - 0s - loss: 13.5956 - val_loss: 43.0394
Epoch 18/300

Epoch 00018: val_loss did not improve from 2.38314
15/15 - 0s - loss: 28.4485 - val_loss: 136.5335
Epoch 19/300

Epoch 00019: val_loss did not improve from 2.38314
15/15 - 0s - loss: 62.0427 - val_loss: 86.4203
Epoch 20/300

Epoch 00020: val_loss did not improve from 2.38314
15/15 - 0s - loss: 26.0845 - val_loss: 6.3688
Epoch 21/300

Epoch 00021: val_loss did not improve from 2.38314
15/15 - 0s - loss: 4.1204 - val_loss: 11.2709
Epoch 22/300

Epoch 00022: val_loss did not improve from 2.38314
15/15 - 0s - loss: 26.5414 - val_loss: 17.0941
Epoch 23/300

Epoch 00023: val_loss improved from 2.38314 to 1.74691, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0.6_20191029-161359_best_model.h5
15/15 - 1s - loss: 23.0799 - val_loss: 1.7469
Epoch 24/300

Epoch 00024: val_loss did not improve from 1.74691
15/15 - 0s - loss: 2.5353 - val_loss: 21.4069
Epoch 25/300

Epoch 00025: val_loss did not improve from 1.74691
15/15 - 0s - loss: 8.5688 - val_loss: 43.8981
Epoch 26/300

Epoch 00026: val_loss did not improve from 1.74691
15/15 - 0s - loss: 15.3207 - val_loss: 24.2502
Epoch 27/300

Epoch 00027: val_loss did not improve from 1.74691
15/15 - 0s - loss: 4.6910 - val_loss: 2.6353
Epoch 28/300

Epoch 00028: val_loss improved from 1.74691 to 1.54051, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0.6_20191029-161359_best_model.h5
15/15 - 1s - loss: 2.8820 - val_loss: 1.5405
Epoch 29/300

Epoch 00029: val_loss improved from 1.54051 to 1.27086, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0.6_20191029-161359_best_model.h5
15/15 - 1s - loss: 8.1802 - val_loss: 1.2709
Epoch 30/300

Epoch 00030: val_loss did not improve from 1.27086
15/15 - 0s - loss: 4.2775 - val_loss: 4.9253
Epoch 31/300

Epoch 00031: val_loss did not improve from 1.27086
15/15 - 0s - loss: 0.6906 - val_loss: 15.9157
Epoch 32/300

Epoch 00032: val_loss did not improve from 1.27086
15/15 - 0s - loss: 3.9588 - val_loss: 16.4834
Epoch 33/300

Epoch 00033: val_loss did not improve from 1.27086
15/15 - 0s - loss: 3.0302 - val_loss: 6.6727
Epoch 34/300

Epoch 00034: val_loss did not improve from 1.27086
15/15 - 0s - loss: 0.5177 - val_loss: 1.4250
Epoch 35/300

Epoch 00035: val_loss improved from 1.27086 to 1.09241, saving model to Models\Model8_filters_1_dense_0_denseSize_32_Dropout_0.6_20191029-161359_best_model.h5
15/15 - 1s - loss: 2.0207 - val_loss: 1.0924
Epoch 36/300

Epoch 00036: val_loss did not improve from 1.09241
15/15 - 0s - loss: 1.9302 - val_loss: 3.1845
Epoch 37/300

Epoch 00037: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.4734 - val_loss: 8.2939
Epoch 38/300

Epoch 00038: val_loss did not improve from 1.09241
15/15 - 0s - loss: 1.0851 - val_loss: 9.7738
Epoch 39/300

Epoch 00039: val_loss did not improve from 1.09241
15/15 - 0s - loss: 1.1775 - val_loss: 5.9214
Epoch 40/300

Epoch 00040: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.2786 - val_loss: 2.6033
Epoch 41/300

Epoch 00041: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.6200 - val_loss: 1.9688
Epoch 42/300

Epoch 00042: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.7194 - val_loss: 3.3097
Epoch 43/300

Epoch 00043: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.2156 - val_loss: 5.6797
Epoch 44/300

Epoch 00044: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.4156 - val_loss: 6.4555
Epoch 45/300

Epoch 00045: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.4590 - val_loss: 4.6293
Epoch 46/300

Epoch 00046: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.1699 - val_loss: 2.9595
Epoch 47/300

Epoch 00047: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.3099 - val_loss: 2.6074
Epoch 48/300

Epoch 00048: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.2964 - val_loss: 3.6332
Epoch 49/300

Epoch 00049: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.1834 - val_loss: 4.8022
Epoch 50/300

Epoch 00050: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.2108 - val_loss: 4.5739
Epoch 51/300

Epoch 00051: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.1598 - val_loss: 3.5929
Epoch 52/300

Epoch 00052: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.1027 - val_loss: 3.0372
Epoch 53/300

Epoch 00053: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.1496 - val_loss: 3.0819
Epoch 54/300

Epoch 00054: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.1188 - val_loss: 3.6584
Epoch 55/300

Epoch 00055: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.1139 - val_loss: 4.0668
Epoch 56/300

Epoch 00056: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.1125 - val_loss: 3.6833
Epoch 57/300

Epoch 00057: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.0780 - val_loss: 3.2218
Epoch 58/300

Epoch 00058: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.0742 - val_loss: 2.9341
Epoch 59/300

Epoch 00059: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.0918 - val_loss: 3.0385
Epoch 60/300

Epoch 00060: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.0726 - val_loss: 3.3513
Epoch 61/300

Epoch 00061: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.0727 - val_loss: 3.5095
Epoch 62/300

Epoch 00062: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.0679 - val_loss: 3.2049
Epoch 63/300

Epoch 00063: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.0520 - val_loss: 2.9596
Epoch 64/300

Epoch 00064: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.0568 - val_loss: 2.8202
Epoch 65/300

Epoch 00065: val_loss did not improve from 1.09241
15/15 - 0s - loss: 0.0547 - val_loss: 2.9705
Epoch 00065: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      265.600586
Mean squared error (MSE):       255263.694924
Root mean squared error (RMSE): 505.236276
R square (R^2):                 -10.815543
[2.93409768e+03 9.93959745e-01 2.81042334e+02 1.01783865e+06]
##############################################
   Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433
##############################################
Model: "model_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 567, 756, 16)      448       
_________________________________________________________________
activation_6 (Activation)    (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_6 (Batch (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 283, 378, 16)      0         
_________________________________________________________________
flatten_6 (Flatten)          (None, 1711584)           0         
_________________________________________________________________
dense_6 (Dense)              (None, 4)                 6846340   
=================================================================
Total params: 6,846,852
Trainable params: 6,846,820
Non-trainable params: 32
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/300
2019-10-29 16:14:34.266689: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 16:14:34.396904: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 72 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 10260.33691, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 12480.7095 - val_loss: 10260.3369
Epoch 2/300

Epoch 00002: val_loss did not improve from 10260.33691
15/15 - 0s - loss: 3262.5441 - val_loss: 76471.5391
Epoch 3/300

Epoch 00003: val_loss did not improve from 10260.33691
15/15 - 0s - loss: 12319.1089 - val_loss: 19397.0215
Epoch 4/300

Epoch 00004: val_loss improved from 10260.33691 to 8202.05566, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1791.3545 - val_loss: 8202.0557
Epoch 5/300

Epoch 00005: val_loss did not improve from 8202.05566
15/15 - 0s - loss: 3478.0299 - val_loss: 26037.6758
Epoch 6/300

Epoch 00006: val_loss improved from 8202.05566 to 5669.53418, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 5134.9900 - val_loss: 5669.5342
Epoch 7/300

Epoch 00007: val_loss improved from 5669.53418 to 2545.45459, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 764.5511 - val_loss: 2545.4546
Epoch 8/300

Epoch 00008: val_loss did not improve from 2545.45459
15/15 - 0s - loss: 1137.4409 - val_loss: 13294.7549
Epoch 9/300

Epoch 00009: val_loss did not improve from 2545.45459
15/15 - 0s - loss: 2713.1141 - val_loss: 7542.3789
Epoch 10/300

Epoch 00010: val_loss improved from 2545.45459 to 168.69473, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1189.5977 - val_loss: 168.6947
Epoch 11/300

Epoch 00011: val_loss did not improve from 168.69473
15/15 - 0s - loss: 160.3456 - val_loss: 4653.6714
Epoch 12/300

Epoch 00012: val_loss did not improve from 168.69473
15/15 - 0s - loss: 1065.2703 - val_loss: 6456.9746
Epoch 13/300

Epoch 00013: val_loss did not improve from 168.69473
15/15 - 0s - loss: 1043.1611 - val_loss: 1597.8508
Epoch 14/300

Epoch 00014: val_loss did not improve from 168.69473
15/15 - 0s - loss: 192.5429 - val_loss: 228.8200
Epoch 15/300

Epoch 00015: val_loss did not improve from 168.69473
15/15 - 0s - loss: 209.2456 - val_loss: 2044.8733
Epoch 16/300

Epoch 00016: val_loss did not improve from 168.69473
15/15 - 0s - loss: 601.2839 - val_loss: 1534.4806
Epoch 17/300

Epoch 00017: val_loss improved from 168.69473 to 111.90463, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 330.6939 - val_loss: 111.9046
Epoch 18/300

Epoch 00018: val_loss did not improve from 111.90463
15/15 - 0s - loss: 35.8471 - val_loss: 637.3074
Epoch 19/300

Epoch 00019: val_loss did not improve from 111.90463
15/15 - 0s - loss: 211.9615 - val_loss: 1157.3660
Epoch 20/300

Epoch 00020: val_loss did not improve from 111.90463
15/15 - 0s - loss: 267.2497 - val_loss: 395.9189
Epoch 21/300

Epoch 00021: val_loss improved from 111.90463 to 14.89189, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 67.8600 - val_loss: 14.8919
Epoch 22/300

Epoch 00022: val_loss did not improve from 14.89189
15/15 - 0s - loss: 41.3340 - val_loss: 369.1178
Epoch 23/300

Epoch 00023: val_loss did not improve from 14.89189
15/15 - 0s - loss: 143.7241 - val_loss: 326.9744
Epoch 24/300

Epoch 00024: val_loss did not improve from 14.89189
15/15 - 0s - loss: 86.2171 - val_loss: 44.1461
Epoch 25/300

Epoch 00025: val_loss did not improve from 14.89189
15/15 - 0s - loss: 14.5099 - val_loss: 159.7652
Epoch 26/300

Epoch 00026: val_loss did not improve from 14.89189
15/15 - 0s - loss: 55.8938 - val_loss: 251.1945
Epoch 27/300

Epoch 00027: val_loss did not improve from 14.89189
15/15 - 0s - loss: 64.4732 - val_loss: 67.9706
Epoch 28/300

Epoch 00028: val_loss improved from 14.89189 to 10.16828, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 12.3322 - val_loss: 10.1683
Epoch 29/300

Epoch 00029: val_loss did not improve from 10.16828
15/15 - 0s - loss: 16.5865 - val_loss: 84.5721
Epoch 30/300

Epoch 00030: val_loss did not improve from 10.16828
15/15 - 0s - loss: 36.6436 - val_loss: 53.9413
Epoch 31/300

Epoch 00031: val_loss did not improve from 10.16828
15/15 - 0s - loss: 14.2265 - val_loss: 22.2473
Epoch 32/300

Epoch 00032: val_loss did not improve from 10.16828
15/15 - 0s - loss: 5.0650 - val_loss: 65.2361
Epoch 33/300

Epoch 00033: val_loss did not improve from 10.16828
15/15 - 0s - loss: 18.8927 - val_loss: 55.6359
Epoch 34/300

Epoch 00034: val_loss improved from 10.16828 to 7.36090, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 12.8592 - val_loss: 7.3609
Epoch 35/300

Epoch 00035: val_loss did not improve from 7.36090
15/15 - 0s - loss: 2.3025 - val_loss: 11.8679
Epoch 36/300

Epoch 00036: val_loss did not improve from 7.36090
15/15 - 0s - loss: 8.3578 - val_loss: 21.7174
Epoch 37/300

Epoch 00037: val_loss did not improve from 7.36090
15/15 - 0s - loss: 7.9301 - val_loss: 14.0079
Epoch 38/300

Epoch 00038: val_loss did not improve from 7.36090
15/15 - 0s - loss: 2.1463 - val_loss: 21.3373
Epoch 39/300

Epoch 00039: val_loss did not improve from 7.36090
15/15 - 0s - loss: 3.9917 - val_loss: 23.7174
Epoch 40/300

Epoch 00040: val_loss did not improve from 7.36090
15/15 - 0s - loss: 4.6171 - val_loss: 9.4210
Epoch 41/300

Epoch 00041: val_loss improved from 7.36090 to 5.11874, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.3843 - val_loss: 5.1187
Epoch 42/300

Epoch 00042: val_loss did not improve from 5.11874
15/15 - 0s - loss: 2.4205 - val_loss: 9.6482
Epoch 43/300

Epoch 00043: val_loss did not improve from 5.11874
15/15 - 0s - loss: 2.7883 - val_loss: 9.9473
Epoch 44/300

Epoch 00044: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.7343 - val_loss: 12.3863
Epoch 45/300

Epoch 00045: val_loss did not improve from 5.11874
15/15 - 0s - loss: 1.1195 - val_loss: 12.8669
Epoch 46/300

Epoch 00046: val_loss did not improve from 5.11874
15/15 - 0s - loss: 1.7128 - val_loss: 8.0125
Epoch 47/300

Epoch 00047: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.9103 - val_loss: 5.2940
Epoch 48/300

Epoch 00048: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.8607 - val_loss: 6.8239
Epoch 49/300

Epoch 00049: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.9900 - val_loss: 8.1212
Epoch 50/300

Epoch 00050: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.4776 - val_loss: 9.3075
Epoch 51/300

Epoch 00051: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.5476 - val_loss: 8.5839
Epoch 52/300

Epoch 00052: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.5954 - val_loss: 6.3391
Epoch 53/300

Epoch 00053: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.3469 - val_loss: 5.5145
Epoch 54/300

Epoch 00054: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.4032 - val_loss: 6.2754
Epoch 55/300

Epoch 00055: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.4033 - val_loss: 7.1723
Epoch 56/300

Epoch 00056: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.2592 - val_loss: 7.5400
Epoch 57/300

Epoch 00057: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.2901 - val_loss: 6.7976
Epoch 58/300

Epoch 00058: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.2749 - val_loss: 5.7298
Epoch 59/300

Epoch 00059: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.2124 - val_loss: 5.5910
Epoch 60/300

Epoch 00060: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.2076 - val_loss: 6.0999
Epoch 61/300

Epoch 00061: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.1741 - val_loss: 6.4839
Epoch 62/300

Epoch 00062: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.1648 - val_loss: 6.3285
Epoch 63/300

Epoch 00063: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.1596 - val_loss: 5.6849
Epoch 64/300

Epoch 00064: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.1285 - val_loss: 5.3192
Epoch 65/300

Epoch 00065: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.1612 - val_loss: 5.3626
Epoch 66/300

Epoch 00066: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.1396 - val_loss: 5.7814
Epoch 67/300

Epoch 00067: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.1031 - val_loss: 5.7676
Epoch 68/300

Epoch 00068: val_loss did not improve from 5.11874
15/15 - 0s - loss: 0.1033 - val_loss: 5.4264
Epoch 69/300

Epoch 00069: val_loss improved from 5.11874 to 5.06009, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0925 - val_loss: 5.0601
Epoch 70/300

Epoch 00070: val_loss improved from 5.06009 to 5.05601, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0838 - val_loss: 5.0560
Epoch 71/300

Epoch 00071: val_loss did not improve from 5.05601
15/15 - 1s - loss: 0.0799 - val_loss: 5.1448
Epoch 72/300

Epoch 00072: val_loss did not improve from 5.05601
15/15 - 0s - loss: 0.0718 - val_loss: 5.1855
Epoch 73/300

Epoch 00073: val_loss did not improve from 5.05601
15/15 - 0s - loss: 0.0801 - val_loss: 5.0906
Epoch 74/300

Epoch 00074: val_loss improved from 5.05601 to 4.78425, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0628 - val_loss: 4.7843
Epoch 75/300

Epoch 00075: val_loss improved from 4.78425 to 4.68493, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0540 - val_loss: 4.6849
Epoch 76/300

Epoch 00076: val_loss improved from 4.68493 to 4.68146, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0598 - val_loss: 4.6815
Epoch 77/300

Epoch 00077: val_loss did not improve from 4.68146
15/15 - 0s - loss: 0.0528 - val_loss: 4.7467
Epoch 78/300

Epoch 00078: val_loss did not improve from 4.68146
15/15 - 0s - loss: 0.0500 - val_loss: 4.8068
Epoch 79/300

Epoch 00079: val_loss improved from 4.68146 to 4.57776, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0533 - val_loss: 4.5778
Epoch 80/300

Epoch 00080: val_loss improved from 4.57776 to 4.35237, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0386 - val_loss: 4.3524
Epoch 81/300

Epoch 00081: val_loss improved from 4.35237 to 4.29937, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0422 - val_loss: 4.2994
Epoch 82/300

Epoch 00082: val_loss did not improve from 4.29937
15/15 - 0s - loss: 0.0378 - val_loss: 4.3694
Epoch 83/300

Epoch 00083: val_loss did not improve from 4.29937
15/15 - 0s - loss: 0.0432 - val_loss: 4.4692
Epoch 84/300

Epoch 00084: val_loss improved from 4.29937 to 4.23670, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0356 - val_loss: 4.2367
Epoch 85/300

Epoch 00085: val_loss improved from 4.23670 to 4.01103, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0254 - val_loss: 4.0110
Epoch 86/300

Epoch 00086: val_loss improved from 4.01103 to 4.00055, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0268 - val_loss: 4.0005
Epoch 87/300

Epoch 00087: val_loss did not improve from 4.00055
15/15 - 0s - loss: 0.0234 - val_loss: 4.0986
Epoch 88/300

Epoch 00088: val_loss did not improve from 4.00055
15/15 - 0s - loss: 0.0220 - val_loss: 4.0789
Epoch 89/300

Epoch 00089: val_loss improved from 4.00055 to 3.89471, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0206 - val_loss: 3.8947
Epoch 90/300

Epoch 00090: val_loss improved from 3.89471 to 3.76692, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0170 - val_loss: 3.7669
Epoch 91/300

Epoch 00091: val_loss did not improve from 3.76692
15/15 - 0s - loss: 0.0172 - val_loss: 3.7791
Epoch 92/300

Epoch 00092: val_loss did not improve from 3.76692
15/15 - 0s - loss: 0.0144 - val_loss: 3.7978
Epoch 93/300

Epoch 00093: val_loss improved from 3.76692 to 3.74769, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0130 - val_loss: 3.7477
Epoch 94/300

Epoch 00094: val_loss improved from 3.74769 to 3.64670, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 4s - loss: 0.0135 - val_loss: 3.6467
Epoch 95/300

Epoch 00095: val_loss improved from 3.64670 to 3.55652, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0112 - val_loss: 3.5565
Epoch 96/300

Epoch 00096: val_loss improved from 3.55652 to 3.52343, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0105 - val_loss: 3.5234
Epoch 97/300

Epoch 00097: val_loss improved from 3.52343 to 3.48948, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0096 - val_loss: 3.4895
Epoch 98/300

Epoch 00098: val_loss improved from 3.48948 to 3.45226, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0086 - val_loss: 3.4523
Epoch 99/300

Epoch 00099: val_loss improved from 3.45226 to 3.39540, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0082 - val_loss: 3.3954
Epoch 100/300

Epoch 00100: val_loss improved from 3.39540 to 3.33266, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0076 - val_loss: 3.3327
Epoch 101/300

Epoch 00101: val_loss improved from 3.33266 to 3.25965, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0066 - val_loss: 3.2596
Epoch 102/300

Epoch 00102: val_loss improved from 3.25965 to 3.23265, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0068 - val_loss: 3.2326
Epoch 103/300

Epoch 00103: val_loss improved from 3.23265 to 3.21338, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0056 - val_loss: 3.2134
Epoch 104/300

Epoch 00104: val_loss improved from 3.21338 to 3.16282, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0057 - val_loss: 3.1628
Epoch 105/300

Epoch 00105: val_loss improved from 3.16282 to 3.10168, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 4s - loss: 0.0052 - val_loss: 3.1017
Epoch 106/300

Epoch 00106: val_loss improved from 3.10168 to 3.07224, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0044 - val_loss: 3.0722
Epoch 107/300

Epoch 00107: val_loss improved from 3.07224 to 3.02986, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0040 - val_loss: 3.0299
Epoch 108/300

Epoch 00108: val_loss improved from 3.02986 to 2.97536, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0037 - val_loss: 2.9754
Epoch 109/300

Epoch 00109: val_loss improved from 2.97536 to 2.93569, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0036 - val_loss: 2.9357
Epoch 110/300

Epoch 00110: val_loss improved from 2.93569 to 2.90723, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0031 - val_loss: 2.9072
Epoch 111/300

Epoch 00111: val_loss improved from 2.90723 to 2.86337, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0030 - val_loss: 2.8634
Epoch 112/300

Epoch 00112: val_loss improved from 2.86337 to 2.82203, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0029 - val_loss: 2.8220
Epoch 113/300

Epoch 00113: val_loss improved from 2.82203 to 2.76782, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0026 - val_loss: 2.7678
Epoch 114/300

Epoch 00114: val_loss improved from 2.76782 to 2.74753, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0023 - val_loss: 2.7475
Epoch 115/300

Epoch 00115: val_loss improved from 2.74753 to 2.71502, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0021 - val_loss: 2.7150
Epoch 116/300

Epoch 00116: val_loss improved from 2.71502 to 2.65773, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 0.0018 - val_loss: 2.6577
Epoch 117/300

Epoch 00117: val_loss improved from 2.65773 to 2.61991, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0019 - val_loss: 2.6199
Epoch 118/300

Epoch 00118: val_loss improved from 2.61991 to 2.60838, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 4s - loss: 0.0016 - val_loss: 2.6084
Epoch 119/300

Epoch 00119: val_loss improved from 2.60838 to 2.57416, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0016 - val_loss: 2.5742
Epoch 120/300

Epoch 00120: val_loss improved from 2.57416 to 2.52229, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0013 - val_loss: 2.5223
Epoch 121/300

Epoch 00121: val_loss improved from 2.52229 to 2.47822, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 0.0013 - val_loss: 2.4782
Epoch 122/300

Epoch 00122: val_loss improved from 2.47822 to 2.46250, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 0.0013 - val_loss: 2.4625
Epoch 123/300

Epoch 00123: val_loss improved from 2.46250 to 2.43680, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 9.7432e-04 - val_loss: 2.4368
Epoch 124/300

Epoch 00124: val_loss improved from 2.43680 to 2.40146, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 0.0011 - val_loss: 2.4015
Epoch 125/300

Epoch 00125: val_loss improved from 2.40146 to 2.35754, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 8.7009e-04 - val_loss: 2.3575
Epoch 126/300

Epoch 00126: val_loss improved from 2.35754 to 2.32665, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 8.1192e-04 - val_loss: 2.3267
Epoch 127/300

Epoch 00127: val_loss improved from 2.32665 to 2.30133, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 7.4994e-04 - val_loss: 2.3013
Epoch 128/300

Epoch 00128: val_loss improved from 2.30133 to 2.27862, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 7.0305e-04 - val_loss: 2.2786
Epoch 129/300

Epoch 00129: val_loss improved from 2.27862 to 2.24602, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 6.6561e-04 - val_loss: 2.2460
Epoch 130/300

Epoch 00130: val_loss improved from 2.24602 to 2.20500, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 5.7804e-04 - val_loss: 2.2050
Epoch 131/300

Epoch 00131: val_loss improved from 2.20500 to 2.17859, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 5.1019e-04 - val_loss: 2.1786
Epoch 132/300

Epoch 00132: val_loss improved from 2.17859 to 2.15662, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 4.6014e-04 - val_loss: 2.1566
Epoch 133/300

Epoch 00133: val_loss improved from 2.15662 to 2.13241, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 4.7112e-04 - val_loss: 2.1324
Epoch 134/300

Epoch 00134: val_loss improved from 2.13241 to 2.10506, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 4.1962e-04 - val_loss: 2.1051
Epoch 135/300

Epoch 00135: val_loss improved from 2.10506 to 2.06605, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 3.9859e-04 - val_loss: 2.0660
Epoch 136/300

Epoch 00136: val_loss improved from 2.06605 to 2.04385, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 5s - loss: 3.7402e-04 - val_loss: 2.0438
Epoch 137/300

Epoch 00137: val_loss improved from 2.04385 to 2.02568, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 3.0449e-04 - val_loss: 2.0257
Epoch 138/300

Epoch 00138: val_loss improved from 2.02568 to 1.99663, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 2.9863e-04 - val_loss: 1.9966
Epoch 139/300

Epoch 00139: val_loss improved from 1.99663 to 1.96253, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 2.7709e-04 - val_loss: 1.9625
Epoch 140/300

Epoch 00140: val_loss improved from 1.96253 to 1.94052, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 2.4963e-04 - val_loss: 1.9405
Epoch 141/300

Epoch 00141: val_loss improved from 1.94052 to 1.92016, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 2.3207e-04 - val_loss: 1.9202
Epoch 142/300

Epoch 00142: val_loss improved from 1.92016 to 1.89729, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 2.1228e-04 - val_loss: 1.8973
Epoch 143/300

Epoch 00143: val_loss improved from 1.89729 to 1.86946, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 2.0781e-04 - val_loss: 1.8695
Epoch 144/300

Epoch 00144: val_loss improved from 1.86946 to 1.84486, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.7957e-04 - val_loss: 1.8449
Epoch 145/300

Epoch 00145: val_loss improved from 1.84486 to 1.82336, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.6814e-04 - val_loss: 1.8234
Epoch 146/300

Epoch 00146: val_loss improved from 1.82336 to 1.80059, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.5835e-04 - val_loss: 1.8006
Epoch 147/300

Epoch 00147: val_loss improved from 1.80059 to 1.77477, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.4138e-04 - val_loss: 1.7748
Epoch 148/300

Epoch 00148: val_loss improved from 1.77477 to 1.75357, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 6s - loss: 1.3831e-04 - val_loss: 1.7536
Epoch 149/300

Epoch 00149: val_loss improved from 1.75357 to 1.73269, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.4196e-04 - val_loss: 1.7327
Epoch 150/300

Epoch 00150: val_loss improved from 1.73269 to 1.70851, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 1.1585e-04 - val_loss: 1.7085
Epoch 151/300

Epoch 00151: val_loss improved from 1.70851 to 1.68947, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 1.3385e-04 - val_loss: 1.6895
Epoch 152/300

Epoch 00152: val_loss improved from 1.68947 to 1.67071, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.1303e-04 - val_loss: 1.6707
Epoch 153/300

Epoch 00153: val_loss improved from 1.67071 to 1.65068, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.0502e-04 - val_loss: 1.6507
Epoch 154/300

Epoch 00154: val_loss improved from 1.65068 to 1.62769, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 9.5329e-05 - val_loss: 1.6277
Epoch 155/300

Epoch 00155: val_loss improved from 1.62769 to 1.60615, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 7.5752e-05 - val_loss: 1.6061
Epoch 156/300

Epoch 00156: val_loss improved from 1.60615 to 1.58826, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 8.4595e-05 - val_loss: 1.5883
Epoch 157/300

Epoch 00157: val_loss improved from 1.58826 to 1.56770, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 4s - loss: 7.3359e-05 - val_loss: 1.5677
Epoch 158/300

Epoch 00158: val_loss improved from 1.56770 to 1.54875, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 6.9036e-05 - val_loss: 1.5488
Epoch 159/300

Epoch 00159: val_loss improved from 1.54875 to 1.52956, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 5.7402e-05 - val_loss: 1.5296
Epoch 160/300

Epoch 00160: val_loss improved from 1.52956 to 1.50983, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 5.7433e-05 - val_loss: 1.5098
Epoch 161/300

Epoch 00161: val_loss improved from 1.50983 to 1.49138, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 5.4979e-05 - val_loss: 1.4914
Epoch 162/300

Epoch 00162: val_loss improved from 1.49138 to 1.47414, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 4s - loss: 4.8399e-05 - val_loss: 1.4741
Epoch 163/300

Epoch 00163: val_loss improved from 1.47414 to 1.45716, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 5.6138e-05 - val_loss: 1.4572
Epoch 164/300

Epoch 00164: val_loss improved from 1.45716 to 1.43608, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 4.4505e-05 - val_loss: 1.4361
Epoch 165/300

Epoch 00165: val_loss improved from 1.43608 to 1.42020, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 4.2762e-05 - val_loss: 1.4202
Epoch 166/300

Epoch 00166: val_loss improved from 1.42020 to 1.40524, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 3.4213e-05 - val_loss: 1.4052
Epoch 167/300

Epoch 00167: val_loss improved from 1.40524 to 1.38730, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 4.1007e-05 - val_loss: 1.3873
Epoch 168/300

Epoch 00168: val_loss improved from 1.38730 to 1.36693, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 4s - loss: 3.2345e-05 - val_loss: 1.3669
Epoch 169/300

Epoch 00169: val_loss improved from 1.36693 to 1.35078, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 4.4582e-05 - val_loss: 1.3508
Epoch 170/300

Epoch 00170: val_loss improved from 1.35078 to 1.33934, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 4.1083e-05 - val_loss: 1.3393
Epoch 171/300

Epoch 00171: val_loss improved from 1.33934 to 1.32106, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 3.4444e-05 - val_loss: 1.3211
Epoch 172/300

Epoch 00172: val_loss improved from 1.32106 to 1.30220, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 2.6382e-05 - val_loss: 1.3022
Epoch 173/300

Epoch 00173: val_loss improved from 1.30220 to 1.28670, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 2.4347e-05 - val_loss: 1.2867
Epoch 174/300

Epoch 00174: val_loss improved from 1.28670 to 1.27390, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 2.8242e-05 - val_loss: 1.2739
Epoch 175/300

Epoch 00175: val_loss improved from 1.27390 to 1.25754, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 2.4027e-05 - val_loss: 1.2575
Epoch 176/300

Epoch 00176: val_loss improved from 1.25754 to 1.24254, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.8547e-05 - val_loss: 1.2425
Epoch 177/300

Epoch 00177: val_loss improved from 1.24254 to 1.22869, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 2.0611e-05 - val_loss: 1.2287
Epoch 178/300

Epoch 00178: val_loss improved from 1.22869 to 1.21181, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.8920e-05 - val_loss: 1.2118
Epoch 179/300

Epoch 00179: val_loss improved from 1.21181 to 1.19761, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 5s - loss: 2.1315e-05 - val_loss: 1.1976
Epoch 180/300

Epoch 00180: val_loss improved from 1.19761 to 1.18553, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.8388e-05 - val_loss: 1.1855
Epoch 181/300

Epoch 00181: val_loss improved from 1.18553 to 1.16912, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.4500e-05 - val_loss: 1.1691
Epoch 182/300

Epoch 00182: val_loss improved from 1.16912 to 1.15421, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.3619e-05 - val_loss: 1.1542
Epoch 183/300

Epoch 00183: val_loss improved from 1.15421 to 1.14167, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.7523e-05 - val_loss: 1.1417
Epoch 184/300

Epoch 00184: val_loss improved from 1.14167 to 1.12823, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.1048e-05 - val_loss: 1.1282
Epoch 185/300

Epoch 00185: val_loss improved from 1.12823 to 1.11519, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.3430e-05 - val_loss: 1.1152
Epoch 186/300

Epoch 00186: val_loss improved from 1.11519 to 1.10044, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 1.5224e-05 - val_loss: 1.1004
Epoch 187/300

Epoch 00187: val_loss improved from 1.10044 to 1.08830, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 9.2912e-06 - val_loss: 1.0883
Epoch 188/300

Epoch 00188: val_loss improved from 1.08830 to 1.07631, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.3037e-05 - val_loss: 1.0763
Epoch 189/300

Epoch 00189: val_loss improved from 1.07631 to 1.06121, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.0229e-05 - val_loss: 1.0612
Epoch 190/300

Epoch 00190: val_loss improved from 1.06121 to 1.04927, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 8.4591e-06 - val_loss: 1.0493
Epoch 191/300

Epoch 00191: val_loss improved from 1.04927 to 1.03782, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.1252e-05 - val_loss: 1.0378
Epoch 192/300

Epoch 00192: val_loss improved from 1.03782 to 1.02607, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 8.1032e-06 - val_loss: 1.0261
Epoch 193/300

Epoch 00193: val_loss improved from 1.02607 to 1.01224, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 4s - loss: 8.2767e-06 - val_loss: 1.0122
Epoch 194/300

Epoch 00194: val_loss improved from 1.01224 to 0.99934, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.0138e-05 - val_loss: 0.9993
Epoch 195/300

Epoch 00195: val_loss improved from 0.99934 to 0.98921, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 7.4690e-06 - val_loss: 0.9892
Epoch 196/300

Epoch 00196: val_loss improved from 0.98921 to 0.97777, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 9.2314e-06 - val_loss: 0.9778
Epoch 197/300

Epoch 00197: val_loss improved from 0.97777 to 0.96512, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.1288e-05 - val_loss: 0.9651
Epoch 198/300

Epoch 00198: val_loss improved from 0.96512 to 0.95160, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 6.6677e-06 - val_loss: 0.9516
Epoch 199/300

Epoch 00199: val_loss improved from 0.95160 to 0.94225, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.4704e-05 - val_loss: 0.9422
Epoch 200/300

Epoch 00200: val_loss improved from 0.94225 to 0.93336, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.4510e-05 - val_loss: 0.9334
Epoch 201/300

Epoch 00201: val_loss improved from 0.93336 to 0.91841, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.3671e-05 - val_loss: 0.9184
Epoch 202/300

Epoch 00202: val_loss improved from 0.91841 to 0.90743, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 7.2496e-06 - val_loss: 0.9074
Epoch 203/300

Epoch 00203: val_loss improved from 0.90743 to 0.89813, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 4.5861e-06 - val_loss: 0.8981
Epoch 204/300

Epoch 00204: val_loss improved from 0.89813 to 0.88803, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 4.4267e-06 - val_loss: 0.8880
Epoch 205/300

Epoch 00205: val_loss improved from 0.88803 to 0.87628, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 4.7477e-06 - val_loss: 0.8763
Epoch 206/300

Epoch 00206: val_loss improved from 0.87628 to 0.86473, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 3.1949e-06 - val_loss: 0.8647
Epoch 207/300

Epoch 00207: val_loss improved from 0.86473 to 0.85511, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 4.8972e-06 - val_loss: 0.8551
Epoch 208/300

Epoch 00208: val_loss improved from 0.85511 to 0.84554, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 9.5761e-06 - val_loss: 0.8455
Epoch 209/300

Epoch 00209: val_loss improved from 0.84554 to 0.83394, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 4.1353e-06 - val_loss: 0.8339
Epoch 210/300

Epoch 00210: val_loss improved from 0.83394 to 0.82394, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 6.6212e-06 - val_loss: 0.8239
Epoch 211/300

Epoch 00211: val_loss improved from 0.82394 to 0.81509, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.1055e-05 - val_loss: 0.8151
Epoch 212/300

Epoch 00212: val_loss improved from 0.81509 to 0.80455, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 9.5964e-06 - val_loss: 0.8045
Epoch 213/300

Epoch 00213: val_loss improved from 0.80455 to 0.79624, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 2.6543e-06 - val_loss: 0.7962
Epoch 214/300

Epoch 00214: val_loss improved from 0.79624 to 0.78677, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 4s - loss: 1.7338e-05 - val_loss: 0.7868
Epoch 215/300

Epoch 00215: val_loss improved from 0.78677 to 0.77439, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 3.0896e-06 - val_loss: 0.7744
Epoch 216/300

Epoch 00216: val_loss improved from 0.77439 to 0.76626, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 8.8875e-06 - val_loss: 0.7663
Epoch 217/300

Epoch 00217: val_loss improved from 0.76626 to 0.75875, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 2.9052e-06 - val_loss: 0.7587
Epoch 218/300

Epoch 00218: val_loss improved from 0.75875 to 0.74891, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 5.5823e-06 - val_loss: 0.7489
Epoch 219/300

Epoch 00219: val_loss improved from 0.74891 to 0.73881, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 3.0094e-06 - val_loss: 0.7388
Epoch 220/300

Epoch 00220: val_loss improved from 0.73881 to 0.72999, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 2.0671e-06 - val_loss: 0.7300
Epoch 221/300

Epoch 00221: val_loss improved from 0.72999 to 0.72172, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 3.6532e-06 - val_loss: 0.7217
Epoch 222/300

Epoch 00222: val_loss improved from 0.72172 to 0.71324, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 4.0144e-06 - val_loss: 0.7132
Epoch 223/300

Epoch 00223: val_loss improved from 0.71324 to 0.70401, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 2.0528e-06 - val_loss: 0.7040
Epoch 224/300

Epoch 00224: val_loss improved from 0.70401 to 0.69486, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 3.2078e-06 - val_loss: 0.6949
Epoch 225/300

Epoch 00225: val_loss improved from 0.69486 to 0.68763, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.3162e-05 - val_loss: 0.6876
Epoch 226/300

Epoch 00226: val_loss improved from 0.68763 to 0.67804, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.6125e-05 - val_loss: 0.6780
Epoch 227/300

Epoch 00227: val_loss improved from 0.67804 to 0.66806, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 4.2478e-06 - val_loss: 0.6681
Epoch 228/300

Epoch 00228: val_loss improved from 0.66806 to 0.66260, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 6.3703e-06 - val_loss: 0.6626
Epoch 229/300

Epoch 00229: val_loss improved from 0.66260 to 0.65601, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.1698e-05 - val_loss: 0.6560
Epoch 230/300

Epoch 00230: val_loss improved from 0.65601 to 0.64429, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 7.4549e-06 - val_loss: 0.6443
Epoch 231/300

Epoch 00231: val_loss improved from 0.64429 to 0.63566, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 4s - loss: 9.0065e-06 - val_loss: 0.6357
Epoch 232/300

Epoch 00232: val_loss improved from 0.63566 to 0.63094, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 6.8781e-06 - val_loss: 0.6309
Epoch 233/300

Epoch 00233: val_loss improved from 0.63094 to 0.62452, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.2925e-05 - val_loss: 0.6245
Epoch 234/300

Epoch 00234: val_loss improved from 0.62452 to 0.61284, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 9.5984e-06 - val_loss: 0.6128
Epoch 235/300

Epoch 00235: val_loss improved from 0.61284 to 0.60475, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.0124e-05 - val_loss: 0.6048
Epoch 236/300

Epoch 00236: val_loss improved from 0.60475 to 0.60077, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 5.5647e-06 - val_loss: 0.6008
Epoch 237/300

Epoch 00237: val_loss improved from 0.60077 to 0.59412, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 9.9312e-06 - val_loss: 0.5941
Epoch 238/300

Epoch 00238: val_loss improved from 0.59412 to 0.58297, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 4s - loss: 7.5537e-06 - val_loss: 0.5830
Epoch 239/300

Epoch 00239: val_loss improved from 0.58297 to 0.57706, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 9.2127e-06 - val_loss: 0.5771
Epoch 240/300

Epoch 00240: val_loss improved from 0.57706 to 0.57265, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.8219e-06 - val_loss: 0.5726
Epoch 241/300

Epoch 00241: val_loss improved from 0.57265 to 0.56378, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.5450e-05 - val_loss: 0.5638
Epoch 242/300

Epoch 00242: val_loss improved from 0.56378 to 0.55375, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 3.8686e-06 - val_loss: 0.5538
Epoch 243/300

Epoch 00243: val_loss improved from 0.55375 to 0.54866, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.2086e-05 - val_loss: 0.5487
Epoch 244/300

Epoch 00244: val_loss improved from 0.54866 to 0.54380, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 2.5364e-06 - val_loss: 0.5438
Epoch 245/300

Epoch 00245: val_loss improved from 0.54380 to 0.53548, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 8.4091e-06 - val_loss: 0.5355
Epoch 246/300

Epoch 00246: val_loss improved from 0.53548 to 0.52684, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.3088e-05 - val_loss: 0.5268
Epoch 247/300

Epoch 00247: val_loss improved from 0.52684 to 0.52336, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 5.7120e-06 - val_loss: 0.5234
Epoch 248/300

Epoch 00248: val_loss improved from 0.52336 to 0.51738, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 6.9408e-06 - val_loss: 0.5174
Epoch 249/300

Epoch 00249: val_loss improved from 0.51738 to 0.50782, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 8.5529e-06 - val_loss: 0.5078
Epoch 250/300

Epoch 00250: val_loss improved from 0.50782 to 0.50241, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 5.2019e-06 - val_loss: 0.5024
Epoch 251/300

Epoch 00251: val_loss improved from 0.50241 to 0.49827, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.0500e-05 - val_loss: 0.4983
Epoch 252/300

Epoch 00252: val_loss improved from 0.49827 to 0.48981, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 6.3881e-06 - val_loss: 0.4898
Epoch 253/300

Epoch 00253: val_loss improved from 0.48981 to 0.48401, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 2.6327e-06 - val_loss: 0.4840
Epoch 254/300

Epoch 00254: val_loss improved from 0.48401 to 0.47905, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 4s - loss: 5.7614e-06 - val_loss: 0.4790
Epoch 255/300

Epoch 00255: val_loss improved from 0.47905 to 0.47329, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 8.2275e-06 - val_loss: 0.4733
Epoch 256/300

Epoch 00256: val_loss improved from 0.47329 to 0.46652, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 3.9049e-06 - val_loss: 0.4665
Epoch 257/300

Epoch 00257: val_loss improved from 0.46652 to 0.46009, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.0014e-06 - val_loss: 0.4601
Epoch 258/300

Epoch 00258: val_loss improved from 0.46009 to 0.45481, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 4.4620e-06 - val_loss: 0.4548
Epoch 259/300

Epoch 00259: val_loss improved from 0.45481 to 0.44869, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 8.1202e-06 - val_loss: 0.4487
Epoch 260/300

Epoch 00260: val_loss improved from 0.44869 to 0.44427, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 8.3717e-07 - val_loss: 0.4443
Epoch 261/300

Epoch 00261: val_loss improved from 0.44427 to 0.43812, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 3.8710e-06 - val_loss: 0.4381
Epoch 262/300

Epoch 00262: val_loss improved from 0.43812 to 0.43214, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 1.1020e-06 - val_loss: 0.4321
Epoch 263/300

Epoch 00263: val_loss improved from 0.43214 to 0.42724, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 8.0041e-06 - val_loss: 0.4272
Epoch 264/300

Epoch 00264: val_loss improved from 0.42724 to 0.42289, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 4s - loss: 1.8069e-06 - val_loss: 0.4229
Epoch 265/300

Epoch 00265: val_loss improved from 0.42289 to 0.41588, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 2.6719e-06 - val_loss: 0.4159
Epoch 266/300

Epoch 00266: val_loss improved from 0.41588 to 0.41050, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 2.2042e-06 - val_loss: 0.4105
Epoch 267/300

Epoch 00267: val_loss improved from 0.41050 to 0.40695, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 4.0226e-06 - val_loss: 0.4069
Epoch 268/300

Epoch 00268: val_loss improved from 0.40695 to 0.40210, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 7.5053e-06 - val_loss: 0.4021
Epoch 269/300

Epoch 00269: val_loss improved from 0.40210 to 0.39590, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 2.6000e-06 - val_loss: 0.3959
Epoch 270/300

Epoch 00270: val_loss improved from 0.39590 to 0.39032, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 3.0445e-06 - val_loss: 0.3903
Epoch 271/300

Epoch 00271: val_loss improved from 0.39032 to 0.38686, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.8467e-06 - val_loss: 0.3869
Epoch 272/300

Epoch 00272: val_loss improved from 0.38686 to 0.38199, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 4.2619e-06 - val_loss: 0.3820
Epoch 273/300

Epoch 00273: val_loss improved from 0.38199 to 0.37530, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 4s - loss: 2.5911e-06 - val_loss: 0.3753
Epoch 274/300

Epoch 00274: val_loss improved from 0.37530 to 0.37140, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.0120e-05 - val_loss: 0.3714
Epoch 275/300

Epoch 00275: val_loss improved from 0.37140 to 0.36764, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.9101e-06 - val_loss: 0.3676
Epoch 276/300

Epoch 00276: val_loss improved from 0.36764 to 0.36316, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.1446e-06 - val_loss: 0.3632
Epoch 277/300

Epoch 00277: val_loss improved from 0.36316 to 0.35818, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 5.8311e-06 - val_loss: 0.3582
Epoch 278/300

Epoch 00278: val_loss improved from 0.35818 to 0.35327, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 2.7856e-05 - val_loss: 0.3533
Epoch 279/300

Epoch 00279: val_loss improved from 0.35327 to 0.35150, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.2425e-06 - val_loss: 0.3515
Epoch 280/300

Epoch 00280: val_loss improved from 0.35150 to 0.34557, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.1103e-05 - val_loss: 0.3456
Epoch 281/300

Epoch 00281: val_loss improved from 0.34557 to 0.33991, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 4.1193e-06 - val_loss: 0.3399
Epoch 282/300

Epoch 00282: val_loss improved from 0.33991 to 0.33682, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 8.8859e-06 - val_loss: 0.3368
Epoch 283/300

Epoch 00283: val_loss improved from 0.33682 to 0.33412, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.1497e-05 - val_loss: 0.3341
Epoch 284/300

Epoch 00284: val_loss improved from 0.33412 to 0.32800, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 4s - loss: 8.6425e-06 - val_loss: 0.3280
Epoch 285/300

Epoch 00285: val_loss improved from 0.32800 to 0.32500, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 8.1481e-06 - val_loss: 0.3250
Epoch 286/300

Epoch 00286: val_loss improved from 0.32500 to 0.32232, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 4.5941e-06 - val_loss: 0.3223
Epoch 287/300

Epoch 00287: val_loss improved from 0.32232 to 0.31712, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 8.3994e-06 - val_loss: 0.3171
Epoch 288/300

Epoch 00288: val_loss improved from 0.31712 to 0.31190, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 4s - loss: 1.3092e-06 - val_loss: 0.3119
Epoch 289/300

Epoch 00289: val_loss improved from 0.31190 to 0.30931, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 8.2432e-06 - val_loss: 0.3093
Epoch 290/300

Epoch 00290: val_loss improved from 0.30931 to 0.30689, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 3s - loss: 3.8176e-06 - val_loss: 0.3069
Epoch 291/300

Epoch 00291: val_loss improved from 0.30689 to 0.30126, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 6.7768e-06 - val_loss: 0.3013
Epoch 292/300

Epoch 00292: val_loss improved from 0.30126 to 0.29754, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 2.5712e-05 - val_loss: 0.2975
Epoch 293/300

Epoch 00293: val_loss improved from 0.29754 to 0.29749, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 4s - loss: 2.1946e-05 - val_loss: 0.2975
Epoch 294/300

Epoch 00294: val_loss improved from 0.29749 to 0.29082, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.3361e-05 - val_loss: 0.2908
Epoch 295/300

Epoch 00295: val_loss improved from 0.29082 to 0.28676, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 8.7508e-06 - val_loss: 0.2868
Epoch 296/300

Epoch 00296: val_loss improved from 0.28676 to 0.28640, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 9.6449e-06 - val_loss: 0.2864
Epoch 297/300

Epoch 00297: val_loss improved from 0.28640 to 0.28329, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 9.2185e-06 - val_loss: 0.2833
Epoch 298/300

Epoch 00298: val_loss improved from 0.28329 to 0.27754, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 2s - loss: 1.2880e-05 - val_loss: 0.2775
Epoch 299/300

Epoch 00299: val_loss improved from 0.27754 to 0.27538, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 5.7200e-06 - val_loss: 0.2754
Epoch 300/300

Epoch 00300: val_loss improved from 0.27538 to 0.27289, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0_20191029-161433_best_model.h5
15/15 - 1s - loss: 1.6900e-06 - val_loss: 0.2729
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      51.394820
Mean squared error (MSE):       7495.377324
Root mean squared error (RMSE): 86.575847
R square (R^2):                 -1.277421
[ 1105.39054457    35.06748786   499.4731212  28341.57814248]
##############################################
   Model8_filters_1_dense_0_denseSize_64_Dropout_0.4_20191029-162216
##############################################
Model: "model_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_8 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 567, 756, 16)      448       
_________________________________________________________________
activation_7 (Activation)    (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_7 (Batch (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 283, 378, 16)      0         
_________________________________________________________________
flatten_7 (Flatten)          (None, 1711584)           0         
_________________________________________________________________
dense_7 (Dense)              (None, 4)                 6846340   
=================================================================
Total params: 6,846,852
Trainable params: 6,846,820
Non-trainable params: 32
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/300
2019-10-29 16:22:17.928006: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 16:22:18.066125: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 72 kernel records, 11 memcpy records.
WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.265789). Check your callbacks.

Epoch 00001: val_loss improved from inf to 2698.24561, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0.4_20191029-162216_best_model.h5
15/15 - 3s - loss: 15265.2429 - val_loss: 2698.2456
Epoch 2/300

Epoch 00002: val_loss did not improve from 2698.24561
15/15 - 2s - loss: 3159.2417 - val_loss: 24255.3867
Epoch 3/300

Epoch 00003: val_loss did not improve from 2698.24561
15/15 - 1s - loss: 12919.8167 - val_loss: 6923.7788
Epoch 4/300

Epoch 00004: val_loss did not improve from 2698.24561
15/15 - 2s - loss: 2371.6714 - val_loss: 3095.8752
Epoch 5/300

Epoch 00005: val_loss did not improve from 2698.24561
15/15 - 2s - loss: 4076.2123 - val_loss: 9061.8359
Epoch 6/300

Epoch 00006: val_loss improved from 2698.24561 to 1835.38599, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0.4_20191029-162216_best_model.h5
15/15 - 3s - loss: 4447.3978 - val_loss: 1835.3860
Epoch 7/300

Epoch 00007: val_loss improved from 1835.38599 to 426.91724, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0.4_20191029-162216_best_model.h5
15/15 - 1s - loss: 457.5593 - val_loss: 426.9172
Epoch 8/300

Epoch 00008: val_loss did not improve from 426.91724
15/15 - 0s - loss: 1213.3660 - val_loss: 1534.5654
Epoch 9/300

Epoch 00009: val_loss improved from 426.91724 to 42.48204, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0.4_20191029-162216_best_model.h5
15/15 - 2s - loss: 2020.4520 - val_loss: 42.4820
Epoch 10/300

Epoch 00010: val_loss did not improve from 42.48204
15/15 - 0s - loss: 584.1853 - val_loss: 3145.2839
Epoch 11/300

Epoch 00011: val_loss did not improve from 42.48204
15/15 - 1s - loss: 232.1408 - val_loss: 10047.4287
Epoch 12/300

Epoch 00012: val_loss did not improve from 42.48204
15/15 - 0s - loss: 1023.0908 - val_loss: 10288.5020
Epoch 13/300

Epoch 00013: val_loss did not improve from 42.48204
15/15 - 0s - loss: 700.6028 - val_loss: 4722.1392
Epoch 14/300

Epoch 00014: val_loss did not improve from 42.48204
15/15 - 1s - loss: 97.1512 - val_loss: 996.4402
Epoch 15/300

Epoch 00015: val_loss did not improve from 42.48204
15/15 - 0s - loss: 324.7411 - val_loss: 335.6262
Epoch 16/300

Epoch 00016: val_loss did not improve from 42.48204
15/15 - 1s - loss: 500.2269 - val_loss: 1089.8130
Epoch 17/300

Epoch 00017: val_loss did not improve from 42.48204
15/15 - 1s - loss: 139.1319 - val_loss: 3756.4727
Epoch 18/300

Epoch 00018: val_loss did not improve from 42.48204
15/15 - 2s - loss: 85.9273 - val_loss: 6482.8154
Epoch 19/300

Epoch 00019: val_loss did not improve from 42.48204
15/15 - 2s - loss: 273.7816 - val_loss: 5931.7695
Epoch 20/300

Epoch 00020: val_loss did not improve from 42.48204
15/15 - 0s - loss: 141.0010 - val_loss: 3324.6814
Epoch 21/300

Epoch 00021: val_loss did not improve from 42.48204
15/15 - 0s - loss: 14.9421 - val_loss: 1570.1892
Epoch 22/300

Epoch 00022: val_loss did not improve from 42.48204
15/15 - 1s - loss: 120.1992 - val_loss: 1317.3169
Epoch 23/300

Epoch 00023: val_loss did not improve from 42.48204
15/15 - 1s - loss: 114.1219 - val_loss: 2182.2256
Epoch 24/300

Epoch 00024: val_loss did not improve from 42.48204
15/15 - 0s - loss: 17.9655 - val_loss: 3648.2368
Epoch 25/300

Epoch 00025: val_loss did not improve from 42.48204
15/15 - 1s - loss: 55.5289 - val_loss: 4227.8149
Epoch 26/300

Epoch 00026: val_loss did not improve from 42.48204
15/15 - 0s - loss: 72.9429 - val_loss: 3289.8169
Epoch 27/300

Epoch 00027: val_loss did not improve from 42.48204
15/15 - 0s - loss: 14.1510 - val_loss: 2142.8242
Epoch 28/300

Epoch 00028: val_loss did not improve from 42.48204
15/15 - 0s - loss: 26.5148 - val_loss: 1681.2087
Epoch 29/300

Epoch 00029: val_loss did not improve from 42.48204
15/15 - 0s - loss: 41.2938 - val_loss: 2011.9274
Epoch 30/300

Epoch 00030: val_loss did not improve from 42.48204
15/15 - 0s - loss: 10.8242 - val_loss: 2713.7280
Epoch 31/300

Epoch 00031: val_loss did not improve from 42.48204
15/15 - 2s - loss: 13.2107 - val_loss: 3029.8381
Epoch 32/300

Epoch 00032: val_loss did not improve from 42.48204
15/15 - 0s - loss: 22.4907 - val_loss: 2651.3533
Epoch 33/300

Epoch 00033: val_loss did not improve from 42.48204
15/15 - 0s - loss: 4.7986 - val_loss: 2051.5605
Epoch 34/300

Epoch 00034: val_loss did not improve from 42.48204
15/15 - 0s - loss: 8.7064 - val_loss: 1766.6154
Epoch 35/300

Epoch 00035: val_loss did not improve from 42.48204
15/15 - 0s - loss: 13.5100 - val_loss: 1948.0190
Epoch 36/300

Epoch 00036: val_loss did not improve from 42.48204
15/15 - 2s - loss: 2.2310 - val_loss: 2284.7334
Epoch 37/300

Epoch 00037: val_loss did not improve from 42.48204
15/15 - 2s - loss: 5.4376 - val_loss: 2421.1650
Epoch 38/300

Epoch 00038: val_loss did not improve from 42.48204
15/15 - 0s - loss: 7.5064 - val_loss: 2173.7468
Epoch 39/300

Epoch 00039: val_loss did not improve from 42.48204
15/15 - 2s - loss: 1.8728 - val_loss: 1832.4702
Epoch 00039: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      816.783501
Mean squared error (MSE):       1154324.216470
Root mean squared error (RMSE): 1074.394814
R square (R^2):                 -1282.145053
[1.01525141e+06 2.39895598e+03 1.25111217e+05 3.47453528e+06]
##############################################
   Model8_filters_1_dense_0_denseSize_64_Dropout_0.6_20191029-162258
##############################################
Model: "model_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_9 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 567, 756, 16)      448       
_________________________________________________________________
activation_8 (Activation)    (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_8 (Batch (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 283, 378, 16)      0         
_________________________________________________________________
flatten_8 (Flatten)          (None, 1711584)           0         
_________________________________________________________________
dense_8 (Dense)              (None, 4)                 6846340   
=================================================================
Total params: 6,846,852
Trainable params: 6,846,820
Non-trainable params: 32
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/300
2019-10-29 16:23:00.232300: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 16:23:00.360574: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 72 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 4624.45068, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0.6_20191029-162258_best_model.h5
15/15 - 3s - loss: 11173.8894 - val_loss: 4624.4507
Epoch 2/300

Epoch 00002: val_loss did not improve from 4624.45068
15/15 - 2s - loss: 3068.3338 - val_loss: 35932.5625
Epoch 3/300

Epoch 00003: val_loss did not improve from 4624.45068
15/15 - 2s - loss: 10230.7512 - val_loss: 9437.7949
Epoch 4/300

Epoch 00004: val_loss improved from 4624.45068 to 3536.83716, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0.6_20191029-162258_best_model.h5
15/15 - 2s - loss: 1970.5918 - val_loss: 3536.8372
Epoch 5/300

Epoch 00005: val_loss did not improve from 3536.83716
15/15 - 2s - loss: 1892.6915 - val_loss: 15566.0898
Epoch 6/300

Epoch 00006: val_loss did not improve from 3536.83716
15/15 - 1s - loss: 4016.9356 - val_loss: 7115.9551
Epoch 7/300

Epoch 00007: val_loss improved from 3536.83716 to 5.61205, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0.6_20191029-162258_best_model.h5
15/15 - 2s - loss: 1270.3212 - val_loss: 5.6120
Epoch 8/300

Epoch 00008: val_loss did not improve from 5.61205
15/15 - 0s - loss: 210.8304 - val_loss: 3529.6406
Epoch 9/300

Epoch 00009: val_loss did not improve from 5.61205
15/15 - 0s - loss: 1548.9450 - val_loss: 4562.1318
Epoch 10/300

Epoch 00010: val_loss did not improve from 5.61205
15/15 - 1s - loss: 1413.0329 - val_loss: 972.0138
Epoch 11/300

Epoch 00011: val_loss did not improve from 5.61205
15/15 - 0s - loss: 243.8278 - val_loss: 301.7957
Epoch 12/300

Epoch 00012: val_loss did not improve from 5.61205
15/15 - 1s - loss: 188.6039 - val_loss: 2293.7144
Epoch 13/300

Epoch 00013: val_loss did not improve from 5.61205
15/15 - 1s - loss: 740.4627 - val_loss: 2278.8945
Epoch 14/300

Epoch 00014: val_loss did not improve from 5.61205
15/15 - 1s - loss: 578.7326 - val_loss: 545.7390
Epoch 15/300

Epoch 00015: val_loss did not improve from 5.61205
15/15 - 0s - loss: 89.3157 - val_loss: 40.4243
Epoch 16/300

Epoch 00016: val_loss did not improve from 5.61205
15/15 - 0s - loss: 99.3969 - val_loss: 601.0791
Epoch 17/300

Epoch 00017: val_loss did not improve from 5.61205
15/15 - 2s - loss: 327.8987 - val_loss: 578.3160
Epoch 18/300

Epoch 00018: val_loss did not improve from 5.61205
15/15 - 1s - loss: 241.1935 - val_loss: 88.2261
Epoch 19/300

Epoch 00019: val_loss did not improve from 5.61205
15/15 - 1s - loss: 31.5647 - val_loss: 74.2118
Epoch 20/300

Epoch 00020: val_loss did not improve from 5.61205
15/15 - 1s - loss: 50.9768 - val_loss: 366.7054
Epoch 21/300

Epoch 00021: val_loss did not improve from 5.61205
15/15 - 3s - loss: 148.3256 - val_loss: 314.1143
Epoch 22/300

Epoch 00022: val_loss did not improve from 5.61205
15/15 - 1s - loss: 97.7870 - val_loss: 56.3970
Epoch 23/300

Epoch 00023: val_loss did not improve from 5.61205
15/15 - 1s - loss: 9.1179 - val_loss: 15.5658
Epoch 24/300

Epoch 00024: val_loss did not improve from 5.61205
15/15 - 1s - loss: 31.1668 - val_loss: 97.0769
Epoch 25/300

Epoch 00025: val_loss did not improve from 5.61205
15/15 - 0s - loss: 69.3513 - val_loss: 62.7593
Epoch 26/300

Epoch 00026: val_loss improved from 5.61205 to 1.10790, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0.6_20191029-162258_best_model.h5
15/15 - 1s - loss: 35.3747 - val_loss: 1.1079
Epoch 27/300

Epoch 00027: val_loss did not improve from 1.10790
15/15 - 0s - loss: 2.9310 - val_loss: 40.9911
Epoch 28/300

Epoch 00028: val_loss did not improve from 1.10790
15/15 - 1s - loss: 21.0240 - val_loss: 79.8700
Epoch 29/300

Epoch 00029: val_loss did not improve from 1.10790
15/15 - 2s - loss: 31.4650 - val_loss: 39.7759
Epoch 30/300

Epoch 00030: val_loss did not improve from 1.10790
15/15 - 2s - loss: 9.8265 - val_loss: 1.3690
Epoch 31/300

Epoch 00031: val_loss did not improve from 1.10790
15/15 - 2s - loss: 2.1123 - val_loss: 9.2996
Epoch 32/300

Epoch 00032: val_loss did not improve from 1.10790
15/15 - 2s - loss: 14.2904 - val_loss: 12.8846
Epoch 33/300

Epoch 00033: val_loss improved from 1.10790 to 1.00556, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0.6_20191029-162258_best_model.h5
15/15 - 2s - loss: 12.5138 - val_loss: 1.0056
Epoch 34/300

Epoch 00034: val_loss did not improve from 1.00556
15/15 - 2s - loss: 1.6414 - val_loss: 7.8001
Epoch 35/300

Epoch 00035: val_loss did not improve from 1.00556
15/15 - 2s - loss: 3.7770 - val_loss: 21.2925
Epoch 36/300

Epoch 00036: val_loss did not improve from 1.00556
15/15 - 2s - loss: 7.8634 - val_loss: 14.0214
Epoch 37/300

Epoch 00037: val_loss did not improve from 1.00556
15/15 - 2s - loss: 3.2382 - val_loss: 1.9909
Epoch 38/300

Epoch 00038: val_loss improved from 1.00556 to 0.75637, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0.6_20191029-162258_best_model.h5
15/15 - 2s - loss: 0.9287 - val_loss: 0.7564
Epoch 39/300

Epoch 00039: val_loss did not improve from 0.75637
15/15 - 1s - loss: 3.4809 - val_loss: 1.1822
Epoch 40/300

Epoch 00040: val_loss improved from 0.75637 to 0.44599, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0.6_20191029-162258_best_model.h5
15/15 - 3s - loss: 2.9442 - val_loss: 0.4460
Epoch 41/300

Epoch 00041: val_loss did not improve from 0.44599
15/15 - 0s - loss: 0.4388 - val_loss: 4.5433
Epoch 42/300

Epoch 00042: val_loss did not improve from 0.44599
15/15 - 2s - loss: 1.1836 - val_loss: 7.7825
Epoch 43/300

Epoch 00043: val_loss did not improve from 0.44599
15/15 - 2s - loss: 1.9712 - val_loss: 4.7462
Epoch 44/300

Epoch 00044: val_loss did not improve from 0.44599
15/15 - 2s - loss: 0.6399 - val_loss: 1.0832
Epoch 45/300

Epoch 00045: val_loss improved from 0.44599 to 0.25782, saving model to Models\Model8_filters_1_dense_0_denseSize_64_Dropout_0.6_20191029-162258_best_model.h5
15/15 - 2s - loss: 0.2960 - val_loss: 0.2578
Epoch 46/300

Epoch 00046: val_loss did not improve from 0.25782
15/15 - 1s - loss: 1.0331 - val_loss: 0.3193
Epoch 47/300

Epoch 00047: val_loss did not improve from 0.25782
15/15 - 0s - loss: 0.5951 - val_loss: 1.3673
Epoch 48/300

Epoch 00048: val_loss did not improve from 0.25782
15/15 - 0s - loss: 0.2070 - val_loss: 3.3942
Epoch 49/300

Epoch 00049: val_loss did not improve from 0.25782
15/15 - 1s - loss: 0.5224 - val_loss: 3.6384
Epoch 50/300

Epoch 00050: val_loss did not improve from 0.25782
15/15 - 1s - loss: 0.4549 - val_loss: 2.1807
Epoch 51/300

Epoch 00051: val_loss did not improve from 0.25782
15/15 - 0s - loss: 0.1736 - val_loss: 0.8817
Epoch 52/300

Epoch 00052: val_loss did not improve from 0.25782
15/15 - 1s - loss: 0.3234 - val_loss: 0.6145
Epoch 53/300

Epoch 00053: val_loss did not improve from 0.25782
15/15 - 0s - loss: 0.3417 - val_loss: 1.1025
Epoch 54/300

Epoch 00054: val_loss did not improve from 0.25782
15/15 - 0s - loss: 0.0997 - val_loss: 2.0748
Epoch 55/300

Epoch 00055: val_loss did not improve from 0.25782
15/15 - 2s - loss: 0.1518 - val_loss: 2.6533
Epoch 56/300

Epoch 00056: val_loss did not improve from 0.25782
15/15 - 1s - loss: 0.2506 - val_loss: 2.1900
Epoch 57/300

Epoch 00057: val_loss did not improve from 0.25782
15/15 - 1s - loss: 0.1451 - val_loss: 1.4253
Epoch 58/300

Epoch 00058: val_loss did not improve from 0.25782
15/15 - 1s - loss: 0.0934 - val_loss: 1.1018
Epoch 59/300

Epoch 00059: val_loss did not improve from 0.25782
15/15 - 1s - loss: 0.1386 - val_loss: 1.1973
Epoch 60/300

Epoch 00060: val_loss did not improve from 0.25782
15/15 - 0s - loss: 0.1139 - val_loss: 1.5465
Epoch 61/300

Epoch 00061: val_loss did not improve from 0.25782
15/15 - 0s - loss: 0.0768 - val_loss: 1.7721
Epoch 62/300

Epoch 00062: val_loss did not improve from 0.25782
15/15 - 1s - loss: 0.0891 - val_loss: 1.8276
Epoch 63/300

Epoch 00063: val_loss did not improve from 0.25782
15/15 - 0s - loss: 0.0869 - val_loss: 1.6548
Epoch 64/300

Epoch 00064: val_loss did not improve from 0.25782
15/15 - 0s - loss: 0.0709 - val_loss: 1.4359
Epoch 65/300

Epoch 00065: val_loss did not improve from 0.25782
15/15 - 0s - loss: 0.0804 - val_loss: 1.3142
Epoch 66/300

Epoch 00066: val_loss did not improve from 0.25782
15/15 - 2s - loss: 0.0771 - val_loss: 1.4413
Epoch 67/300

Epoch 00067: val_loss did not improve from 0.25782
15/15 - 0s - loss: 0.0627 - val_loss: 1.6196
Epoch 68/300

Epoch 00068: val_loss did not improve from 0.25782
15/15 - 1s - loss: 0.0802 - val_loss: 1.7826
Epoch 69/300

Epoch 00069: val_loss did not improve from 0.25782
15/15 - 0s - loss: 0.0709 - val_loss: 1.5875
Epoch 70/300

Epoch 00070: val_loss did not improve from 0.25782
15/15 - 0s - loss: 0.0551 - val_loss: 1.4230
Epoch 71/300

Epoch 00071: val_loss did not improve from 0.25782
15/15 - 0s - loss: 0.0566 - val_loss: 1.3419
Epoch 72/300

Epoch 00072: val_loss did not improve from 0.25782
15/15 - 0s - loss: 0.0651 - val_loss: 1.3624
Epoch 73/300

Epoch 00073: val_loss did not improve from 0.25782
15/15 - 0s - loss: 0.0564 - val_loss: 1.5792
Epoch 74/300

Epoch 00074: val_loss did not improve from 0.25782
15/15 - 1s - loss: 0.0533 - val_loss: 1.6783
Epoch 75/300

Epoch 00075: val_loss did not improve from 0.25782
15/15 - 0s - loss: 0.0541 - val_loss: 1.5560
Epoch 00075: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      78.838416
Mean squared error (MSE):       23015.074145
Root mean squared error (RMSE): 151.707199
R square (R^2):                 -3.629201
[2.18217594e+03 3.72958133e+00 1.08382815e+03 8.87905629e+04]
##############################################
   Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427
##############################################
16
Model: "model_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_10 (InputLayer)        [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 567, 756, 16)      448       
_________________________________________________________________
activation_9 (Activation)    (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_9 (Batch (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 283, 378, 16)      0         
_________________________________________________________________
flatten_9 (Flatten)          (None, 1711584)           0         
_________________________________________________________________
dense_9 (Dense)              (None, 16)                27385360  
_________________________________________________________________
activation_10 (Activation)   (None, 16)                0         
_________________________________________________________________
dropout (Dropout)            (None, 16)                0         
_________________________________________________________________
dense_10 (Dense)             (None, 4)                 68        
=================================================================
Total params: 27,385,940
Trainable params: 27,385,908
Non-trainable params: 32
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/300
2019-10-29 16:24:29.089650: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 16:24:29.233655: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 86 kernel records, 11 memcpy records.
WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.612363). Check your callbacks.

Epoch 00001: val_loss improved from inf to 2453.48657, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 7s - loss: 5742.9291 - val_loss: 2453.4866
Epoch 2/300

Epoch 00002: val_loss improved from 2453.48657 to 143.71986, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 1799.9722 - val_loss: 143.7199
Epoch 3/300

Epoch 00003: val_loss improved from 143.71986 to 0.34854, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 14.7535 - val_loss: 0.3485
Epoch 4/300

Epoch 00004: val_loss improved from 0.34854 to 0.34684, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3451 - val_loss: 0.3468
Epoch 5/300

Epoch 00005: val_loss improved from 0.34684 to 0.34575, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3454 - val_loss: 0.3458
Epoch 6/300

Epoch 00006: val_loss improved from 0.34575 to 0.34507, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3456 - val_loss: 0.3451
Epoch 7/300

Epoch 00007: val_loss improved from 0.34507 to 0.34461, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3458 - val_loss: 0.3446
Epoch 8/300

Epoch 00008: val_loss improved from 0.34461 to 0.34430, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3459 - val_loss: 0.3443
Epoch 9/300

Epoch 00009: val_loss improved from 0.34430 to 0.34409, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3460 - val_loss: 0.3441
Epoch 10/300

Epoch 00010: val_loss improved from 0.34409 to 0.34393, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3460 - val_loss: 0.3439
Epoch 11/300

Epoch 00011: val_loss improved from 0.34393 to 0.34383, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3460 - val_loss: 0.3438
Epoch 12/300

Epoch 00012: val_loss improved from 0.34383 to 0.34377, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3461 - val_loss: 0.3438
Epoch 13/300

Epoch 00013: val_loss improved from 0.34377 to 0.34338, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3461 - val_loss: 0.3434
Epoch 14/300

Epoch 00014: val_loss improved from 0.34338 to 0.34334, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3460 - val_loss: 0.3433
Epoch 15/300

Epoch 00015: val_loss improved from 0.34334 to 0.34330, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3460 - val_loss: 0.3433
Epoch 16/300

Epoch 00016: val_loss improved from 0.34330 to 0.34325, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3460 - val_loss: 0.3432
Epoch 17/300

Epoch 00017: val_loss improved from 0.34325 to 0.34319, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3459 - val_loss: 0.3432
Epoch 18/300

Epoch 00018: val_loss improved from 0.34319 to 0.34313, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3459 - val_loss: 0.3431
Epoch 19/300

Epoch 00019: val_loss improved from 0.34313 to 0.34306, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3458 - val_loss: 0.3431
Epoch 20/300

Epoch 00020: val_loss improved from 0.34306 to 0.34299, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3457 - val_loss: 0.3430
Epoch 21/300

Epoch 00021: val_loss improved from 0.34299 to 0.34292, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3456 - val_loss: 0.3429
Epoch 22/300

Epoch 00022: val_loss improved from 0.34292 to 0.34285, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3456 - val_loss: 0.3428
Epoch 23/300

Epoch 00023: val_loss improved from 0.34285 to 0.34277, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3455 - val_loss: 0.3428
Epoch 24/300

Epoch 00024: val_loss improved from 0.34277 to 0.34268, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3454 - val_loss: 0.3427
Epoch 25/300

Epoch 00025: val_loss improved from 0.34268 to 0.34260, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3453 - val_loss: 0.3426
Epoch 26/300

Epoch 00026: val_loss improved from 0.34260 to 0.34252, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3452 - val_loss: 0.3425
Epoch 27/300

Epoch 00027: val_loss improved from 0.34252 to 0.34243, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 7s - loss: 0.3451 - val_loss: 0.3424
Epoch 28/300

Epoch 00028: val_loss improved from 0.34243 to 0.34234, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 8s - loss: 0.3450 - val_loss: 0.3423
Epoch 29/300

Epoch 00029: val_loss improved from 0.34234 to 0.34224, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3449 - val_loss: 0.3422
Epoch 30/300

Epoch 00030: val_loss improved from 0.34224 to 0.34215, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3448 - val_loss: 0.3422
Epoch 31/300

Epoch 00031: val_loss improved from 0.34215 to 0.34205, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3446 - val_loss: 0.3421
Epoch 32/300

Epoch 00032: val_loss improved from 0.34205 to 0.34196, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3445 - val_loss: 0.3420
Epoch 33/300

Epoch 00033: val_loss improved from 0.34196 to 0.34186, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3444 - val_loss: 0.3419
Epoch 34/300

Epoch 00034: val_loss improved from 0.34186 to 0.34176, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3443 - val_loss: 0.3418
Epoch 35/300

Epoch 00035: val_loss improved from 0.34176 to 0.34165, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3442 - val_loss: 0.3417
Epoch 36/300

Epoch 00036: val_loss improved from 0.34165 to 0.34155, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3440 - val_loss: 0.3415
Epoch 37/300

Epoch 00037: val_loss improved from 0.34155 to 0.34144, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3439 - val_loss: 0.3414
Epoch 38/300

Epoch 00038: val_loss improved from 0.34144 to 0.34134, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3438 - val_loss: 0.3413
Epoch 39/300

Epoch 00039: val_loss improved from 0.34134 to 0.34123, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3437 - val_loss: 0.3412
Epoch 40/300

Epoch 00040: val_loss improved from 0.34123 to 0.34112, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3435 - val_loss: 0.3411
Epoch 41/300

Epoch 00041: val_loss improved from 0.34112 to 0.34101, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3434 - val_loss: 0.3410
Epoch 42/300

Epoch 00042: val_loss improved from 0.34101 to 0.34089, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3433 - val_loss: 0.3409
Epoch 43/300

Epoch 00043: val_loss improved from 0.34089 to 0.34078, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 6s - loss: 0.3431 - val_loss: 0.3408
Epoch 44/300

Epoch 00044: val_loss improved from 0.34078 to 0.34066, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 8s - loss: 0.3430 - val_loss: 0.3407
Epoch 45/300

Epoch 00045: val_loss improved from 0.34066 to 0.34055, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3429 - val_loss: 0.3405
Epoch 46/300

Epoch 00046: val_loss improved from 0.34055 to 0.34043, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3427 - val_loss: 0.3404
Epoch 47/300

Epoch 00047: val_loss improved from 0.34043 to 0.34031, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3426 - val_loss: 0.3403
Epoch 48/300

Epoch 00048: val_loss improved from 0.34031 to 0.34019, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3424 - val_loss: 0.3402
Epoch 49/300

Epoch 00049: val_loss improved from 0.34019 to 0.34007, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3423 - val_loss: 0.3401
Epoch 50/300

Epoch 00050: val_loss improved from 0.34007 to 0.33994, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3421 - val_loss: 0.3399
Epoch 51/300

Epoch 00051: val_loss improved from 0.33994 to 0.33982, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3420 - val_loss: 0.3398
Epoch 52/300

Epoch 00052: val_loss improved from 0.33982 to 0.33970, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 6s - loss: 0.3418 - val_loss: 0.3397
Epoch 53/300

Epoch 00053: val_loss improved from 0.33970 to 0.33957, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3417 - val_loss: 0.3396
Epoch 54/300

Epoch 00054: val_loss improved from 0.33957 to 0.33944, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3415 - val_loss: 0.3394
Epoch 55/300

Epoch 00055: val_loss improved from 0.33944 to 0.33931, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3414 - val_loss: 0.3393
Epoch 56/300

Epoch 00056: val_loss improved from 0.33931 to 0.33918, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3412 - val_loss: 0.3392
Epoch 57/300

Epoch 00057: val_loss improved from 0.33918 to 0.33905, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3411 - val_loss: 0.3391
Epoch 58/300

Epoch 00058: val_loss improved from 0.33905 to 0.33892, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 7s - loss: 0.3409 - val_loss: 0.3389
Epoch 59/300

Epoch 00059: val_loss improved from 0.33892 to 0.33878, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3408 - val_loss: 0.3388
Epoch 60/300

Epoch 00060: val_loss improved from 0.33878 to 0.33865, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3406 - val_loss: 0.3387
Epoch 61/300

Epoch 00061: val_loss improved from 0.33865 to 0.33851, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3404 - val_loss: 0.3385
Epoch 62/300

Epoch 00062: val_loss improved from 0.33851 to 0.33838, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3403 - val_loss: 0.3384
Epoch 63/300

Epoch 00063: val_loss improved from 0.33838 to 0.33824, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3401 - val_loss: 0.3382
Epoch 64/300

Epoch 00064: val_loss improved from 0.33824 to 0.33810, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3399 - val_loss: 0.3381
Epoch 65/300

Epoch 00065: val_loss improved from 0.33810 to 0.33796, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3398 - val_loss: 0.3380
Epoch 66/300

Epoch 00066: val_loss improved from 0.33796 to 0.33782, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3396 - val_loss: 0.3378
Epoch 67/300

Epoch 00067: val_loss improved from 0.33782 to 0.33768, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3394 - val_loss: 0.3377
Epoch 68/300

Epoch 00068: val_loss improved from 0.33768 to 0.33754, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3393 - val_loss: 0.3375
Epoch 69/300

Epoch 00069: val_loss improved from 0.33754 to 0.33739, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3391 - val_loss: 0.3374
Epoch 70/300

Epoch 00070: val_loss improved from 0.33739 to 0.33725, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3389 - val_loss: 0.3372
Epoch 71/300

Epoch 00071: val_loss improved from 0.33725 to 0.33710, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3387 - val_loss: 0.3371
Epoch 72/300

Epoch 00072: val_loss improved from 0.33710 to 0.33696, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3386 - val_loss: 0.3370
Epoch 73/300

Epoch 00073: val_loss improved from 0.33696 to 0.33681, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3384 - val_loss: 0.3368
Epoch 74/300

Epoch 00074: val_loss improved from 0.33681 to 0.33666, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3382 - val_loss: 0.3367
Epoch 75/300

Epoch 00075: val_loss improved from 0.33666 to 0.33651, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3380 - val_loss: 0.3365
Epoch 76/300

Epoch 00076: val_loss improved from 0.33651 to 0.33636, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3378 - val_loss: 0.3364
Epoch 77/300

Epoch 00077: val_loss improved from 0.33636 to 0.33621, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3377 - val_loss: 0.3362
Epoch 78/300

Epoch 00078: val_loss improved from 0.33621 to 0.33605, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3375 - val_loss: 0.3361
Epoch 79/300

Epoch 00079: val_loss improved from 0.33605 to 0.33590, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3373 - val_loss: 0.3359
Epoch 80/300

Epoch 00080: val_loss improved from 0.33590 to 0.33575, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3371 - val_loss: 0.3357
Epoch 81/300

Epoch 00081: val_loss improved from 0.33575 to 0.33559, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3369 - val_loss: 0.3356
Epoch 82/300

Epoch 00082: val_loss improved from 0.33559 to 0.33544, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3367 - val_loss: 0.3354
Epoch 83/300

Epoch 00083: val_loss improved from 0.33544 to 0.33528, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3366 - val_loss: 0.3353
Epoch 84/300

Epoch 00084: val_loss improved from 0.33528 to 0.33512, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3364 - val_loss: 0.3351
Epoch 85/300

Epoch 00085: val_loss improved from 0.33512 to 0.33496, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3362 - val_loss: 0.3350
Epoch 86/300

Epoch 00086: val_loss improved from 0.33496 to 0.33480, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3360 - val_loss: 0.3348
Epoch 87/300

Epoch 00087: val_loss improved from 0.33480 to 0.33464, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3358 - val_loss: 0.3346
Epoch 88/300

Epoch 00088: val_loss improved from 0.33464 to 0.33448, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3356 - val_loss: 0.3345
Epoch 89/300

Epoch 00089: val_loss improved from 0.33448 to 0.33432, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3354 - val_loss: 0.3343
Epoch 90/300

Epoch 00090: val_loss improved from 0.33432 to 0.33415, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3352 - val_loss: 0.3342
Epoch 91/300

Epoch 00091: val_loss improved from 0.33415 to 0.33399, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3350 - val_loss: 0.3340
Epoch 92/300

Epoch 00092: val_loss improved from 0.33399 to 0.33383, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3348 - val_loss: 0.3338
Epoch 93/300

Epoch 00093: val_loss improved from 0.33383 to 0.33366, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3346 - val_loss: 0.3337
Epoch 94/300

Epoch 00094: val_loss improved from 0.33366 to 0.33350, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3344 - val_loss: 0.3335
Epoch 95/300

Epoch 00095: val_loss improved from 0.33350 to 0.33333, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3342 - val_loss: 0.3333
Epoch 96/300

Epoch 00096: val_loss improved from 0.33333 to 0.33316, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3340 - val_loss: 0.3332
Epoch 97/300

Epoch 00097: val_loss improved from 0.33316 to 0.33299, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3338 - val_loss: 0.3330
Epoch 98/300

Epoch 00098: val_loss improved from 0.33299 to 0.33282, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3336 - val_loss: 0.3328
Epoch 99/300

Epoch 00099: val_loss improved from 0.33282 to 0.33265, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3334 - val_loss: 0.3327
Epoch 100/300

Epoch 00100: val_loss improved from 0.33265 to 0.33248, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3332 - val_loss: 0.3325
Epoch 101/300

Epoch 00101: val_loss improved from 0.33248 to 0.33231, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3330 - val_loss: 0.3323
Epoch 102/300

Epoch 00102: val_loss improved from 0.33231 to 0.33214, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3328 - val_loss: 0.3321
Epoch 103/300

Epoch 00103: val_loss improved from 0.33214 to 0.33197, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 6s - loss: 0.3326 - val_loss: 0.3320
Epoch 104/300

Epoch 00104: val_loss improved from 0.33197 to 0.33179, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 6s - loss: 0.3324 - val_loss: 0.3318
Epoch 105/300

Epoch 00105: val_loss improved from 0.33179 to 0.33162, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3322 - val_loss: 0.3316
Epoch 106/300

Epoch 00106: val_loss improved from 0.33162 to 0.33144, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3319 - val_loss: 0.3314
Epoch 107/300

Epoch 00107: val_loss improved from 0.33144 to 0.33127, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3317 - val_loss: 0.3313
Epoch 108/300

Epoch 00108: val_loss improved from 0.33127 to 0.33109, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3315 - val_loss: 0.3311
Epoch 109/300

Epoch 00109: val_loss improved from 0.33109 to 0.33091, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3313 - val_loss: 0.3309
Epoch 110/300

Epoch 00110: val_loss improved from 0.33091 to 0.33073, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3311 - val_loss: 0.3307
Epoch 111/300

Epoch 00111: val_loss improved from 0.33073 to 0.33055, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 6s - loss: 0.3309 - val_loss: 0.3306
Epoch 112/300

Epoch 00112: val_loss improved from 0.33055 to 0.33038, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3307 - val_loss: 0.3304
Epoch 113/300

Epoch 00113: val_loss improved from 0.33038 to 0.33019, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3305 - val_loss: 0.3302
Epoch 114/300

Epoch 00114: val_loss improved from 0.33019 to 0.33001, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3302 - val_loss: 0.3300
Epoch 115/300

Epoch 00115: val_loss improved from 0.33001 to 0.32983, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3300 - val_loss: 0.3298
Epoch 116/300

Epoch 00116: val_loss improved from 0.32983 to 0.32965, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3298 - val_loss: 0.3296
Epoch 117/300

Epoch 00117: val_loss improved from 0.32965 to 0.32947, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3296 - val_loss: 0.3295
Epoch 118/300

Epoch 00118: val_loss improved from 0.32947 to 0.32928, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3294 - val_loss: 0.3293
Epoch 119/300

Epoch 00119: val_loss improved from 0.32928 to 0.32910, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3291 - val_loss: 0.3291
Epoch 120/300

Epoch 00120: val_loss improved from 0.32910 to 0.32891, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3289 - val_loss: 0.3289
Epoch 121/300

Epoch 00121: val_loss improved from 0.32891 to 0.32873, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3287 - val_loss: 0.3287
Epoch 122/300

Epoch 00122: val_loss improved from 0.32873 to 0.32854, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3285 - val_loss: 0.3285
Epoch 123/300

Epoch 00123: val_loss improved from 0.32854 to 0.32835, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3282 - val_loss: 0.3284
Epoch 124/300

Epoch 00124: val_loss improved from 0.32835 to 0.32817, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 7s - loss: 0.3280 - val_loss: 0.3282
Epoch 125/300

Epoch 00125: val_loss improved from 0.32817 to 0.32798, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3278 - val_loss: 0.3280
Epoch 126/300

Epoch 00126: val_loss improved from 0.32798 to 0.32779, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 6s - loss: 0.3276 - val_loss: 0.3278
Epoch 127/300

Epoch 00127: val_loss improved from 0.32779 to 0.32760, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3273 - val_loss: 0.3276
Epoch 128/300

Epoch 00128: val_loss improved from 0.32760 to 0.32741, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3271 - val_loss: 0.3274
Epoch 129/300

Epoch 00129: val_loss improved from 0.32741 to 0.32722, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3269 - val_loss: 0.3272
Epoch 130/300

Epoch 00130: val_loss improved from 0.32722 to 0.32703, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3266 - val_loss: 0.3270
Epoch 131/300

Epoch 00131: val_loss improved from 0.32703 to 0.32684, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3264 - val_loss: 0.3268
Epoch 132/300

Epoch 00132: val_loss improved from 0.32684 to 0.32664, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3262 - val_loss: 0.3266
Epoch 133/300

Epoch 00133: val_loss improved from 0.32664 to 0.32645, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3259 - val_loss: 0.3264
Epoch 134/300

Epoch 00134: val_loss improved from 0.32645 to 0.32626, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3257 - val_loss: 0.3263
Epoch 135/300

Epoch 00135: val_loss improved from 0.32626 to 0.32606, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3255 - val_loss: 0.3261
Epoch 136/300

Epoch 00136: val_loss improved from 0.32606 to 0.32587, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3252 - val_loss: 0.3259
Epoch 137/300

Epoch 00137: val_loss improved from 0.32587 to 0.32567, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3250 - val_loss: 0.3257
Epoch 138/300

Epoch 00138: val_loss improved from 0.32567 to 0.32547, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3248 - val_loss: 0.3255
Epoch 139/300

Epoch 00139: val_loss improved from 0.32547 to 0.32528, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3245 - val_loss: 0.3253
Epoch 140/300

Epoch 00140: val_loss improved from 0.32528 to 0.32508, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3243 - val_loss: 0.3251
Epoch 141/300

Epoch 00141: val_loss improved from 0.32508 to 0.32488, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3241 - val_loss: 0.3249
Epoch 142/300

Epoch 00142: val_loss improved from 0.32488 to 0.32468, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3238 - val_loss: 0.3247
Epoch 143/300

Epoch 00143: val_loss improved from 0.32468 to 0.32448, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3236 - val_loss: 0.3245
Epoch 144/300

Epoch 00144: val_loss improved from 0.32448 to 0.32428, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3233 - val_loss: 0.3243
Epoch 145/300

Epoch 00145: val_loss improved from 0.32428 to 0.32408, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3231 - val_loss: 0.3241
Epoch 146/300

Epoch 00146: val_loss improved from 0.32408 to 0.32388, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3229 - val_loss: 0.3239
Epoch 147/300

Epoch 00147: val_loss improved from 0.32388 to 0.32368, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 7s - loss: 0.3226 - val_loss: 0.3237
Epoch 148/300

Epoch 00148: val_loss improved from 0.32368 to 0.32348, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3224 - val_loss: 0.3235
Epoch 149/300

Epoch 00149: val_loss improved from 0.32348 to 0.32328, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3221 - val_loss: 0.3233
Epoch 150/300

Epoch 00150: val_loss improved from 0.32328 to 0.32307, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3219 - val_loss: 0.3231
Epoch 151/300

Epoch 00151: val_loss improved from 0.32307 to 0.32287, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3216 - val_loss: 0.3229
Epoch 152/300

Epoch 00152: val_loss improved from 0.32287 to 0.32267, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3214 - val_loss: 0.3227
Epoch 153/300

Epoch 00153: val_loss improved from 0.32267 to 0.32246, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3211 - val_loss: 0.3225
Epoch 154/300

Epoch 00154: val_loss improved from 0.32246 to 0.32226, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3209 - val_loss: 0.3223
Epoch 155/300

Epoch 00155: val_loss improved from 0.32226 to 0.32205, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3207 - val_loss: 0.3220
Epoch 156/300

Epoch 00156: val_loss improved from 0.32205 to 0.32184, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3204 - val_loss: 0.3218
Epoch 157/300

Epoch 00157: val_loss improved from 0.32184 to 0.32164, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3202 - val_loss: 0.3216
Epoch 158/300

Epoch 00158: val_loss improved from 0.32164 to 0.32143, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3199 - val_loss: 0.3214
Epoch 159/300

Epoch 00159: val_loss improved from 0.32143 to 0.32122, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3197 - val_loss: 0.3212
Epoch 160/300

Epoch 00160: val_loss improved from 0.32122 to 0.32102, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3194 - val_loss: 0.3210
Epoch 161/300

Epoch 00161: val_loss improved from 0.32102 to 0.32081, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3192 - val_loss: 0.3208
Epoch 162/300

Epoch 00162: val_loss improved from 0.32081 to 0.32060, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 6s - loss: 0.3189 - val_loss: 0.3206
Epoch 163/300

Epoch 00163: val_loss improved from 0.32060 to 0.32039, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3186 - val_loss: 0.3204
Epoch 164/300

Epoch 00164: val_loss improved from 0.32039 to 0.32018, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3184 - val_loss: 0.3202
Epoch 165/300

Epoch 00165: val_loss improved from 0.32018 to 0.31997, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3181 - val_loss: 0.3200
Epoch 166/300

Epoch 00166: val_loss improved from 0.31997 to 0.31976, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3179 - val_loss: 0.3198
Epoch 167/300

Epoch 00167: val_loss improved from 0.31976 to 0.31955, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3176 - val_loss: 0.3195
Epoch 168/300

Epoch 00168: val_loss improved from 0.31955 to 0.31934, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3174 - val_loss: 0.3193
Epoch 169/300

Epoch 00169: val_loss improved from 0.31934 to 0.31912, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3171 - val_loss: 0.3191
Epoch 170/300

Epoch 00170: val_loss improved from 0.31912 to 0.31891, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 7s - loss: 0.3169 - val_loss: 0.3189
Epoch 171/300

Epoch 00171: val_loss improved from 0.31891 to 0.31870, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3166 - val_loss: 0.3187
Epoch 172/300

Epoch 00172: val_loss improved from 0.31870 to 0.31848, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3164 - val_loss: 0.3185
Epoch 173/300

Epoch 00173: val_loss improved from 0.31848 to 0.31827, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3161 - val_loss: 0.3183
Epoch 174/300

Epoch 00174: val_loss improved from 0.31827 to 0.31806, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3158 - val_loss: 0.3181
Epoch 175/300

Epoch 00175: val_loss improved from 0.31806 to 0.31784, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3156 - val_loss: 0.3178
Epoch 176/300

Epoch 00176: val_loss improved from 0.31784 to 0.31763, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3153 - val_loss: 0.3176
Epoch 177/300

Epoch 00177: val_loss improved from 0.31763 to 0.31741, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3151 - val_loss: 0.3174
Epoch 178/300

Epoch 00178: val_loss improved from 0.31741 to 0.31719, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3148 - val_loss: 0.3172
Epoch 179/300

Epoch 00179: val_loss improved from 0.31719 to 0.31698, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3145 - val_loss: 0.3170
Epoch 180/300

Epoch 00180: val_loss improved from 0.31698 to 0.31676, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3143 - val_loss: 0.3168
Epoch 181/300

Epoch 00181: val_loss improved from 0.31676 to 0.31654, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3140 - val_loss: 0.3165
Epoch 182/300

Epoch 00182: val_loss improved from 0.31654 to 0.31632, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3137 - val_loss: 0.3163
Epoch 183/300

Epoch 00183: val_loss improved from 0.31632 to 0.31611, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3135 - val_loss: 0.3161
Epoch 184/300

Epoch 00184: val_loss improved from 0.31611 to 0.31589, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3132 - val_loss: 0.3159
Epoch 185/300

Epoch 00185: val_loss improved from 0.31589 to 0.31567, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3130 - val_loss: 0.3157
Epoch 186/300

Epoch 00186: val_loss improved from 0.31567 to 0.31545, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 6s - loss: 0.3127 - val_loss: 0.3155
Epoch 187/300

Epoch 00187: val_loss improved from 0.31545 to 0.31523, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3124 - val_loss: 0.3152
Epoch 188/300

Epoch 00188: val_loss improved from 0.31523 to 0.31501, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3122 - val_loss: 0.3150
Epoch 189/300

Epoch 00189: val_loss improved from 0.31501 to 0.31479, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3119 - val_loss: 0.3148
Epoch 190/300

Epoch 00190: val_loss improved from 0.31479 to 0.31457, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3116 - val_loss: 0.3146
Epoch 191/300

Epoch 00191: val_loss improved from 0.31457 to 0.31435, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3114 - val_loss: 0.3143
Epoch 192/300

Epoch 00192: val_loss improved from 0.31435 to 0.31413, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3111 - val_loss: 0.3141
Epoch 193/300

Epoch 00193: val_loss improved from 0.31413 to 0.31390, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3108 - val_loss: 0.3139
Epoch 194/300

Epoch 00194: val_loss improved from 0.31390 to 0.31368, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3105 - val_loss: 0.3137
Epoch 195/300

Epoch 00195: val_loss improved from 0.31368 to 0.31346, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3103 - val_loss: 0.3135
Epoch 196/300

Epoch 00196: val_loss improved from 0.31346 to 0.31323, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3100 - val_loss: 0.3132
Epoch 197/300

Epoch 00197: val_loss improved from 0.31323 to 0.31301, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3097 - val_loss: 0.3130
Epoch 198/300

Epoch 00198: val_loss improved from 0.31301 to 0.31279, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3095 - val_loss: 0.3128
Epoch 199/300

Epoch 00199: val_loss improved from 0.31279 to 0.31256, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3092 - val_loss: 0.3126
Epoch 200/300

Epoch 00200: val_loss improved from 0.31256 to 0.31234, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3089 - val_loss: 0.3123
Epoch 201/300

Epoch 00201: val_loss improved from 0.31234 to 0.31211, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3086 - val_loss: 0.3121
Epoch 202/300

Epoch 00202: val_loss improved from 0.31211 to 0.31188, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 7s - loss: 0.3084 - val_loss: 0.3119
Epoch 203/300

Epoch 00203: val_loss improved from 0.31188 to 0.31166, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3081 - val_loss: 0.3117
Epoch 204/300

Epoch 00204: val_loss improved from 0.31166 to 0.31143, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3078 - val_loss: 0.3114
Epoch 205/300

Epoch 00205: val_loss improved from 0.31143 to 0.31120, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3076 - val_loss: 0.3112
Epoch 206/300

Epoch 00206: val_loss improved from 0.31120 to 0.31098, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3073 - val_loss: 0.3110
Epoch 207/300

Epoch 00207: val_loss improved from 0.31098 to 0.31075, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3070 - val_loss: 0.3107
Epoch 208/300

Epoch 00208: val_loss improved from 0.31075 to 0.31052, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3067 - val_loss: 0.3105
Epoch 209/300

Epoch 00209: val_loss improved from 0.31052 to 0.31029, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3065 - val_loss: 0.3103
Epoch 210/300

Epoch 00210: val_loss improved from 0.31029 to 0.31007, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3062 - val_loss: 0.3101
Epoch 211/300

Epoch 00211: val_loss improved from 0.31007 to 0.30984, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 6s - loss: 0.3059 - val_loss: 0.3098
Epoch 212/300

Epoch 00212: val_loss improved from 0.30984 to 0.30961, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 6s - loss: 0.3056 - val_loss: 0.3096
Epoch 213/300

Epoch 00213: val_loss improved from 0.30961 to 0.30938, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.3053 - val_loss: 0.3094
Epoch 214/300

Epoch 00214: val_loss improved from 0.30938 to 0.30915, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 6s - loss: 0.3051 - val_loss: 0.3092
Epoch 215/300

Epoch 00215: val_loss improved from 0.30915 to 0.30892, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3048 - val_loss: 0.3089
Epoch 216/300

Epoch 00216: val_loss improved from 0.30892 to 0.30869, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3045 - val_loss: 0.3087
Epoch 217/300

Epoch 00217: val_loss improved from 0.30869 to 0.30846, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3042 - val_loss: 0.3085
Epoch 218/300

Epoch 00218: val_loss improved from 0.30846 to 0.30823, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3040 - val_loss: 0.3082
Epoch 219/300

Epoch 00219: val_loss improved from 0.30823 to 0.30800, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3037 - val_loss: 0.3080
Epoch 220/300

Epoch 00220: val_loss improved from 0.30800 to 0.30777, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3034 - val_loss: 0.3078
Epoch 221/300

Epoch 00221: val_loss improved from 0.30777 to 0.30753, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3031 - val_loss: 0.3075
Epoch 222/300

Epoch 00222: val_loss improved from 0.30753 to 0.30730, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3028 - val_loss: 0.3073
Epoch 223/300

Epoch 00223: val_loss improved from 0.30730 to 0.30707, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3025 - val_loss: 0.3071
Epoch 224/300

Epoch 00224: val_loss improved from 0.30707 to 0.30684, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3023 - val_loss: 0.3068
Epoch 225/300

Epoch 00225: val_loss improved from 0.30684 to 0.30660, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3020 - val_loss: 0.3066
Epoch 226/300

Epoch 00226: val_loss improved from 0.30660 to 0.30637, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3017 - val_loss: 0.3064
Epoch 227/300

Epoch 00227: val_loss improved from 0.30637 to 0.30614, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3014 - val_loss: 0.3061
Epoch 228/300

Epoch 00228: val_loss improved from 0.30614 to 0.30590, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3011 - val_loss: 0.3059
Epoch 229/300

Epoch 00229: val_loss improved from 0.30590 to 0.30567, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3008 - val_loss: 0.3057
Epoch 230/300

Epoch 00230: val_loss improved from 0.30567 to 0.30544, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3006 - val_loss: 0.3054
Epoch 231/300

Epoch 00231: val_loss improved from 0.30544 to 0.30520, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.3003 - val_loss: 0.3052
Epoch 232/300

Epoch 00232: val_loss improved from 0.30520 to 0.30496, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.3000 - val_loss: 0.3050
Epoch 233/300

Epoch 00233: val_loss improved from 0.30496 to 0.30473, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2997 - val_loss: 0.3047
Epoch 234/300

Epoch 00234: val_loss improved from 0.30473 to 0.30449, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2994 - val_loss: 0.3045
Epoch 235/300

Epoch 00235: val_loss improved from 0.30449 to 0.30426, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 6s - loss: 0.2991 - val_loss: 0.3043
Epoch 236/300

Epoch 00236: val_loss improved from 0.30426 to 0.30402, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2988 - val_loss: 0.3040
Epoch 237/300

Epoch 00237: val_loss improved from 0.30402 to 0.30379, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 6s - loss: 0.2986 - val_loss: 0.3038
Epoch 238/300

Epoch 00238: val_loss improved from 0.30379 to 0.30355, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2983 - val_loss: 0.3035
Epoch 239/300

Epoch 00239: val_loss improved from 0.30355 to 0.30331, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2980 - val_loss: 0.3033
Epoch 240/300

Epoch 00240: val_loss improved from 0.30331 to 0.30307, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2977 - val_loss: 0.3031
Epoch 241/300

Epoch 00241: val_loss improved from 0.30307 to 0.30284, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.2974 - val_loss: 0.3028
Epoch 242/300

Epoch 00242: val_loss improved from 0.30284 to 0.30260, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2971 - val_loss: 0.3026
Epoch 243/300

Epoch 00243: val_loss improved from 0.30260 to 0.30236, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 7s - loss: 0.2968 - val_loss: 0.3024
Epoch 244/300

Epoch 00244: val_loss improved from 0.30236 to 0.30212, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 6s - loss: 0.2965 - val_loss: 0.3021
Epoch 245/300

Epoch 00245: val_loss improved from 0.30212 to 0.30189, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.2963 - val_loss: 0.3019
Epoch 246/300

Epoch 00246: val_loss improved from 0.30189 to 0.30165, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2960 - val_loss: 0.3016
Epoch 247/300

Epoch 00247: val_loss improved from 0.30165 to 0.30141, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.2957 - val_loss: 0.3014
Epoch 248/300

Epoch 00248: val_loss improved from 0.30141 to 0.30117, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2954 - val_loss: 0.3012
Epoch 249/300

Epoch 00249: val_loss improved from 0.30117 to 0.30093, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2951 - val_loss: 0.3009
Epoch 250/300

Epoch 00250: val_loss improved from 0.30093 to 0.30069, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.2948 - val_loss: 0.3007
Epoch 251/300

Epoch 00251: val_loss improved from 0.30069 to 0.30045, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2945 - val_loss: 0.3005
Epoch 252/300

Epoch 00252: val_loss improved from 0.30045 to 0.30021, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.2942 - val_loss: 0.3002
Epoch 253/300

Epoch 00253: val_loss improved from 0.30021 to 0.29997, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2939 - val_loss: 0.3000
Epoch 254/300

Epoch 00254: val_loss improved from 0.29997 to 0.29973, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.2936 - val_loss: 0.2997
Epoch 255/300

Epoch 00255: val_loss improved from 0.29973 to 0.29949, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2933 - val_loss: 0.2995
Epoch 256/300

Epoch 00256: val_loss improved from 0.29949 to 0.29925, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2931 - val_loss: 0.2992
Epoch 257/300

Epoch 00257: val_loss improved from 0.29925 to 0.29901, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.2928 - val_loss: 0.2990
Epoch 258/300

Epoch 00258: val_loss improved from 0.29901 to 0.29877, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2925 - val_loss: 0.2988
Epoch 259/300

Epoch 00259: val_loss improved from 0.29877 to 0.29852, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2922 - val_loss: 0.2985
Epoch 260/300

Epoch 00260: val_loss improved from 0.29852 to 0.29828, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.2919 - val_loss: 0.2983
Epoch 261/300

Epoch 00261: val_loss improved from 0.29828 to 0.29804, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.2916 - val_loss: 0.2980
Epoch 262/300

Epoch 00262: val_loss improved from 0.29804 to 0.29780, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2913 - val_loss: 0.2978
Epoch 263/300

Epoch 00263: val_loss improved from 0.29780 to 0.29756, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2910 - val_loss: 0.2976
Epoch 264/300

Epoch 00264: val_loss improved from 0.29756 to 0.29732, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.2907 - val_loss: 0.2973
Epoch 265/300

Epoch 00265: val_loss improved from 0.29732 to 0.29707, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5715s - loss: 0.2904 - val_loss: 0.2971
Epoch 266/300

Epoch 00266: val_loss improved from 0.29707 to 0.29683, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2901 - val_loss: 0.2968
Epoch 267/300

Epoch 00267: val_loss improved from 0.29683 to 0.29659, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.2898 - val_loss: 0.2966
Epoch 268/300

Epoch 00268: val_loss improved from 0.29659 to 0.29634, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2895 - val_loss: 0.2963
Epoch 269/300

Epoch 00269: val_loss improved from 0.29634 to 0.29610, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 7s - loss: 0.2892 - val_loss: 0.2961
Epoch 270/300

Epoch 00270: val_loss improved from 0.29610 to 0.29586, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2889 - val_loss: 0.2959
Epoch 271/300

Epoch 00271: val_loss improved from 0.29586 to 0.29561, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2886 - val_loss: 0.2956
Epoch 272/300

Epoch 00272: val_loss improved from 0.29561 to 0.29537, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2883 - val_loss: 0.2954
Epoch 273/300

Epoch 00273: val_loss improved from 0.29537 to 0.29512, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2880 - val_loss: 0.2951
Epoch 274/300

Epoch 00274: val_loss improved from 0.29512 to 0.29488, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2877 - val_loss: 0.2949
Epoch 275/300

Epoch 00275: val_loss improved from 0.29488 to 0.29464, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2874 - val_loss: 0.2946
Epoch 276/300

Epoch 00276: val_loss improved from 0.29464 to 0.29439, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2871 - val_loss: 0.2944
Epoch 277/300

Epoch 00277: val_loss improved from 0.29439 to 0.29415, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2868 - val_loss: 0.2941
Epoch 278/300

Epoch 00278: val_loss improved from 0.29415 to 0.29390, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2865 - val_loss: 0.2939
Epoch 279/300

Epoch 00279: val_loss improved from 0.29390 to 0.29366, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2863 - val_loss: 0.2937
Epoch 280/300

Epoch 00280: val_loss improved from 0.29366 to 0.29341, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2860 - val_loss: 0.2934
Epoch 281/300

Epoch 00281: val_loss improved from 0.29341 to 0.29317, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2857 - val_loss: 0.2932
Epoch 282/300

Epoch 00282: val_loss improved from 0.29317 to 0.29292, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2854 - val_loss: 0.2929
Epoch 283/300

Epoch 00283: val_loss improved from 0.29292 to 0.29268, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2851 - val_loss: 0.2927
Epoch 284/300

Epoch 00284: val_loss improved from 0.29268 to 0.29243, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2848 - val_loss: 0.2924
Epoch 285/300

Epoch 00285: val_loss improved from 0.29243 to 0.29218, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2845 - val_loss: 0.2922
Epoch 286/300

Epoch 00286: val_loss improved from 0.29218 to 0.29194, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2842 - val_loss: 0.2919
Epoch 287/300

Epoch 00287: val_loss improved from 0.29194 to 0.29169, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2839 - val_loss: 0.2917
Epoch 288/300

Epoch 00288: val_loss improved from 0.29169 to 0.29145, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2836 - val_loss: 0.2914
Epoch 289/300

Epoch 00289: val_loss improved from 0.29145 to 0.29120, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2833 - val_loss: 0.2912
Epoch 290/300

Epoch 00290: val_loss improved from 0.29120 to 0.29095, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2830 - val_loss: 0.2910
Epoch 291/300

Epoch 00291: val_loss improved from 0.29095 to 0.29071, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2827 - val_loss: 0.2907
Epoch 292/300

Epoch 00292: val_loss improved from 0.29071 to 0.29046, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2824 - val_loss: 0.2905
Epoch 293/300

Epoch 00293: val_loss improved from 0.29046 to 0.29021, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.2821 - val_loss: 0.2902
Epoch 294/300

Epoch 00294: val_loss improved from 0.29021 to 0.28996, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2818 - val_loss: 0.2900
Epoch 295/300

Epoch 00295: val_loss improved from 0.28996 to 0.28972, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 6s - loss: 0.2815 - val_loss: 0.2897
Epoch 296/300

Epoch 00296: val_loss improved from 0.28972 to 0.28947, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.2811 - val_loss: 0.2895
Epoch 297/300

Epoch 00297: val_loss improved from 0.28947 to 0.28923, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2808 - val_loss: 0.2892
Epoch 298/300

Epoch 00298: val_loss improved from 0.28923 to 0.28898, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 3s - loss: 0.2806 - val_loss: 0.2890
Epoch 299/300

Epoch 00299: val_loss improved from 0.28898 to 0.28873, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 5s - loss: 0.2802 - val_loss: 0.2887
Epoch 300/300

Epoch 00300: val_loss improved from 0.28873 to 0.28848, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0_20191029-162427_best_model.h5
15/15 - 4s - loss: 0.2799 - val_loss: 0.2885
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      65.396238
Mean squared error (MSE):       16891.726678
Root mean squared error (RMSE): 129.968176
R square (R^2):                 -4.103460
[3.36844128e+03 2.36737229e+01 5.69758211e+02 6.36050335e+04]
##############################################
   Model8_filters_1_dense_1_denseSize_16_Dropout_0.4_20191029-181913
##############################################
16
Model: "model_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_11 (InputLayer)        [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 567, 756, 16)      448       
_________________________________________________________________
activation_11 (Activation)   (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_10 (Batc (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 283, 378, 16)      0         
_________________________________________________________________
flatten_10 (Flatten)         (None, 1711584)           0         
_________________________________________________________________
dense_11 (Dense)             (None, 16)                27385360  
_________________________________________________________________
activation_12 (Activation)   (None, 16)                0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 4)                 68        
=================================================================
Total params: 27,385,940
Trainable params: 27,385,908
Non-trainable params: 32
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/300
2019-10-29 18:19:16.813051: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 18:19:16.977636: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 92 kernel records, 11 memcpy records.
WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.174543). Check your callbacks.

Epoch 00001: val_loss improved from inf to 1578.45227, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.4_20191029-181913_best_model.h5
15/15 - 5s - loss: 4256.0261 - val_loss: 1578.4523
Epoch 2/300

Epoch 00002: val_loss improved from 1578.45227 to 0.29106, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.4_20191029-181913_best_model.h5
15/15 - 3s - loss: 302.0895 - val_loss: 0.2911
Epoch 3/300

Epoch 00003: val_loss did not improve from 0.29106
15/15 - 1s - loss: 818.0011 - val_loss: 6.1283
Epoch 4/300

Epoch 00004: val_loss did not improve from 0.29106
15/15 - 0s - loss: 5.7271 - val_loss: 0.4045
Epoch 5/300

Epoch 00005: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3456 - val_loss: 0.3147
Epoch 6/300

Epoch 00006: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3458 - val_loss: 0.3161
Epoch 7/300

Epoch 00007: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3462 - val_loss: 0.3175
Epoch 8/300

Epoch 00008: val_loss did not improve from 0.29106
15/15 - 1s - loss: 0.3465 - val_loss: 0.3188
Epoch 9/300

Epoch 00009: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3467 - val_loss: 0.3200
Epoch 10/300

Epoch 00010: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3468 - val_loss: 0.3211
Epoch 11/300

Epoch 00011: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3469 - val_loss: 0.3219
Epoch 12/300

Epoch 00012: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3469 - val_loss: 0.3227
Epoch 13/300

Epoch 00013: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3468 - val_loss: 0.3233
Epoch 14/300

Epoch 00014: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3468 - val_loss: 0.3238
Epoch 15/300

Epoch 00015: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3467 - val_loss: 0.3243
Epoch 16/300

Epoch 00016: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3465 - val_loss: 0.3245
Epoch 17/300

Epoch 00017: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3463 - val_loss: 0.3247
Epoch 18/300

Epoch 00018: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3462 - val_loss: 0.3249
Epoch 19/300

Epoch 00019: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3460 - val_loss: 0.3250
Epoch 20/300

Epoch 00020: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3457 - val_loss: 0.3250
Epoch 21/300

Epoch 00021: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3455 - val_loss: 0.3251
Epoch 22/300

Epoch 00022: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3452 - val_loss: 0.3251
Epoch 23/300

Epoch 00023: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3450 - val_loss: 0.3251
Epoch 24/300

Epoch 00024: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3447 - val_loss: 0.3251
Epoch 25/300

Epoch 00025: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3444 - val_loss: 0.3251
Epoch 26/300

Epoch 00026: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3441 - val_loss: 0.3251
Epoch 27/300

Epoch 00027: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3438 - val_loss: 0.3250
Epoch 28/300

Epoch 00028: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3435 - val_loss: 0.3250
Epoch 29/300

Epoch 00029: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3432 - val_loss: 0.3249
Epoch 30/300

Epoch 00030: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3429 - val_loss: 0.3248
Epoch 31/300

Epoch 00031: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3426 - val_loss: 0.3247
Epoch 32/300

Epoch 00032: val_loss did not improve from 0.29106
15/15 - 0s - loss: 0.3422 - val_loss: 0.3247
Epoch 00032: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      69.336876
Mean squared error (MSE):       18033.285856
Root mean squared error (RMSE): 134.288070
R square (R^2):                 -4.197223
[2.46533533e+03 5.84156243e+00 1.43490272e+03 6.82270638e+04]
##############################################
   Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942
##############################################
16
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
Model: "model_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_12 (InputLayer)        [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 567, 756, 16)      448       
_________________________________________________________________
activation_13 (Activation)   (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_11 (Batc (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 283, 378, 16)      0         
_________________________________________________________________
flatten_11 (Flatten)         (None, 1711584)           0         
_________________________________________________________________
dense_13 (Dense)             (None, 16)                27385360  
_________________________________________________________________
activation_14 (Activation)   (None, 16)                0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_14 (Dense)             (None, 4)                 68        
=================================================================
Total params: 27,385,940
Trainable params: 27,385,908
Non-trainable params: 32
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/300
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
2019-10-29 18:19:44.363581: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 18:19:44.527911: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 92 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 1120.84839, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 4053.6744 - val_loss: 1120.8484
Epoch 2/300

Epoch 00002: val_loss improved from 1120.84839 to 0.34795, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 1424.1804 - val_loss: 0.3479
Epoch 3/300

Epoch 00003: val_loss did not improve from 0.34795
15/15 - 0s - loss: 0.3447 - val_loss: 0.3480
Epoch 4/300

Epoch 00004: val_loss improved from 0.34795 to 0.34793, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3453 - val_loss: 0.3479
Epoch 5/300

Epoch 00005: val_loss improved from 0.34793 to 0.34789, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3457 - val_loss: 0.3479
Epoch 6/300

Epoch 00006: val_loss improved from 0.34789 to 0.34785, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3460 - val_loss: 0.3478
Epoch 7/300

Epoch 00007: val_loss improved from 0.34785 to 0.34783, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3462 - val_loss: 0.3478
Epoch 8/300

Epoch 00008: val_loss improved from 0.34783 to 0.34780, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3463 - val_loss: 0.3478
Epoch 9/300

Epoch 00009: val_loss improved from 0.34780 to 0.34774, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3465 - val_loss: 0.3477
Epoch 10/300

Epoch 00010: val_loss improved from 0.34774 to 0.34769, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3465 - val_loss: 0.3477
Epoch 11/300

Epoch 00011: val_loss improved from 0.34769 to 0.34763, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3466 - val_loss: 0.3476
Epoch 12/300

Epoch 00012: val_loss improved from 0.34763 to 0.34755, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3466 - val_loss: 0.3476
Epoch 13/300

Epoch 00013: val_loss improved from 0.34755 to 0.34747, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3466 - val_loss: 0.3475
Epoch 14/300

Epoch 00014: val_loss improved from 0.34747 to 0.34737, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3466 - val_loss: 0.3474
Epoch 15/300

Epoch 00015: val_loss improved from 0.34737 to 0.34727, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3466 - val_loss: 0.3473
Epoch 16/300

Epoch 00016: val_loss improved from 0.34727 to 0.34714, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3465 - val_loss: 0.3471
Epoch 17/300

Epoch 00017: val_loss improved from 0.34714 to 0.34702, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3465 - val_loss: 0.3470
Epoch 18/300

Epoch 00018: val_loss improved from 0.34702 to 0.34688, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3464 - val_loss: 0.3469
Epoch 19/300

Epoch 00019: val_loss improved from 0.34688 to 0.34676, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3463 - val_loss: 0.3468
Epoch 20/300

Epoch 00020: val_loss improved from 0.34676 to 0.34664, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3462 - val_loss: 0.3466
Epoch 21/300

Epoch 00021: val_loss improved from 0.34664 to 0.34651, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3461 - val_loss: 0.3465
Epoch 22/300

Epoch 00022: val_loss improved from 0.34651 to 0.34639, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3461 - val_loss: 0.3464
Epoch 23/300

Epoch 00023: val_loss improved from 0.34639 to 0.34627, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3460 - val_loss: 0.3463
Epoch 24/300

Epoch 00024: val_loss improved from 0.34627 to 0.34614, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3458 - val_loss: 0.3461
Epoch 25/300

Epoch 00025: val_loss improved from 0.34614 to 0.34600, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3457 - val_loss: 0.3460
Epoch 26/300

Epoch 00026: val_loss improved from 0.34600 to 0.34586, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3456 - val_loss: 0.3459
Epoch 27/300

Epoch 00027: val_loss improved from 0.34586 to 0.34571, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3455 - val_loss: 0.3457
Epoch 28/300

Epoch 00028: val_loss improved from 0.34571 to 0.34556, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3454 - val_loss: 0.3456
Epoch 29/300

Epoch 00029: val_loss improved from 0.34556 to 0.34540, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3452 - val_loss: 0.3454
Epoch 30/300

Epoch 00030: val_loss improved from 0.34540 to 0.34523, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3451 - val_loss: 0.3452
Epoch 31/300

Epoch 00031: val_loss improved from 0.34523 to 0.34506, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3450 - val_loss: 0.3451
Epoch 32/300

Epoch 00032: val_loss improved from 0.34506 to 0.34489, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3448 - val_loss: 0.3449
Epoch 33/300

Epoch 00033: val_loss improved from 0.34489 to 0.34472, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3447 - val_loss: 0.3447
Epoch 34/300

Epoch 00034: val_loss improved from 0.34472 to 0.34454, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3446 - val_loss: 0.3445
Epoch 35/300

Epoch 00035: val_loss improved from 0.34454 to 0.34436, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3444 - val_loss: 0.3444
Epoch 36/300

Epoch 00036: val_loss improved from 0.34436 to 0.34417, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3443 - val_loss: 0.3442
Epoch 37/300

Epoch 00037: val_loss improved from 0.34417 to 0.34398, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 6s - loss: 0.3441 - val_loss: 0.3440
Epoch 38/300

Epoch 00038: val_loss improved from 0.34398 to 0.34379, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3440 - val_loss: 0.3438
Epoch 39/300

Epoch 00039: val_loss improved from 0.34379 to 0.34360, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3438 - val_loss: 0.3436
Epoch 40/300

Epoch 00040: val_loss improved from 0.34360 to 0.34341, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3437 - val_loss: 0.3434
Epoch 41/300

Epoch 00041: val_loss improved from 0.34341 to 0.34321, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3435 - val_loss: 0.3432
Epoch 42/300

Epoch 00042: val_loss improved from 0.34321 to 0.34301, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3433 - val_loss: 0.3430
Epoch 43/300

Epoch 00043: val_loss improved from 0.34301 to 0.34281, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.3432 - val_loss: 0.3428
Epoch 44/300

Epoch 00044: val_loss improved from 0.34281 to 0.34261, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3430 - val_loss: 0.3426
Epoch 45/300

Epoch 00045: val_loss improved from 0.34261 to 0.34241, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.3429 - val_loss: 0.3424
Epoch 46/300

Epoch 00046: val_loss improved from 0.34241 to 0.34220, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3427 - val_loss: 0.3422
Epoch 47/300

Epoch 00047: val_loss improved from 0.34220 to 0.34200, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3425 - val_loss: 0.3420
Epoch 48/300

Epoch 00048: val_loss improved from 0.34200 to 0.34179, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3423 - val_loss: 0.3418
Epoch 49/300

Epoch 00049: val_loss improved from 0.34179 to 0.34158, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3422 - val_loss: 0.3416
Epoch 50/300

Epoch 00050: val_loss improved from 0.34158 to 0.34136, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3420 - val_loss: 0.3414
Epoch 51/300

Epoch 00051: val_loss improved from 0.34136 to 0.34115, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3418 - val_loss: 0.3412
Epoch 52/300

Epoch 00052: val_loss improved from 0.34115 to 0.34094, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3416 - val_loss: 0.3409
Epoch 53/300

Epoch 00053: val_loss improved from 0.34094 to 0.34072, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3415 - val_loss: 0.3407
Epoch 54/300

Epoch 00054: val_loss improved from 0.34072 to 0.34050, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3413 - val_loss: 0.3405
Epoch 55/300

Epoch 00055: val_loss improved from 0.34050 to 0.34028, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3411 - val_loss: 0.3403
Epoch 56/300

Epoch 00056: val_loss improved from 0.34028 to 0.34004, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3409 - val_loss: 0.3400
Epoch 57/300

Epoch 00057: val_loss improved from 0.34004 to 0.33981, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3407 - val_loss: 0.3398
Epoch 58/300

Epoch 00058: val_loss improved from 0.33981 to 0.33957, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3405 - val_loss: 0.3396
Epoch 59/300

Epoch 00059: val_loss improved from 0.33957 to 0.33934, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3404 - val_loss: 0.3393
Epoch 60/300

Epoch 00060: val_loss improved from 0.33934 to 0.33911, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3402 - val_loss: 0.3391
Epoch 61/300

Epoch 00061: val_loss improved from 0.33911 to 0.33891, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 6s - loss: 0.3400 - val_loss: 0.3389
Epoch 62/300

Epoch 00062: val_loss improved from 0.33891 to 0.33872, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3398 - val_loss: 0.3387
Epoch 63/300

Epoch 00063: val_loss improved from 0.33872 to 0.33853, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 6s - loss: 0.3396 - val_loss: 0.3385
Epoch 64/300

Epoch 00064: val_loss improved from 0.33853 to 0.33833, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3394 - val_loss: 0.3383
Epoch 65/300

Epoch 00065: val_loss improved from 0.33833 to 0.33811, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3392 - val_loss: 0.3381
Epoch 66/300

Epoch 00066: val_loss improved from 0.33811 to 0.33787, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.3390 - val_loss: 0.3379
Epoch 67/300

Epoch 00067: val_loss improved from 0.33787 to 0.33764, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3388 - val_loss: 0.3376
Epoch 68/300

Epoch 00068: val_loss improved from 0.33764 to 0.33740, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3386 - val_loss: 0.3374
Epoch 69/300

Epoch 00069: val_loss improved from 0.33740 to 0.33716, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 7s - loss: 0.3384 - val_loss: 0.3372
Epoch 70/300

Epoch 00070: val_loss improved from 0.33716 to 0.33692, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3382 - val_loss: 0.3369
Epoch 71/300

Epoch 00071: val_loss improved from 0.33692 to 0.33671, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3380 - val_loss: 0.3367
Epoch 72/300

Epoch 00072: val_loss improved from 0.33671 to 0.33652, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3378 - val_loss: 0.3365
Epoch 73/300

Epoch 00073: val_loss improved from 0.33652 to 0.33632, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3375 - val_loss: 0.3363
Epoch 74/300

Epoch 00074: val_loss improved from 0.33632 to 0.33612, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3373 - val_loss: 0.3361
Epoch 75/300

Epoch 00075: val_loss improved from 0.33612 to 0.33593, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3371 - val_loss: 0.3359
Epoch 76/300

Epoch 00076: val_loss improved from 0.33593 to 0.33575, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3369 - val_loss: 0.3357
Epoch 77/300

Epoch 00077: val_loss improved from 0.33575 to 0.33555, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3367 - val_loss: 0.3355
Epoch 78/300

Epoch 00078: val_loss improved from 0.33555 to 0.33534, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3365 - val_loss: 0.3353
Epoch 79/300

Epoch 00079: val_loss improved from 0.33534 to 0.33513, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3363 - val_loss: 0.3351
Epoch 80/300

Epoch 00080: val_loss improved from 0.33513 to 0.33493, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3360 - val_loss: 0.3349
Epoch 81/300

Epoch 00081: val_loss improved from 0.33493 to 0.33472, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3358 - val_loss: 0.3347
Epoch 82/300

Epoch 00082: val_loss improved from 0.33472 to 0.33451, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3356 - val_loss: 0.3345
Epoch 83/300

Epoch 00083: val_loss improved from 0.33451 to 0.33429, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3354 - val_loss: 0.3343
Epoch 84/300

Epoch 00084: val_loss improved from 0.33429 to 0.33408, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3351 - val_loss: 0.3341
Epoch 85/300

Epoch 00085: val_loss improved from 0.33408 to 0.33387, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3349 - val_loss: 0.3339
Epoch 86/300

Epoch 00086: val_loss improved from 0.33387 to 0.33365, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3347 - val_loss: 0.3337
Epoch 87/300

Epoch 00087: val_loss improved from 0.33365 to 0.33343, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3345 - val_loss: 0.3334
Epoch 88/300

Epoch 00088: val_loss improved from 0.33343 to 0.33322, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3342 - val_loss: 0.3332
Epoch 89/300

Epoch 00089: val_loss improved from 0.33322 to 0.33300, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3340 - val_loss: 0.3330
Epoch 90/300

Epoch 00090: val_loss improved from 0.33300 to 0.33278, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3338 - val_loss: 0.3328
Epoch 91/300

Epoch 00091: val_loss improved from 0.33278 to 0.33256, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3335 - val_loss: 0.3326
Epoch 92/300

Epoch 00092: val_loss improved from 0.33256 to 0.33233, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3333 - val_loss: 0.3323
Epoch 93/300

Epoch 00093: val_loss improved from 0.33233 to 0.33211, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3331 - val_loss: 0.3321
Epoch 94/300

Epoch 00094: val_loss improved from 0.33211 to 0.33188, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3328 - val_loss: 0.3319
Epoch 95/300

Epoch 00095: val_loss improved from 0.33188 to 0.33166, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3326 - val_loss: 0.3317
Epoch 96/300

Epoch 00096: val_loss improved from 0.33166 to 0.33143, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3324 - val_loss: 0.3314
Epoch 97/300

Epoch 00097: val_loss improved from 0.33143 to 0.33120, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3321 - val_loss: 0.3312
Epoch 98/300

Epoch 00098: val_loss improved from 0.33120 to 0.33097, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3319 - val_loss: 0.3310
Epoch 99/300

Epoch 00099: val_loss improved from 0.33097 to 0.33074, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3316 - val_loss: 0.3307
Epoch 100/300

Epoch 00100: val_loss improved from 0.33074 to 0.33051, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3314 - val_loss: 0.3305
Epoch 101/300

Epoch 00101: val_loss improved from 0.33051 to 0.33028, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3311 - val_loss: 0.3303
Epoch 102/300

Epoch 00102: val_loss improved from 0.33028 to 0.33005, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3309 - val_loss: 0.3300
Epoch 103/300

Epoch 00103: val_loss improved from 0.33005 to 0.32981, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3306 - val_loss: 0.3298
Epoch 104/300

Epoch 00104: val_loss improved from 0.32981 to 0.32957, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3304 - val_loss: 0.3296
Epoch 105/300

Epoch 00105: val_loss improved from 0.32957 to 0.32934, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3301 - val_loss: 0.3293
Epoch 106/300

Epoch 00106: val_loss improved from 0.32934 to 0.32910, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3299 - val_loss: 0.3291
Epoch 107/300

Epoch 00107: val_loss improved from 0.32910 to 0.32886, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3296 - val_loss: 0.3289
Epoch 108/300

Epoch 00108: val_loss improved from 0.32886 to 0.32862, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3294 - val_loss: 0.3286
Epoch 109/300

Epoch 00109: val_loss improved from 0.32862 to 0.32838, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.3291 - val_loss: 0.3284
Epoch 110/300

Epoch 00110: val_loss improved from 0.32838 to 0.32814, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3289 - val_loss: 0.3281
Epoch 111/300

Epoch 00111: val_loss improved from 0.32814 to 0.32790, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3286 - val_loss: 0.3279
Epoch 112/300

Epoch 00112: val_loss improved from 0.32790 to 0.32765, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 6s - loss: 0.3284 - val_loss: 0.3277
Epoch 113/300

Epoch 00113: val_loss improved from 0.32765 to 0.32741, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 6s - loss: 0.3281 - val_loss: 0.3274
Epoch 114/300

Epoch 00114: val_loss improved from 0.32741 to 0.32716, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3279 - val_loss: 0.3272
Epoch 115/300

Epoch 00115: val_loss improved from 0.32716 to 0.32692, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3276 - val_loss: 0.3269
Epoch 116/300

Epoch 00116: val_loss improved from 0.32692 to 0.32667, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 7s - loss: 0.3273 - val_loss: 0.3267
Epoch 117/300

Epoch 00117: val_loss improved from 0.32667 to 0.32642, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3271 - val_loss: 0.3264
Epoch 118/300

Epoch 00118: val_loss improved from 0.32642 to 0.32617, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3268 - val_loss: 0.3262
Epoch 119/300

Epoch 00119: val_loss improved from 0.32617 to 0.32592, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3265 - val_loss: 0.3259
Epoch 120/300

Epoch 00120: val_loss improved from 0.32592 to 0.32567, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3263 - val_loss: 0.3257
Epoch 121/300

Epoch 00121: val_loss improved from 0.32567 to 0.32542, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3260 - val_loss: 0.3254
Epoch 122/300

Epoch 00122: val_loss improved from 0.32542 to 0.32517, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3258 - val_loss: 0.3252
Epoch 123/300

Epoch 00123: val_loss improved from 0.32517 to 0.32491, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3255 - val_loss: 0.3249
Epoch 124/300

Epoch 00124: val_loss improved from 0.32491 to 0.32466, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3252 - val_loss: 0.3247
Epoch 125/300

Epoch 00125: val_loss improved from 0.32466 to 0.32441, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3249 - val_loss: 0.3244
Epoch 126/300

Epoch 00126: val_loss improved from 0.32441 to 0.32415, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3247 - val_loss: 0.3241
Epoch 127/300

Epoch 00127: val_loss improved from 0.32415 to 0.32389, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3244 - val_loss: 0.3239
Epoch 128/300

Epoch 00128: val_loss improved from 0.32389 to 0.32364, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.3241 - val_loss: 0.3236
Epoch 129/300

Epoch 00129: val_loss improved from 0.32364 to 0.32338, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3239 - val_loss: 0.3234
Epoch 130/300

Epoch 00130: val_loss improved from 0.32338 to 0.32312, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 6s - loss: 0.3236 - val_loss: 0.3231
Epoch 131/300

Epoch 00131: val_loss improved from 0.32312 to 0.32286, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3233 - val_loss: 0.3229
Epoch 132/300

Epoch 00132: val_loss improved from 0.32286 to 0.32259, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3230 - val_loss: 0.3226
Epoch 133/300

Epoch 00133: val_loss improved from 0.32259 to 0.32233, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3228 - val_loss: 0.3223
Epoch 134/300

Epoch 00134: val_loss improved from 0.32233 to 0.32207, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 7s - loss: 0.3225 - val_loss: 0.3221
Epoch 135/300

Epoch 00135: val_loss improved from 0.32207 to 0.32181, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3222 - val_loss: 0.3218
Epoch 136/300

Epoch 00136: val_loss improved from 0.32181 to 0.32154, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3219 - val_loss: 0.3215
Epoch 137/300

Epoch 00137: val_loss improved from 0.32154 to 0.32128, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3216 - val_loss: 0.3213
Epoch 138/300

Epoch 00138: val_loss improved from 0.32128 to 0.32101, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3214 - val_loss: 0.3210
Epoch 139/300

Epoch 00139: val_loss improved from 0.32101 to 0.32074, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3211 - val_loss: 0.3207
Epoch 140/300

Epoch 00140: val_loss improved from 0.32074 to 0.32048, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.3208 - val_loss: 0.3205
Epoch 141/300

Epoch 00141: val_loss improved from 0.32048 to 0.32021, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3205 - val_loss: 0.3202
Epoch 142/300

Epoch 00142: val_loss improved from 0.32021 to 0.31994, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3202 - val_loss: 0.3199
Epoch 143/300

Epoch 00143: val_loss improved from 0.31994 to 0.31967, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3199 - val_loss: 0.3197
Epoch 144/300

Epoch 00144: val_loss improved from 0.31967 to 0.31940, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3196 - val_loss: 0.3194
Epoch 145/300

Epoch 00145: val_loss improved from 0.31940 to 0.31913, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3194 - val_loss: 0.3191
Epoch 146/300

Epoch 00146: val_loss improved from 0.31913 to 0.31886, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3191 - val_loss: 0.3189
Epoch 147/300

Epoch 00147: val_loss improved from 0.31886 to 0.31858, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3188 - val_loss: 0.3186
Epoch 148/300

Epoch 00148: val_loss improved from 0.31858 to 0.31831, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3185 - val_loss: 0.3183
Epoch 149/300

Epoch 00149: val_loss improved from 0.31831 to 0.31804, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3182 - val_loss: 0.3180
Epoch 150/300

Epoch 00150: val_loss improved from 0.31804 to 0.31776, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3179 - val_loss: 0.3178
Epoch 151/300

Epoch 00151: val_loss improved from 0.31776 to 0.31748, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3176 - val_loss: 0.3175
Epoch 152/300

Epoch 00152: val_loss improved from 0.31748 to 0.31721, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3173 - val_loss: 0.3172
Epoch 153/300

Epoch 00153: val_loss improved from 0.31721 to 0.31693, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3170 - val_loss: 0.3169
Epoch 154/300

Epoch 00154: val_loss improved from 0.31693 to 0.31665, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3167 - val_loss: 0.3167
Epoch 155/300

Epoch 00155: val_loss improved from 0.31665 to 0.31637, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3164 - val_loss: 0.3164
Epoch 156/300

Epoch 00156: val_loss improved from 0.31637 to 0.31609, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.3161 - val_loss: 0.3161
Epoch 157/300

Epoch 00157: val_loss improved from 0.31609 to 0.31581, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3158 - val_loss: 0.3158
Epoch 158/300

Epoch 00158: val_loss improved from 0.31581 to 0.31553, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3155 - val_loss: 0.3155
Epoch 159/300

Epoch 00159: val_loss improved from 0.31553 to 0.31525, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3153 - val_loss: 0.3152
Epoch 160/300

Epoch 00160: val_loss improved from 0.31525 to 0.31497, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3150 - val_loss: 0.3150
Epoch 161/300

Epoch 00161: val_loss improved from 0.31497 to 0.31468, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3146 - val_loss: 0.3147
Epoch 162/300

Epoch 00162: val_loss improved from 0.31468 to 0.31440, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3143 - val_loss: 0.3144
Epoch 163/300

Epoch 00163: val_loss improved from 0.31440 to 0.31412, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 6s - loss: 0.3141 - val_loss: 0.3141
Epoch 164/300

Epoch 00164: val_loss improved from 0.31412 to 0.31383, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3137 - val_loss: 0.3138
Epoch 165/300

Epoch 00165: val_loss improved from 0.31383 to 0.31354, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3134 - val_loss: 0.3135
Epoch 166/300

Epoch 00166: val_loss improved from 0.31354 to 0.31326, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3131 - val_loss: 0.3133
Epoch 167/300

Epoch 00167: val_loss improved from 0.31326 to 0.31297, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3128 - val_loss: 0.3130
Epoch 168/300

Epoch 00168: val_loss improved from 0.31297 to 0.31268, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3125 - val_loss: 0.3127
Epoch 169/300

Epoch 00169: val_loss improved from 0.31268 to 0.31239, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3122 - val_loss: 0.3124
Epoch 170/300

Epoch 00170: val_loss improved from 0.31239 to 0.31210, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3119 - val_loss: 0.3121
Epoch 171/300

Epoch 00171: val_loss improved from 0.31210 to 0.31182, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3116 - val_loss: 0.3118
Epoch 172/300

Epoch 00172: val_loss improved from 0.31182 to 0.31153, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3113 - val_loss: 0.3115
Epoch 173/300

Epoch 00173: val_loss improved from 0.31153 to 0.31123, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3110 - val_loss: 0.3112
Epoch 174/300

Epoch 00174: val_loss improved from 0.31123 to 0.31094, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3107 - val_loss: 0.3109
Epoch 175/300

Epoch 00175: val_loss improved from 0.31094 to 0.31065, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3104 - val_loss: 0.3107
Epoch 176/300

Epoch 00176: val_loss improved from 0.31065 to 0.31036, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3101 - val_loss: 0.3104
Epoch 177/300

Epoch 00177: val_loss improved from 0.31036 to 0.31006, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3098 - val_loss: 0.3101
Epoch 178/300

Epoch 00178: val_loss improved from 0.31006 to 0.30977, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3094 - val_loss: 0.3098
Epoch 179/300

Epoch 00179: val_loss improved from 0.30977 to 0.30948, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3091 - val_loss: 0.3095
Epoch 180/300

Epoch 00180: val_loss improved from 0.30948 to 0.30918, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3088 - val_loss: 0.3092
Epoch 181/300

Epoch 00181: val_loss improved from 0.30918 to 0.30888, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3085 - val_loss: 0.3089
Epoch 182/300

Epoch 00182: val_loss improved from 0.30888 to 0.30859, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3082 - val_loss: 0.3086
Epoch 183/300

Epoch 00183: val_loss improved from 0.30859 to 0.30829, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3079 - val_loss: 0.3083
Epoch 184/300

Epoch 00184: val_loss improved from 0.30829 to 0.30799, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3076 - val_loss: 0.3080
Epoch 185/300

Epoch 00185: val_loss improved from 0.30799 to 0.30770, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3072 - val_loss: 0.3077
Epoch 186/300

Epoch 00186: val_loss improved from 0.30770 to 0.30740, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3069 - val_loss: 0.3074
Epoch 187/300

Epoch 00187: val_loss improved from 0.30740 to 0.30710, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3066 - val_loss: 0.3071
Epoch 188/300

Epoch 00188: val_loss improved from 0.30710 to 0.30680, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3063 - val_loss: 0.3068
Epoch 189/300

Epoch 00189: val_loss improved from 0.30680 to 0.30650, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3060 - val_loss: 0.3065
Epoch 190/300

Epoch 00190: val_loss improved from 0.30650 to 0.30620, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3057 - val_loss: 0.3062
Epoch 191/300

Epoch 00191: val_loss improved from 0.30620 to 0.30590, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3053 - val_loss: 0.3059
Epoch 192/300

Epoch 00192: val_loss improved from 0.30590 to 0.30559, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3050 - val_loss: 0.3056
Epoch 193/300

Epoch 00193: val_loss improved from 0.30559 to 0.30529, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3047 - val_loss: 0.3053
Epoch 194/300

Epoch 00194: val_loss improved from 0.30529 to 0.30499, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3044 - val_loss: 0.3050
Epoch 195/300

Epoch 00195: val_loss improved from 0.30499 to 0.30469, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3041 - val_loss: 0.3047
Epoch 196/300

Epoch 00196: val_loss improved from 0.30469 to 0.30438, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3037 - val_loss: 0.3044
Epoch 197/300

Epoch 00197: val_loss improved from 0.30438 to 0.30408, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3034 - val_loss: 0.3041
Epoch 198/300

Epoch 00198: val_loss improved from 0.30408 to 0.30377, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3031 - val_loss: 0.3038
Epoch 199/300

Epoch 00199: val_loss improved from 0.30377 to 0.30347, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3028 - val_loss: 0.3035
Epoch 200/300

Epoch 00200: val_loss improved from 0.30347 to 0.30316, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.3024 - val_loss: 0.3032
Epoch 201/300

Epoch 00201: val_loss improved from 0.30316 to 0.30286, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 6s - loss: 0.3021 - val_loss: 0.3029
Epoch 202/300

Epoch 00202: val_loss improved from 0.30286 to 0.30255, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3018 - val_loss: 0.3025
Epoch 203/300

Epoch 00203: val_loss improved from 0.30255 to 0.30224, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3014 - val_loss: 0.3022
Epoch 204/300

Epoch 00204: val_loss improved from 0.30224 to 0.30194, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3011 - val_loss: 0.3019
Epoch 205/300

Epoch 00205: val_loss improved from 0.30194 to 0.30163, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3008 - val_loss: 0.3016
Epoch 206/300

Epoch 00206: val_loss improved from 0.30163 to 0.30132, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3005 - val_loss: 0.3013
Epoch 207/300

Epoch 00207: val_loss improved from 0.30132 to 0.30101, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.3001 - val_loss: 0.3010
Epoch 208/300

Epoch 00208: val_loss improved from 0.30101 to 0.30070, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2998 - val_loss: 0.3007
Epoch 209/300

Epoch 00209: val_loss improved from 0.30070 to 0.30039, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2995 - val_loss: 0.3004
Epoch 210/300

Epoch 00210: val_loss improved from 0.30039 to 0.30008, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2991 - val_loss: 0.3001
Epoch 211/300

Epoch 00211: val_loss improved from 0.30008 to 0.29977, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2988 - val_loss: 0.2998
Epoch 212/300

Epoch 00212: val_loss improved from 0.29977 to 0.29946, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2985 - val_loss: 0.2995
Epoch 213/300

Epoch 00213: val_loss improved from 0.29946 to 0.29915, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2982 - val_loss: 0.2991
Epoch 214/300

Epoch 00214: val_loss improved from 0.29915 to 0.29883, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2978 - val_loss: 0.2988
Epoch 215/300

Epoch 00215: val_loss improved from 0.29883 to 0.29852, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2975 - val_loss: 0.2985
Epoch 216/300

Epoch 00216: val_loss improved from 0.29852 to 0.29821, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2972 - val_loss: 0.2982
Epoch 217/300

Epoch 00217: val_loss improved from 0.29821 to 0.29789, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2968 - val_loss: 0.2979
Epoch 218/300

Epoch 00218: val_loss improved from 0.29789 to 0.29758, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2965 - val_loss: 0.2976
Epoch 219/300

Epoch 00219: val_loss improved from 0.29758 to 0.29727, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.2962 - val_loss: 0.2973
Epoch 220/300

Epoch 00220: val_loss improved from 0.29727 to 0.29695, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2958 - val_loss: 0.2970
Epoch 221/300

Epoch 00221: val_loss improved from 0.29695 to 0.29663, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2955 - val_loss: 0.2966
Epoch 222/300

Epoch 00222: val_loss improved from 0.29663 to 0.29632, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2951 - val_loss: 0.2963
Epoch 223/300

Epoch 00223: val_loss improved from 0.29632 to 0.29600, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2948 - val_loss: 0.2960
Epoch 224/300

Epoch 00224: val_loss improved from 0.29600 to 0.29569, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2945 - val_loss: 0.2957
Epoch 225/300

Epoch 00225: val_loss improved from 0.29569 to 0.29537, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2941 - val_loss: 0.2954
Epoch 226/300

Epoch 00226: val_loss improved from 0.29537 to 0.29505, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2938 - val_loss: 0.2951
Epoch 227/300

Epoch 00227: val_loss improved from 0.29505 to 0.29474, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2935 - val_loss: 0.2947
Epoch 228/300

Epoch 00228: val_loss improved from 0.29474 to 0.29442, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2931 - val_loss: 0.2944
Epoch 229/300

Epoch 00229: val_loss improved from 0.29442 to 0.29410, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 6s - loss: 0.2928 - val_loss: 0.2941
Epoch 230/300

Epoch 00230: val_loss improved from 0.29410 to 0.29378, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2924 - val_loss: 0.2938
Epoch 231/300

Epoch 00231: val_loss improved from 0.29378 to 0.29346, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2921 - val_loss: 0.2935
Epoch 232/300

Epoch 00232: val_loss improved from 0.29346 to 0.29314, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2918 - val_loss: 0.2931
Epoch 233/300

Epoch 00233: val_loss improved from 0.29314 to 0.29282, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.2914 - val_loss: 0.2928
Epoch 234/300

Epoch 00234: val_loss improved from 0.29282 to 0.29250, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2911 - val_loss: 0.2925
Epoch 235/300

Epoch 00235: val_loss improved from 0.29250 to 0.29218, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2907 - val_loss: 0.2922
Epoch 236/300

Epoch 00236: val_loss improved from 0.29218 to 0.29186, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.2904 - val_loss: 0.2919
Epoch 237/300

Epoch 00237: val_loss improved from 0.29186 to 0.29154, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2901 - val_loss: 0.2915
Epoch 238/300

Epoch 00238: val_loss improved from 0.29154 to 0.29122, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.2897 - val_loss: 0.2912
Epoch 239/300

Epoch 00239: val_loss improved from 0.29122 to 0.29090, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2894 - val_loss: 0.2909
Epoch 240/300

Epoch 00240: val_loss improved from 0.29090 to 0.29058, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2890 - val_loss: 0.2906
Epoch 241/300

Epoch 00241: val_loss improved from 0.29058 to 0.29025, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2887 - val_loss: 0.2903
Epoch 242/300

Epoch 00242: val_loss improved from 0.29025 to 0.28993, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.2883 - val_loss: 0.2899
Epoch 243/300

Epoch 00243: val_loss improved from 0.28993 to 0.28960, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2880 - val_loss: 0.2896
Epoch 244/300

Epoch 00244: val_loss improved from 0.28960 to 0.28928, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2877 - val_loss: 0.2893
Epoch 245/300

Epoch 00245: val_loss improved from 0.28928 to 0.28896, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2873 - val_loss: 0.2890
Epoch 246/300

Epoch 00246: val_loss improved from 0.28896 to 0.28863, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2870 - val_loss: 0.2886
Epoch 247/300

Epoch 00247: val_loss improved from 0.28863 to 0.28831, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.2866 - val_loss: 0.2883
Epoch 248/300

Epoch 00248: val_loss improved from 0.28831 to 0.28798, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2863 - val_loss: 0.2880
Epoch 249/300

Epoch 00249: val_loss improved from 0.28798 to 0.28766, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2859 - val_loss: 0.2877
Epoch 250/300

Epoch 00250: val_loss improved from 0.28766 to 0.28733, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2856 - val_loss: 0.2873
Epoch 251/300

Epoch 00251: val_loss improved from 0.28733 to 0.28701, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2852 - val_loss: 0.2870
Epoch 252/300

Epoch 00252: val_loss improved from 0.28701 to 0.28668, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2849 - val_loss: 0.2867
Epoch 253/300

Epoch 00253: val_loss improved from 0.28668 to 0.28635, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2845 - val_loss: 0.2864
Epoch 254/300

Epoch 00254: val_loss improved from 0.28635 to 0.28603, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2842 - val_loss: 0.2860
Epoch 255/300

Epoch 00255: val_loss improved from 0.28603 to 0.28570, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2838 - val_loss: 0.2857
Epoch 256/300

Epoch 00256: val_loss improved from 0.28570 to 0.28537, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.2835 - val_loss: 0.2854
Epoch 257/300

Epoch 00257: val_loss improved from 0.28537 to 0.28504, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2831 - val_loss: 0.2850
Epoch 258/300

Epoch 00258: val_loss improved from 0.28504 to 0.28472, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2828 - val_loss: 0.2847
Epoch 259/300

Epoch 00259: val_loss improved from 0.28472 to 0.28439, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2824 - val_loss: 0.2844
Epoch 260/300

Epoch 00260: val_loss improved from 0.28439 to 0.28406, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2821 - val_loss: 0.2841
Epoch 261/300

Epoch 00261: val_loss improved from 0.28406 to 0.28373, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.2817 - val_loss: 0.2837
Epoch 262/300

Epoch 00262: val_loss improved from 0.28373 to 0.28340, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2814 - val_loss: 0.2834
Epoch 263/300

Epoch 00263: val_loss improved from 0.28340 to 0.28307, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2810 - val_loss: 0.2831
Epoch 264/300

Epoch 00264: val_loss improved from 0.28307 to 0.28274, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2807 - val_loss: 0.2827
Epoch 265/300

Epoch 00265: val_loss improved from 0.28274 to 0.28241, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2803 - val_loss: 0.2824
Epoch 266/300

Epoch 00266: val_loss improved from 0.28241 to 0.28208, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.2800 - val_loss: 0.2821
Epoch 267/300

Epoch 00267: val_loss improved from 0.28208 to 0.28175, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2796 - val_loss: 0.2818
Epoch 268/300

Epoch 00268: val_loss improved from 0.28175 to 0.28142, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2793 - val_loss: 0.2814
Epoch 269/300

Epoch 00269: val_loss improved from 0.28142 to 0.28109, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2789 - val_loss: 0.2811
Epoch 270/300

Epoch 00270: val_loss improved from 0.28109 to 0.28076, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2786 - val_loss: 0.2808
Epoch 271/300

Epoch 00271: val_loss improved from 0.28076 to 0.28043, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2782 - val_loss: 0.2804
Epoch 272/300

Epoch 00272: val_loss improved from 0.28043 to 0.28010, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2778 - val_loss: 0.2801
Epoch 273/300

Epoch 00273: val_loss improved from 0.28010 to 0.27977, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.2775 - val_loss: 0.2798
Epoch 274/300

Epoch 00274: val_loss improved from 0.27977 to 0.27943, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2771 - val_loss: 0.2794
Epoch 275/300

Epoch 00275: val_loss improved from 0.27943 to 0.27910, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2768 - val_loss: 0.2791
Epoch 276/300

Epoch 00276: val_loss improved from 0.27910 to 0.27877, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2764 - val_loss: 0.2788
Epoch 277/300

Epoch 00277: val_loss improved from 0.27877 to 0.27844, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2761 - val_loss: 0.2784
Epoch 278/300

Epoch 00278: val_loss improved from 0.27844 to 0.27810, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2757 - val_loss: 0.2781
Epoch 279/300

Epoch 00279: val_loss improved from 0.27810 to 0.27777, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2754 - val_loss: 0.2778
Epoch 280/300

Epoch 00280: val_loss improved from 0.27777 to 0.27744, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2750 - val_loss: 0.2774
Epoch 281/300

Epoch 00281: val_loss improved from 0.27744 to 0.27711, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2746 - val_loss: 0.2771
Epoch 282/300

Epoch 00282: val_loss improved from 0.27711 to 0.27677, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 7s - loss: 0.2743 - val_loss: 0.2768
Epoch 283/300

Epoch 00283: val_loss improved from 0.27677 to 0.27644, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2739 - val_loss: 0.2764
Epoch 284/300

Epoch 00284: val_loss improved from 0.27644 to 0.27611, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2736 - val_loss: 0.2761
Epoch 285/300

Epoch 00285: val_loss improved from 0.27611 to 0.27577, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2732 - val_loss: 0.2758
Epoch 286/300

Epoch 00286: val_loss improved from 0.27577 to 0.27544, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2728 - val_loss: 0.2754
Epoch 287/300

Epoch 00287: val_loss improved from 0.27544 to 0.27510, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2725 - val_loss: 0.2751
Epoch 288/300

Epoch 00288: val_loss improved from 0.27510 to 0.27477, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2721 - val_loss: 0.2748
Epoch 289/300

Epoch 00289: val_loss improved from 0.27477 to 0.27444, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.2718 - val_loss: 0.2744
Epoch 290/300

Epoch 00290: val_loss improved from 0.27444 to 0.27410, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2714 - val_loss: 0.2741
Epoch 291/300

Epoch 00291: val_loss improved from 0.27410 to 0.27377, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2711 - val_loss: 0.2738
Epoch 292/300

Epoch 00292: val_loss improved from 0.27377 to 0.27343, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2707 - val_loss: 0.2734
Epoch 293/300

Epoch 00293: val_loss improved from 0.27343 to 0.27309, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 5s - loss: 0.2703 - val_loss: 0.2731
Epoch 294/300

Epoch 00294: val_loss improved from 0.27309 to 0.27276, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2700 - val_loss: 0.2728
Epoch 295/300

Epoch 00295: val_loss improved from 0.27276 to 0.27242, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2696 - val_loss: 0.2724
Epoch 296/300

Epoch 00296: val_loss improved from 0.27242 to 0.27209, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2693 - val_loss: 0.2721
Epoch 297/300

Epoch 00297: val_loss improved from 0.27209 to 0.27175, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2689 - val_loss: 0.2717
Epoch 298/300

Epoch 00298: val_loss improved from 0.27175 to 0.27141, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 4s - loss: 0.2685 - val_loss: 0.2714
Epoch 299/300

Epoch 00299: val_loss improved from 0.27141 to 0.27107, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2682 - val_loss: 0.2711
Epoch 300/300

Epoch 00300: val_loss improved from 0.27107 to 0.27074, saving model to Models\Model8_filters_1_dense_1_denseSize_16_Dropout_0.6_20191029-181942_best_model.h5
15/15 - 3s - loss: 0.2678 - val_loss: 0.2707
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      62.419361
Mean squared error (MSE):       16268.726837
Root mean squared error (RMSE): 127.548919
R square (R^2):                 -3.334941
[2.55986790e+03 2.01505947e+01 6.74253802e+02 6.18206351e+04]
##############################################
   Model8_filters_1_dense_1_denseSize_32_Dropout_0_20191029-183751
##############################################
32
2019-10-29 18:38:01.997905: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 208.93MiB (rounded to 219082752).  Current allocation summary follows.
2019-10-29 18:38:01.998244: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (256): 	Total Chunks: 248, Chunks in use: 247. 62.0KiB allocated for chunks. 61.8KiB in use in bin. 14.4KiB client-requested in use in bin.
2019-10-29 18:38:01.998577: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (512): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-29 18:38:01.998921: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (1024): 	Total Chunks: 14, Chunks in use: 14. 24.0KiB allocated for chunks. 24.0KiB in use in bin. 22.9KiB client-requested in use in bin.
2019-10-29 18:38:01.999535: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (2048): 	Total Chunks: 21, Chunks in use: 20. 51.3KiB allocated for chunks. 48.8KiB in use in bin. 33.8KiB client-requested in use in bin.
2019-10-29 18:38:01.999921: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-29 18:38:02.000433: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-29 18:38:02.000887: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-29 18:38:02.001543: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-29 18:38:02.001989: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (65536): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-29 18:38:02.002358: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-29 18:38:02.002758: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (262144): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-29 18:38:02.003534: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (524288): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-29 18:38:02.004022: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-29 18:38:02.004333: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-29 18:38:02.004641: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-29 18:38:02.004976: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-29 18:38:02.005595: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (16777216): 	Total Chunks: 21, Chunks in use: 18. 548.36MiB allocated for chunks. 470.11MiB in use in bin. 470.10MiB client-requested in use in bin.
2019-10-29 18:38:02.006020: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (33554432): 	Total Chunks: 2, Chunks in use: 0. 104.45MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-29 18:38:02.006687: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (67108864): 	Total Chunks: 15, Chunks in use: 13. 1.50GiB allocated for chunks. 1.33GiB in use in bin. 1.33GiB client-requested in use in bin.
2019-10-29 18:38:02.007344: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (134217728): 	Total Chunks: 4, Chunks in use: 3. 809.34MiB allocated for chunks. 600.68MiB in use in bin. 522.33MiB client-requested in use in bin.
2019-10-29 18:38:02.007830: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-29 18:38:02.011507: I tensorflow/core/common_runtime/bfc_allocator.cc:885] Bin for 208.93MiB was 128.00MiB, Chunk State: 
2019-10-29 18:38:02.011743: I tensorflow/core/common_runtime/bfc_allocator.cc:891]   Size: 208.65MiB | Requested Size: 0B | in_use: 0 | bin_num: 19, prev:   Size: 208.93MiB | Requested Size: 208.93MiB | in_use: 1 | bin_num: -1
2019-10-29 18:38:02.012132: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 3149043968
2019-10-29 18:38:02.012317: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400000 next 1 of size 1280
2019-10-29 18:38:02.012513: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400500 next 2 of size 256
2019-10-29 18:38:02.012878: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400600 next 5 of size 256
2019-10-29 18:38:02.013188: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400700 next 4 of size 256
2019-10-29 18:38:02.013442: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400800 next 7 of size 256
2019-10-29 18:38:02.013673: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400900 next 8 of size 256
2019-10-29 18:38:02.013944: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400A00 next 9 of size 256
2019-10-29 18:38:02.014178: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400B00 next 10 of size 256
2019-10-29 18:38:02.014414: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400C00 next 3 of size 2560
2019-10-29 18:38:02.014643: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702401600 next 6 of size 1792
2019-10-29 18:38:02.014906: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000702401D00 next 148 of size 27385344
2019-10-29 18:38:02.015146: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000703E1FB00 next 13 of size 27385344
2019-10-29 18:38:02.015404: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070583D900 next 11 of size 27385344
2019-10-29 18:38:02.015654: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070725B700 next 51 of size 256
2019-10-29 18:38:02.015985: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070725B800 next 32 of size 27388928
2019-10-29 18:38:02.016258: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000708C7A400 next 40 of size 256
2019-10-29 18:38:02.016518: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000708C7A500 next 33 of size 256
2019-10-29 18:38:02.016713: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000708C7A600 next 34 of size 256
2019-10-29 18:38:02.017000: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000708C7A700 next 54 of size 256
2019-10-29 18:38:02.017247: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000708C7A800 next 36 of size 256
2019-10-29 18:38:02.017496: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000708C7A900 next 42 of size 256
2019-10-29 18:38:02.017725: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000708C7AA00 next 38 of size 256
2019-10-29 18:38:02.018103: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000708C7AB00 next 50 of size 2560
2019-10-29 18:38:02.018354: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000708C7B500 next 52 of size 27385344
2019-10-29 18:38:02.018546: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070A699300 next 48 of size 256
2019-10-29 18:38:02.018728: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070A699400 next 44 of size 256
2019-10-29 18:38:02.019136: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070A699500 next 39 of size 256
2019-10-29 18:38:02.019372: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070A699600 next 46 of size 256
2019-10-29 18:38:02.019606: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070A699700 next 45 of size 256
2019-10-29 18:38:02.019852: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070A699800 next 61 of size 27391232
2019-10-29 18:38:02.020148: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0B8D00 next 66 of size 256
2019-10-29 18:38:02.020353: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0B8E00 next 65 of size 256
2019-10-29 18:38:02.020535: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0B8F00 next 63 of size 256
2019-10-29 18:38:02.020717: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0B9000 next 62 of size 256
2019-10-29 18:38:02.021001: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0B9100 next 67 of size 256
2019-10-29 18:38:02.021205: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0B9200 next 68 of size 256
2019-10-29 18:38:02.021391: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0B9300 next 228 of size 256
2019-10-29 18:38:02.021578: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0B9400 next 41 of size 256
2019-10-29 18:38:02.021809: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0B9500 next 240 of size 256
2019-10-29 18:38:02.022345: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0B9600 next 100 of size 256
2019-10-29 18:38:02.022583: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0B9700 next 94 of size 256
2019-10-29 18:38:02.022863: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0B9800 next 117 of size 256
2019-10-29 18:38:02.023109: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0B9900 next 102 of size 256
2019-10-29 18:38:02.023350: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0B9A00 next 121 of size 256
2019-10-29 18:38:02.023589: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0B9B00 next 105 of size 256
2019-10-29 18:38:02.023831: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0B9C00 next 57 of size 256
2019-10-29 18:38:02.024116: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0B9D00 next 64 of size 1792
2019-10-29 18:38:02.024307: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BA400 next 131 of size 256
2019-10-29 18:38:02.024497: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BA500 next 58 of size 256
2019-10-29 18:38:02.024682: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BA600 next 55 of size 256
2019-10-29 18:38:02.025074: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BA700 next 35 of size 256
2019-10-29 18:38:02.025281: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BA800 next 31 of size 256
2019-10-29 18:38:02.025469: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BA900 next 128 of size 256
2019-10-29 18:38:02.025661: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BAA00 next 53 of size 256
2019-10-29 18:38:02.025875: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BAB00 next 129 of size 2560
2019-10-29 18:38:02.026073: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BB500 next 29 of size 2304
2019-10-29 18:38:02.026309: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BBE00 next 17 of size 256
2019-10-29 18:38:02.026529: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BBF00 next 24 of size 256
2019-10-29 18:38:02.026742: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BC000 next 25 of size 256
2019-10-29 18:38:02.026939: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BC100 next 30 of size 256
2019-10-29 18:38:02.027135: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BC200 next 22 of size 256
2019-10-29 18:38:02.027333: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BC300 next 18 of size 256
2019-10-29 18:38:02.027530: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BC400 next 23 of size 2560
2019-10-29 18:38:02.028145: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BCE00 next 26 of size 1792
2019-10-29 18:38:02.028402: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070C0BD500 next 27 of size 27385344
2019-10-29 18:38:02.028651: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 000000070DADB300 next 47 of size 54754048
2019-10-29 18:38:02.028989: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000710F12E00 next 71 of size 27385344
2019-10-29 18:38:02.029261: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000712930C00 next 69 of size 27385344
2019-10-29 18:38:02.029461: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434EA00 next 189 of size 256
2019-10-29 18:38:02.029651: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434EB00 next 122 of size 256
2019-10-29 18:38:02.030027: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434EC00 next 126 of size 256
2019-10-29 18:38:02.030236: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434ED00 next 98 of size 256
2019-10-29 18:38:02.030429: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434EE00 next 221 of size 256
2019-10-29 18:38:02.030623: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434EF00 next 84 of size 256
2019-10-29 18:38:02.030817: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434F000 next 87 of size 256
2019-10-29 18:38:02.031010: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434F100 next 234 of size 256
2019-10-29 18:38:02.031207: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434F200 next 226 of size 256
2019-10-29 18:38:02.031402: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434F300 next 108 of size 256
2019-10-29 18:38:02.031598: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434F400 next 106 of size 256
2019-10-29 18:38:02.031799: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434F500 next 99 of size 256
2019-10-29 18:38:02.031998: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434F600 next 14 of size 256
2019-10-29 18:38:02.032199: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434F700 next 110 of size 256
2019-10-29 18:38:02.032400: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434F800 next 95 of size 256
2019-10-29 18:38:02.033072: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434F900 next 15 of size 256
2019-10-29 18:38:02.033320: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434FA00 next 143 of size 256
2019-10-29 18:38:02.033566: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434FB00 next 251 of size 256
2019-10-29 18:38:02.033838: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434FC00 next 59 of size 256
2019-10-29 18:38:02.034141: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434FD00 next 80 of size 256
2019-10-29 18:38:02.034472: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434FE00 next 75 of size 256
2019-10-29 18:38:02.034670: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071434FF00 next 96 of size 256
2019-10-29 18:38:02.034916: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714350000 next 120 of size 256
2019-10-29 18:38:02.035107: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714350100 next 123 of size 256
2019-10-29 18:38:02.035296: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714350200 next 119 of size 256
2019-10-29 18:38:02.035486: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714350300 next 101 of size 256
2019-10-29 18:38:02.035674: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714350400 next 97 of size 256
2019-10-29 18:38:02.035884: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714350500 next 104 of size 256
2019-10-29 18:38:02.036397: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714350600 next 114 of size 256
2019-10-29 18:38:02.036654: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714350700 next 113 of size 2560
2019-10-29 18:38:02.036910: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714351100 next 93 of size 2560
2019-10-29 18:38:02.037297: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714351B00 next 218 of size 256
2019-10-29 18:38:02.037582: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714351C00 next 217 of size 256
2019-10-29 18:38:02.037846: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714351D00 next 213 of size 256
2019-10-29 18:38:02.038103: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714351E00 next 216 of size 256
2019-10-29 18:38:02.038345: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714351F00 next 215 of size 256
2019-10-29 18:38:02.038583: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714352000 next 214 of size 256
2019-10-29 18:38:02.038825: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714352100 next 209 of size 256
2019-10-29 18:38:02.039064: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714352200 next 208 of size 256
2019-10-29 18:38:02.039294: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714352300 next 266 of size 256
2019-10-29 18:38:02.039525: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714352400 next 139 of size 256
2019-10-29 18:38:02.039784: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714352500 next 74 of size 2304
2019-10-29 18:38:02.040041: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714352E00 next 83 of size 3072
2019-10-29 18:38:02.040291: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714353A00 next 81 of size 256
2019-10-29 18:38:02.040547: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714353B00 next 78 of size 256
2019-10-29 18:38:02.040788: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714353C00 next 142 of size 256
2019-10-29 18:38:02.041036: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714353D00 next 141 of size 256
2019-10-29 18:38:02.041301: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714353E00 next 73 of size 256
2019-10-29 18:38:02.041530: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714353F00 next 79 of size 256
2019-10-29 18:38:02.041861: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714354000 next 70 of size 256
2019-10-29 18:38:02.042162: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714354100 next 135 of size 2560
2019-10-29 18:38:02.042415: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714354B00 next 249 of size 256
2019-10-29 18:38:02.042663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714354C00 next 238 of size 256
2019-10-29 18:38:02.042925: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714354D00 next 239 of size 256
2019-10-29 18:38:02.043172: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714354E00 next 253 of size 256
2019-10-29 18:38:02.043414: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714354F00 next 247 of size 256
2019-10-29 18:38:02.043669: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714355000 next 241 of size 256
2019-10-29 18:38:02.043934: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714355100 next 232 of size 256
2019-10-29 18:38:02.044165: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714355200 next 235 of size 256
2019-10-29 18:38:02.044396: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714355300 next 130 of size 256
2019-10-29 18:38:02.044662: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714355400 next 49 of size 256
2019-10-29 18:38:02.044945: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714355500 next 155 of size 2560
2019-10-29 18:38:02.045240: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714355F00 next 145 of size 256
2019-10-29 18:38:02.045474: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714356000 next 154 of size 256
2019-10-29 18:38:02.045743: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714356100 next 153 of size 256
2019-10-29 18:38:02.045974: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714356200 next 152 of size 256
2019-10-29 18:38:02.046178: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714356300 next 157 of size 256
2019-10-29 18:38:02.046376: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714356400 next 147 of size 256
2019-10-29 18:38:02.046597: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714356500 next 76 of size 2560
2019-10-29 18:38:02.047067: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714356F00 next 127 of size 256
2019-10-29 18:38:02.047271: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714357000 next 107 of size 256
2019-10-29 18:38:02.047473: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714357100 next 82 of size 256
2019-10-29 18:38:02.047965: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714357200 next 124 of size 256
2019-10-29 18:38:02.048387: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714357300 next 109 of size 256
2019-10-29 18:38:02.049403: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714357400 next 125 of size 256
2019-10-29 18:38:02.049642: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714357500 next 85 of size 256
2019-10-29 18:38:02.050407: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714357600 next 151 of size 256
2019-10-29 18:38:02.050608: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714357700 next 156 of size 1792
2019-10-29 18:38:02.050859: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714357E00 next 103 of size 1792
2019-10-29 18:38:02.051062: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714358500 next 16 of size 256
2019-10-29 18:38:02.051257: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714358600 next 86 of size 256
2019-10-29 18:38:02.051451: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714358700 next 197 of size 256
2019-10-29 18:38:02.051648: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714358800 next 176 of size 256
2019-10-29 18:38:02.051847: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714358900 next 195 of size 256
2019-10-29 18:38:02.052046: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714358A00 next 175 of size 256
2019-10-29 18:38:02.052243: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714358B00 next 111 of size 256
2019-10-29 18:38:02.052440: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714358C00 next 91 of size 256
2019-10-29 18:38:02.052637: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714358D00 next 115 of size 256
2019-10-29 18:38:02.052840: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714358E00 next 174 of size 256
2019-10-29 18:38:02.053039: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714358F00 next 227 of size 256
2019-10-29 18:38:02.053238: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714359000 next 177 of size 2048
2019-10-29 18:38:02.053443: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714359800 next 183 of size 256
2019-10-29 18:38:02.053649: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714359900 next 196 of size 256
2019-10-29 18:38:02.053849: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714359A00 next 188 of size 256
2019-10-29 18:38:02.054048: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714359B00 next 184 of size 256
2019-10-29 18:38:02.054248: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714359C00 next 193 of size 256
2019-10-29 18:38:02.058212: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714359D00 next 194 of size 256
2019-10-29 18:38:02.058419: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714359E00 next 178 of size 256
2019-10-29 18:38:02.058621: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714359F00 next 179 of size 2560
2019-10-29 18:38:02.058822: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435A900 next 89 of size 256
2019-10-29 18:38:02.059137: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435AA00 next 182 of size 256
2019-10-29 18:38:02.059398: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435AB00 next 186 of size 256
2019-10-29 18:38:02.059658: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435AC00 next 37 of size 256
2019-10-29 18:38:02.059901: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435AD00 next 181 of size 256
2019-10-29 18:38:02.060125: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435AE00 next 60 of size 256
2019-10-29 18:38:02.060323: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435AF00 next 164 of size 256
2019-10-29 18:38:02.060520: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435B000 next 290 of size 256
2019-10-29 18:38:02.060717: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435B100 next 163 of size 256
2019-10-29 18:38:02.061098: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435B200 next 168 of size 256
2019-10-29 18:38:02.061302: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435B300 next 289 of size 256
2019-10-29 18:38:02.061526: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435B400 next 166 of size 256
2019-10-29 18:38:02.061748: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435B500 next 165 of size 256
2019-10-29 18:38:02.061979: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435B600 next 285 of size 256
2019-10-29 18:38:02.062162: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435B700 next 167 of size 256
2019-10-29 18:38:02.062377: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435B800 next 301 of size 256
2019-10-29 18:38:02.062559: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435B900 next 169 of size 256
2019-10-29 18:38:02.063080: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435BA00 next 203 of size 2560
2019-10-29 18:38:02.063339: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435C400 next 190 of size 256
2019-10-29 18:38:02.063610: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435C500 next 202 of size 256
2019-10-29 18:38:02.063912: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435C600 next 201 of size 256
2019-10-29 18:38:02.064168: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435C700 next 200 of size 256
2019-10-29 18:38:02.064409: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435C800 next 205 of size 256
2019-10-29 18:38:02.064688: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435C900 next 191 of size 256
2019-10-29 18:38:02.064941: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435CA00 next 198 of size 2048
2019-10-29 18:38:02.065172: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435D200 next 199 of size 2560
2019-10-29 18:38:02.065424: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435DC00 next 204 of size 1792
2019-10-29 18:38:02.065665: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435E300 next 28 of size 256
2019-10-29 18:38:02.065872: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435E400 next 133 of size 256
2019-10-29 18:38:02.066193: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435E500 next 140 of size 256
2019-10-29 18:38:02.066433: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435E600 next 211 of size 256
2019-10-29 18:38:02.066663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435E700 next 150 of size 256
2019-10-29 18:38:02.067010: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435E800 next 149 of size 256
2019-10-29 18:38:02.067330: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435E900 next 137 of size 256
2019-10-29 18:38:02.067613: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435EA00 next 219 of size 256
2019-10-29 18:38:02.067929: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435EB00 next 146 of size 256
2019-10-29 18:38:02.068399: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435EC00 next 43 of size 1792
2019-10-29 18:38:02.068676: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435F300 next 88 of size 256
2019-10-29 18:38:02.068931: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435F400 next 246 of size 256
2019-10-29 18:38:02.069156: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435F500 next 224 of size 256
2019-10-29 18:38:02.069407: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435F600 next 223 of size 256
2019-10-29 18:38:02.069718: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435F700 next 222 of size 256
2019-10-29 18:38:02.070009: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435F800 next 19 of size 256
2019-10-29 18:38:02.070265: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435F900 next 161 of size 256
2019-10-29 18:38:02.070468: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435FA00 next 225 of size 256
2019-10-29 18:38:02.070672: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435FB00 next 229 of size 256
2019-10-29 18:38:02.070869: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435FC00 next 242 of size 256
2019-10-29 18:38:02.071068: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435FD00 next 230 of size 256
2019-10-29 18:38:02.071264: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435FE00 next 237 of size 256
2019-10-29 18:38:02.071921: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071435FF00 next 233 of size 256
2019-10-29 18:38:02.072189: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714360000 next 236 of size 256
2019-10-29 18:38:02.072452: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714360100 next 243 of size 256
2019-10-29 18:38:02.072746: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714360200 next 245 of size 2560
2019-10-29 18:38:02.072991: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714360C00 next 210 of size 1792
2019-10-29 18:38:02.073245: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714361300 next 267 of size 256
2019-10-29 18:38:02.073502: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714361400 next 268 of size 256
2019-10-29 18:38:02.073901: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714361500 next 258 of size 2816
2019-10-29 18:38:02.074110: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714362000 next 248 of size 256
2019-10-29 18:38:02.074302: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714362100 next 257 of size 256
2019-10-29 18:38:02.074504: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714362200 next 256 of size 256
2019-10-29 18:38:02.074801: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714362300 next 255 of size 256
2019-10-29 18:38:02.075015: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714362400 next 260 of size 256
2019-10-29 18:38:02.075216: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714362500 next 250 of size 256
2019-10-29 18:38:02.075412: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714362600 next 187 of size 256
2019-10-29 18:38:02.075638: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714362700 next 231 of size 256
2019-10-29 18:38:02.075842: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714362800 next 90 of size 256
2019-10-29 18:38:02.076055: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714362900 next 56 of size 256
2019-10-29 18:38:02.076668: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714362A00 next 12 of size 256
2019-10-29 18:38:02.076895: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714362B00 next 132 of size 256
2019-10-29 18:38:02.077294: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714362C00 next 134 of size 256
2019-10-29 18:38:02.077497: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714362D00 next 252 of size 256
2019-10-29 18:38:02.077699: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714362E00 next 261 of size 256
2019-10-29 18:38:02.077936: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714362F00 next 264 of size 256
2019-10-29 18:38:02.078144: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714363000 next 265 of size 256
2019-10-29 18:38:02.078620: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714363100 next 254 of size 1792
2019-10-29 18:38:02.078866: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714363800 next 259 of size 1792
2019-10-29 18:38:02.079123: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714363F00 next 269 of size 256
2019-10-29 18:38:02.079368: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714364000 next 270 of size 256
2019-10-29 18:38:02.079607: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714364100 next 271 of size 256
2019-10-29 18:38:02.079850: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714364200 next 272 of size 256
2019-10-29 18:38:02.080094: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714364300 next 273 of size 256
2019-10-29 18:38:02.080342: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714364400 next 274 of size 256
2019-10-29 18:38:02.080542: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714364500 next 275 of size 256
2019-10-29 18:38:02.081028: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714364600 next 276 of size 256
2019-10-29 18:38:02.081228: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714364700 next 277 of size 256
2019-10-29 18:38:02.081425: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714364800 next 278 of size 256
2019-10-29 18:38:02.081622: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714364900 next 279 of size 256
2019-10-29 18:38:02.081817: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714364A00 next 280 of size 256
2019-10-29 18:38:02.082014: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714364B00 next 281 of size 256
2019-10-29 18:38:02.082264: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714364C00 next 294 of size 256
2019-10-29 18:38:02.082461: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714364D00 next 292 of size 256
2019-10-29 18:38:02.083044: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714364E00 next 293 of size 256
2019-10-29 18:38:02.083286: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714364F00 next 284 of size 256
2019-10-29 18:38:02.083526: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714365000 next 291 of size 256
2019-10-29 18:38:02.083806: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714365100 next 298 of size 256
2019-10-29 18:38:02.084049: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714365200 next 300 of size 256
2019-10-29 18:38:02.084297: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714365300 next 302 of size 256
2019-10-29 18:38:02.084541: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714365400 next 286 of size 256
2019-10-29 18:38:02.084803: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714365500 next 303 of size 256
2019-10-29 18:38:02.085069: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714365600 next 282 of size 1792
2019-10-29 18:38:02.085316: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714365D00 next 283 of size 256
2019-10-29 18:38:02.085558: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714365E00 next 172 of size 256
2019-10-29 18:38:02.085802: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714365F00 next 162 of size 256
2019-10-29 18:38:02.086052: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714366000 next 299 of size 256
2019-10-29 18:38:02.086315: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714366100 next 171 of size 256
2019-10-29 18:38:02.086550: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714366200 next 315 of size 256
2019-10-29 18:38:02.086743: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714366300 next 287 of size 256
2019-10-29 18:38:02.086939: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714366400 next 295 of size 256
2019-10-29 18:38:02.087133: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714366500 next 304 of size 2048
2019-10-29 18:38:02.087337: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714366D00 next 297 of size 256
2019-10-29 18:38:02.087541: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714366E00 next 305 of size 256
2019-10-29 18:38:02.087765: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714366F00 next 306 of size 256
2019-10-29 18:38:02.087966: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714367000 next 307 of size 256
2019-10-29 18:38:02.088162: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714367100 next 308 of size 256
2019-10-29 18:38:02.088360: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714367200 next 310 of size 256
2019-10-29 18:38:02.088571: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714367300 next 320 of size 256
2019-10-29 18:38:02.088771: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714367400 next 316 of size 256
2019-10-29 18:38:02.089363: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714367500 next 319 of size 256
2019-10-29 18:38:02.089608: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714367600 next 318 of size 256
2019-10-29 18:38:02.089808: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714367700 next 317 of size 256
2019-10-29 18:38:02.090007: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714367800 next 322 of size 256
2019-10-29 18:38:02.090209: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000714367900 next 312 of size 256
2019-10-29 18:38:02.090409: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714367A00 next 313 of size 256
2019-10-29 18:38:02.090619: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714367B00 next 314 of size 1792
2019-10-29 18:38:02.090820: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000714368200 next 311 of size 2560
2019-10-29 18:38:02.091021: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714368C00 next 321 of size 1792
2019-10-29 18:38:02.091220: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000714369300 next 20 of size 27276544
2019-10-29 18:38:02.091422: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000715D6C800 next 21 of size 27385344
2019-10-29 18:38:02.091677: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071778A600 next 92 of size 27385344
2019-10-29 18:38:02.091888: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007191A8400 next 118 of size 27385344
2019-10-29 18:38:02.092089: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 000000071ABC6200 next 112 of size 27385344
2019-10-29 18:38:02.092292: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071C5E4000 next 138 of size 27385344
2019-10-29 18:38:02.092495: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 000000071E001E00 next 173 of size 54770688
2019-10-29 18:38:02.092701: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000072143DA00 next 160 of size 27385344
2019-10-29 18:38:02.092905: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000722E5B800 next 159 of size 27385344
2019-10-29 18:38:02.093111: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000724879600 next 158 of size 27385344
2019-10-29 18:38:02.093314: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000726297400 next 192 of size 27385344
2019-10-29 18:38:02.093517: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000727CB5200 next 207 of size 82156032
2019-10-29 18:38:02.093720: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000072CB0EC00 next 206 of size 27385344
2019-10-29 18:38:02.093922: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000072E52CA00 next 244 of size 27385344
2019-10-29 18:38:02.094126: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000072FF4A800 next 72 of size 109541376
2019-10-29 18:38:02.094329: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007367C2000 next 263 of size 191697408
2019-10-29 18:38:02.094534: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000741E93200 next 262 of size 109541376
2019-10-29 18:38:02.095545: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000074870AA00 next 185 of size 109541376
2019-10-29 18:38:02.095758: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000074EF82200 next 180 of size 109541376
2019-10-29 18:38:02.096081: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007557F9A00 next 144 of size 109541376
2019-10-29 18:38:02.096356: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000075C071200 next 77 of size 109541376
2019-10-29 18:38:02.096616: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007628E8A00 next 220 of size 109541376
2019-10-29 18:38:02.096824: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000769160200 next 212 of size 109541376
2019-10-29 18:38:02.097198: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000076F9D7A00 next 288 of size 109541376
2019-10-29 18:38:02.097405: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000077624F200 next 136 of size 109541376
2019-10-29 18:38:02.097760: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000077CAC6A00 next 116 of size 109541376
2019-10-29 18:38:02.098017: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000078333E200 next 170 of size 109541376
2019-10-29 18:38:02.098269: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000789BB5A00 next 309 of size 109541376
2019-10-29 18:38:02.098544: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079042D200 next 296 of size 109541376
2019-10-29 18:38:02.098821: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000796CA4A00 next 323 of size 219082752
2019-10-29 18:38:02.099030: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A3D93A00 next 325 of size 219082752
2019-10-29 18:38:02.099354: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007B0E82A00 next 18446744073709551615 of size 218787584
2019-10-29 18:38:02.099652: I tensorflow/core/common_runtime/bfc_allocator.cc:914]      Summary of in-use Chunks by size: 
2019-10-29 18:38:02.099911: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 247 Chunks of size 256 totalling 61.8KiB
2019-10-29 18:38:02.100136: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1280 totalling 1.3KiB
2019-10-29 18:38:02.100324: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 13 Chunks of size 1792 totalling 22.8KiB
2019-10-29 18:38:02.100511: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 3 Chunks of size 2048 totalling 6.0KiB
2019-10-29 18:38:02.100727: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 2304 totalling 4.5KiB
2019-10-29 18:38:02.100915: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 13 Chunks of size 2560 totalling 32.5KiB
2019-10-29 18:38:02.101107: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2816 totalling 2.8KiB
2019-10-29 18:38:02.101292: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 3072 totalling 3.0KiB
2019-10-29 18:38:02.101475: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 16 Chunks of size 27385344 totalling 417.87MiB
2019-10-29 18:38:02.101687: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 27388928 totalling 26.12MiB
2019-10-29 18:38:02.101879: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 27391232 totalling 26.12MiB
2019-10-29 18:38:02.102072: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 13 Chunks of size 109541376 totalling 1.33GiB
2019-10-29 18:38:02.102706: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 191697408 totalling 182.82MiB
2019-10-29 18:38:02.102943: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 219082752 totalling 417.87MiB
2019-10-29 18:38:02.103176: I tensorflow/core/common_runtime/bfc_allocator.cc:921] Sum Total of in-use chunks: 2.37GiB
2019-10-29 18:38:02.103392: I tensorflow/core/common_runtime/bfc_allocator.cc:923] total_region_allocated_bytes_: 3149043968 memory_limit_: 3149044121 available bytes: 153 curr_region_allocation_bytes_: 6298088448
2019-10-29 18:38:02.103830: I tensorflow/core/common_runtime/bfc_allocator.cc:929] Stats: 
Limit:                  3149044121
InUse:                  2546984192
MaxInUse:               2630286848
NumAllocs:                  182094
MaxAllocSize:           1191644416

2019-10-29 18:38:02.104337: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ***************_*****_**********x****************************************__*******************______
2019-10-29 18:38:02.107843: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at cwise_ops_common.cc:82 : Resource exhausted: OOM when allocating tensor with shape[1711584,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc

Process finished with exit code -1073741819 (0xC0000005)
