C:\Users\DELL\Anaconda3\python.exe "D:/OneDrive/My Research/Dr_Mosaad/Data 2/program/cnn_regression.py"
2019-10-29 23:22:55.897573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
[INFO] loading attributes...
[INFO] loading house images...
1.jpg
10.jpg
11.jpg
12.jpg
13.jpg
18.jpg
19.jpg
2.jpg
20.jpg
21.jpg
22.jpg
23.jpg
24.jpg
25.jpg
26.jpg
3.jpg
4.jpg
5.jpg
6.jpg
---------------- Train Y  --------------------
    distance        C2        Cm        RL
6       0.00  0.718310  0.708511  0.177836
2       0.50  0.718310  0.708511  0.249850
10      0.50  0.859155  0.708511  0.177836
13      0.50  0.000000  0.708511  0.177836
8       0.75  0.718310  0.708511  0.177836
14      0.50  0.718310  0.806383  0.177836
16      0.50  0.718310  0.468085  0.177836
18      0.50  0.718310  1.000000  0.177836
12      0.50  0.295775  0.708511  0.177836
11      0.50  1.000000  0.708511  0.177836
1       0.50  0.718310  0.708511  0.083817
0       0.50  0.718310  0.708511  0.177836
15      0.50  0.718310  0.853191  0.177836
4       0.50  0.718310  0.708511  0.000000
9       1.00  0.718310  0.708511  0.177836
---------------- Test Y  --------------------
    distance       C2        Cm        RL
3       0.50  0.71831  0.708511  1.000000
7       0.25  0.71831  0.708511  0.177836
17      0.50  0.71831  0.000000  0.177836
5       0.50  0.71831  0.708511  0.177836
##############################################
   Model8_filters_2_dense_0_denseSize_16_Dropout_0_20191029-232301
##############################################
2019-10-29 23:23:01.242739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2019-10-29 23:23:02.462720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.493
pciBusID: 0000:01:00.0
2019-10-29 23:23:02.463050: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-10-29 23:23:02.463903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-29 23:23:02.464339: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-10-29 23:23:02.561503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.493
pciBusID: 0000:01:00.0
2019-10-29 23:23:02.561834: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-10-29 23:23:02.562677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-29 23:23:04.087580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-29 23:23:04.087816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-10-29 23:23:04.087956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-10-29 23:23:04.088889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3003 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d (Conv2D)              (None, 567, 756, 16)      448       
_________________________________________________________________
activation (Activation)      (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization (BatchNo (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 283, 378, 16)      0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 283, 378, 32)      4640      
_________________________________________________________________
activation_1 (Activation)    (None, 283, 378, 32)      0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 283, 378, 32)      128       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 141, 189, 32)      0         
_________________________________________________________________
flatten (Flatten)            (None, 852768)            0         
_________________________________________________________________
dense (Dense)                (None, 4)                 3411076   
=================================================================
Total params: 3,416,356
Trainable params: 3,416,260
Non-trainable params: 96
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/1000
2019-10-29 23:23:06.391010: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2019-10-29 23:23:07.012408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2019-10-29 23:23:09.135090: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Internal: Invoking ptxas not supported on Windows
Relying on driver to perform ptx compilation. This message will be only logged once.
2019-10-29 23:23:10.212649: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 23:23:10.214826: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cupti64_100.dll
2019-10-29 23:23:11.466563: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 2475 kernel records, 33 memcpy records.

Epoch 00001: val_loss improved from inf to 34.63926, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0_20191029-232301_best_model.h5
15/15 - 8s - loss: 109527.1341 - val_loss: 34.6393
Epoch 2/1000

Epoch 00002: val_loss did not improve from 34.63926
15/15 - 0s - loss: 28759.0602 - val_loss: 254.4525
Epoch 3/1000

Epoch 00003: val_loss did not improve from 34.63926
15/15 - 0s - loss: 104008.8917 - val_loss: 300.6725
Epoch 4/1000

Epoch 00004: val_loss did not improve from 34.63926
15/15 - 0s - loss: 13232.9871 - val_loss: 183.3505
Epoch 5/1000

Epoch 00005: val_loss did not improve from 34.63926
15/15 - 0s - loss: 28438.3539 - val_loss: 74.3071
Epoch 6/1000

Epoch 00006: val_loss improved from 34.63926 to 31.93313, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0_20191029-232301_best_model.h5
15/15 - 1s - loss: 26966.3271 - val_loss: 31.9331
Epoch 7/1000

Epoch 00007: val_loss improved from 31.93313 to 20.35177, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0_20191029-232301_best_model.h5
15/15 - 1s - loss: 4340.9520 - val_loss: 20.3518
Epoch 8/1000

Epoch 00008: val_loss improved from 20.35177 to 3.77154, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0_20191029-232301_best_model.h5
15/15 - 1s - loss: 14138.8905 - val_loss: 3.7715
Epoch 9/1000

Epoch 00009: val_loss improved from 3.77154 to 2.44734, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0_20191029-232301_best_model.h5
15/15 - 1s - loss: 4397.0450 - val_loss: 2.4473
Epoch 10/1000

Epoch 00010: val_loss did not improve from 2.44734
15/15 - 0s - loss: 3827.0246 - val_loss: 11.1341
Epoch 11/1000

Epoch 00011: val_loss did not improve from 2.44734
15/15 - 0s - loss: 6073.3210 - val_loss: 8.6460
Epoch 12/1000

Epoch 00012: val_loss did not improve from 2.44734
15/15 - 0s - loss: 386.7627 - val_loss: 3.9362
Epoch 13/1000

Epoch 00013: val_loss did not improve from 2.44734
15/15 - 1s - loss: 3387.7338 - val_loss: 4.1106
Epoch 14/1000

Epoch 00014: val_loss did not improve from 2.44734
15/15 - 1s - loss: 2582.1992 - val_loss: 9.8369
Epoch 15/1000

Epoch 00015: val_loss did not improve from 2.44734
15/15 - 0s - loss: 474.8051 - val_loss: 16.6776
Epoch 16/1000

Epoch 00016: val_loss did not improve from 2.44734
15/15 - 1s - loss: 2453.8187 - val_loss: 16.3747
Epoch 17/1000

Epoch 00017: val_loss did not improve from 2.44734
15/15 - 0s - loss: 901.4050 - val_loss: 11.8068
Epoch 18/1000

Epoch 00018: val_loss did not improve from 2.44734
15/15 - 0s - loss: 776.3989 - val_loss: 10.1482
Epoch 19/1000

Epoch 00019: val_loss did not improve from 2.44734
15/15 - 1s - loss: 1294.0319 - val_loss: 11.6656
Epoch 20/1000

Epoch 00020: val_loss did not improve from 2.44734
15/15 - 1s - loss: 173.8151 - val_loss: 13.6844
Epoch 21/1000

Epoch 00021: val_loss did not improve from 2.44734
15/15 - 1s - loss: 801.5404 - val_loss: 13.1513
Epoch 22/1000

Epoch 00022: val_loss did not improve from 2.44734
15/15 - 1s - loss: 493.6003 - val_loss: 10.9491
Epoch 23/1000

Epoch 00023: val_loss did not improve from 2.44734
15/15 - 0s - loss: 135.2093 - val_loss: 9.6349
Epoch 24/1000

Epoch 00024: val_loss did not improve from 2.44734
15/15 - 0s - loss: 450.1799 - val_loss: 9.5393
Epoch 25/1000

Epoch 00025: val_loss did not improve from 2.44734
15/15 - 0s - loss: 83.5150 - val_loss: 9.7032
Epoch 26/1000

Epoch 00026: val_loss did not improve from 2.44734
15/15 - 0s - loss: 223.1439 - val_loss: 9.1470
Epoch 27/1000

Epoch 00027: val_loss did not improve from 2.44734
15/15 - 0s - loss: 143.4652 - val_loss: 8.2596
Epoch 28/1000

Epoch 00028: val_loss did not improve from 2.44734
15/15 - 0s - loss: 74.0582 - val_loss: 7.7087
Epoch 29/1000

Epoch 00029: val_loss did not improve from 2.44734
15/15 - 0s - loss: 155.8390 - val_loss: 7.5487
Epoch 00029: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      153.801631
Mean squared error (MSE):       52923.552521
Root mean squared error (RMSE): 230.051195
R square (R^2):                 -22.871320
[  9316.32451758    203.684775     9949.93000307 192224.2707883 ]
##############################################
   Model8_filters_2_dense_0_denseSize_16_Dropout_0.4_20191029-232328
##############################################
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 567, 756, 16)      448       
_________________________________________________________________
activation_2 (Activation)    (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 283, 378, 16)      0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 283, 378, 32)      4640      
_________________________________________________________________
activation_3 (Activation)    (None, 283, 378, 32)      0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 283, 378, 32)      128       
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 141, 189, 32)      0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 852768)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 3411076   
=================================================================
Total params: 3,416,356
Trainable params: 3,416,260
Non-trainable params: 96
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/1000
2019-10-29 23:23:30.179828: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 23:23:30.346350: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 110 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 199.59985, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.4_20191029-232328_best_model.h5
15/15 - 1s - loss: 88478.9765 - val_loss: 199.5999
Epoch 2/1000

Epoch 00002: val_loss did not improve from 199.59985
15/15 - 0s - loss: 24729.4029 - val_loss: 996.9512
Epoch 3/1000

Epoch 00003: val_loss did not improve from 199.59985
15/15 - 1s - loss: 73385.5987 - val_loss: 6188.2852
Epoch 4/1000

Epoch 00004: val_loss did not improve from 199.59985
15/15 - 1s - loss: 5338.0776 - val_loss: 16804.4492
Epoch 5/1000

Epoch 00005: val_loss did not improve from 199.59985
15/15 - 1s - loss: 35638.7961 - val_loss: 10482.6484
Epoch 6/1000

Epoch 00006: val_loss did not improve from 199.59985
15/15 - 1s - loss: 15894.2406 - val_loss: 2152.1250
Epoch 7/1000

Epoch 00007: val_loss improved from 199.59985 to 127.14931, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.4_20191029-232328_best_model.h5
15/15 - 1s - loss: 5033.5199 - val_loss: 127.1493
Epoch 8/1000

Epoch 00008: val_loss improved from 127.14931 to 39.82817, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.4_20191029-232328_best_model.h5
15/15 - 1s - loss: 18233.4275 - val_loss: 39.8282
Epoch 9/1000

Epoch 00009: val_loss did not improve from 39.82817
15/15 - 0s - loss: 7305.1255 - val_loss: 65.1461
Epoch 10/1000

Epoch 00010: val_loss did not improve from 39.82817
15/15 - 1s - loss: 2387.5007 - val_loss: 110.7310
Epoch 11/1000

Epoch 00011: val_loss did not improve from 39.82817
15/15 - 1s - loss: 9057.3145 - val_loss: 213.4734
Epoch 12/1000

Epoch 00012: val_loss did not improve from 39.82817
15/15 - 1s - loss: 4376.8296 - val_loss: 359.7914
Epoch 13/1000

Epoch 00013: val_loss did not improve from 39.82817
15/15 - 0s - loss: 799.7447 - val_loss: 492.6908
Epoch 14/1000

Epoch 00014: val_loss did not improve from 39.82817
15/15 - 0s - loss: 4383.3674 - val_loss: 540.6821
Epoch 15/1000

Epoch 00015: val_loss did not improve from 39.82817
15/15 - 1s - loss: 2924.1996 - val_loss: 522.7017
Epoch 16/1000

Epoch 00016: val_loss did not improve from 39.82817
15/15 - 0s - loss: 440.6318 - val_loss: 504.8468
Epoch 17/1000

Epoch 00017: val_loss did not improve from 39.82817
15/15 - 0s - loss: 2135.1438 - val_loss: 501.1188
Epoch 18/1000

Epoch 00018: val_loss did not improve from 39.82817
15/15 - 0s - loss: 1759.4871 - val_loss: 503.9887
Epoch 19/1000

Epoch 00019: val_loss did not improve from 39.82817
15/15 - 0s - loss: 212.7830 - val_loss: 507.9286
Epoch 20/1000

Epoch 00020: val_loss did not improve from 39.82817
15/15 - 1s - loss: 1090.5985 - val_loss: 503.9493
Epoch 21/1000

Epoch 00021: val_loss did not improve from 39.82817
15/15 - 1s - loss: 961.2627 - val_loss: 488.4512
Epoch 22/1000

Epoch 00022: val_loss did not improve from 39.82817
15/15 - 0s - loss: 138.9845 - val_loss: 471.0484
Epoch 23/1000

Epoch 00023: val_loss did not improve from 39.82817
15/15 - 0s - loss: 599.6894 - val_loss: 453.9229
Epoch 24/1000

Epoch 00024: val_loss did not improve from 39.82817
15/15 - 0s - loss: 501.7890 - val_loss: 438.3893
Epoch 25/1000

Epoch 00025: val_loss did not improve from 39.82817
15/15 - 0s - loss: 87.0583 - val_loss: 425.6571
Epoch 26/1000

Epoch 00026: val_loss did not improve from 39.82817
15/15 - 0s - loss: 371.5964 - val_loss: 412.4947
Epoch 27/1000

Epoch 00027: val_loss did not improve from 39.82817
15/15 - 0s - loss: 264.8504 - val_loss: 397.5560
Epoch 28/1000

Epoch 00028: val_loss did not improve from 39.82817
15/15 - 0s - loss: 60.5323 - val_loss: 382.9047
Epoch 00028: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      480.581079
Mean squared error (MSE):       767777.562311
Root mean squared error (RMSE): 876.229172
R square (R^2):                 -3304.042539
[3.03549313e+06 2.05819764e+02 4.81311720e+02 3.49299910e+04]
##############################################
   Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348
##############################################
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 567, 756, 16)      448       
_________________________________________________________________
activation_4 (Activation)    (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_4 (Batch (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 283, 378, 16)      0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 283, 378, 32)      4640      
_________________________________________________________________
activation_5 (Activation)    (None, 283, 378, 32)      0         
_________________________________________________________________
batch_normalization_5 (Batch (None, 283, 378, 32)      128       
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 141, 189, 32)      0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 852768)            0         
_________________________________________________________________
dense_2 (Dense)              (None, 4)                 3411076   
=================================================================
Total params: 3,416,356
Trainable params: 3,416,260
Non-trainable params: 96
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/1000
2019-10-29 23:23:49.487293: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 23:23:49.646857: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 110 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 73.51155, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348_best_model.h5
15/15 - 1s - loss: 105240.1210 - val_loss: 73.5116
Epoch 2/1000

Epoch 00002: val_loss did not improve from 73.51155
15/15 - 0s - loss: 25874.6656 - val_loss: 656.1647
Epoch 3/1000

Epoch 00003: val_loss did not improve from 73.51155
15/15 - 1s - loss: 78969.3299 - val_loss: 651.9562
Epoch 4/1000

Epoch 00004: val_loss did not improve from 73.51155
15/15 - 0s - loss: 8684.8259 - val_loss: 312.0960
Epoch 5/1000

Epoch 00005: val_loss did not improve from 73.51155
15/15 - 0s - loss: 36749.5581 - val_loss: 173.7154
Epoch 6/1000

Epoch 00006: val_loss did not improve from 73.51155
15/15 - 1s - loss: 14489.9771 - val_loss: 191.8564
Epoch 7/1000

Epoch 00007: val_loss did not improve from 73.51155
15/15 - 0s - loss: 10675.4833 - val_loss: 211.4970
Epoch 8/1000

Epoch 00008: val_loss did not improve from 73.51155
15/15 - 1s - loss: 16034.9693 - val_loss: 144.1487
Epoch 9/1000

Epoch 00009: val_loss did not improve from 73.51155
15/15 - 1s - loss: 1167.0133 - val_loss: 84.1940
Epoch 10/1000

Epoch 00010: val_loss improved from 73.51155 to 63.21307, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348_best_model.h5
15/15 - 1s - loss: 9161.8614 - val_loss: 63.2131
Epoch 11/1000

Epoch 00011: val_loss did not improve from 63.21307
15/15 - 0s - loss: 5496.0461 - val_loss: 65.5625
Epoch 12/1000

Epoch 00012: val_loss did not improve from 63.21307
15/15 - 0s - loss: 1715.7873 - val_loss: 65.7893
Epoch 13/1000

Epoch 00013: val_loss improved from 63.21307 to 54.49262, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348_best_model.h5
15/15 - 1s - loss: 5568.7326 - val_loss: 54.4926
Epoch 14/1000

Epoch 00014: val_loss improved from 54.49262 to 42.68833, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348_best_model.h5
15/15 - 1s - loss: 1176.4425 - val_loss: 42.6883
Epoch 15/1000

Epoch 00015: val_loss improved from 42.68833 to 33.69948, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348_best_model.h5
15/15 - 1s - loss: 2026.5820 - val_loss: 33.6995
Epoch 16/1000

Epoch 00016: val_loss improved from 33.69948 to 24.59390, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348_best_model.h5
15/15 - 1s - loss: 2650.6340 - val_loss: 24.5939
Epoch 17/1000

Epoch 00017: val_loss improved from 24.59390 to 17.67765, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348_best_model.h5
15/15 - 1s - loss: 395.5766 - val_loss: 17.6777
Epoch 18/1000

Epoch 00018: val_loss improved from 17.67765 to 13.74692, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348_best_model.h5
15/15 - 1s - loss: 1910.8256 - val_loss: 13.7469
Epoch 19/1000

Epoch 00019: val_loss improved from 13.74692 to 12.17882, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348_best_model.h5
15/15 - 1s - loss: 839.4388 - val_loss: 12.1788
Epoch 20/1000

Epoch 00020: val_loss improved from 12.17882 to 10.51287, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348_best_model.h5
15/15 - 1s - loss: 447.0116 - val_loss: 10.5129
Epoch 21/1000

Epoch 00021: val_loss improved from 10.51287 to 6.93745, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348_best_model.h5
15/15 - 1s - loss: 1067.5877 - val_loss: 6.9374
Epoch 22/1000

Epoch 00022: val_loss improved from 6.93745 to 3.79062, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348_best_model.h5
15/15 - 1s - loss: 145.0781 - val_loss: 3.7906
Epoch 23/1000

Epoch 00023: val_loss improved from 3.79062 to 2.62558, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348_best_model.h5
15/15 - 1s - loss: 615.5658 - val_loss: 2.6256
Epoch 24/1000

Epoch 00024: val_loss did not improve from 2.62558
15/15 - 0s - loss: 336.7590 - val_loss: 2.7719
Epoch 25/1000

Epoch 00025: val_loss did not improve from 2.62558
15/15 - 1s - loss: 176.0477 - val_loss: 2.6434
Epoch 26/1000

Epoch 00026: val_loss improved from 2.62558 to 1.43786, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348_best_model.h5
15/15 - 1s - loss: 421.0147 - val_loss: 1.4379
Epoch 27/1000

Epoch 00027: val_loss improved from 1.43786 to 0.54715, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348_best_model.h5
15/15 - 1s - loss: 78.6783 - val_loss: 0.5472
Epoch 28/1000

Epoch 00028: val_loss improved from 0.54715 to 0.38022, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348_best_model.h5
15/15 - 1s - loss: 262.0561 - val_loss: 0.3802
Epoch 29/1000

Epoch 00029: val_loss did not improve from 0.38022
15/15 - 0s - loss: 95.3866 - val_loss: 0.4644
Epoch 30/1000

Epoch 00030: val_loss did not improve from 0.38022
15/15 - 1s - loss: 94.9303 - val_loss: 0.3896
Epoch 31/1000

Epoch 00031: val_loss improved from 0.38022 to 0.23455, saving model to Models\Model8_filters_2_dense_0_denseSize_16_Dropout_0.6_20191029-232348_best_model.h5
15/15 - 1s - loss: 105.0833 - val_loss: 0.2345
Epoch 32/1000

Epoch 00032: val_loss did not improve from 0.23455
15/15 - 0s - loss: 40.2640 - val_loss: 0.3283
Epoch 33/1000

Epoch 00033: val_loss did not improve from 0.23455
15/15 - 0s - loss: 93.5111 - val_loss: 0.3206
Epoch 34/1000

Epoch 00034: val_loss did not improve from 0.23455
15/15 - 0s - loss: 11.8869 - val_loss: 0.2715
Epoch 35/1000

Epoch 00035: val_loss did not improve from 0.23455
15/15 - 0s - loss: 60.9596 - val_loss: 0.3396
Epoch 36/1000

Epoch 00036: val_loss did not improve from 0.23455
15/15 - 0s - loss: 18.8623 - val_loss: 0.5976
Epoch 37/1000

Epoch 00037: val_loss did not improve from 0.23455
15/15 - 0s - loss: 33.5965 - val_loss: 0.7285
Epoch 38/1000

Epoch 00038: val_loss did not improve from 0.23455
15/15 - 0s - loss: 23.2555 - val_loss: 0.5752
Epoch 39/1000

Epoch 00039: val_loss did not improve from 0.23455
15/15 - 0s - loss: 11.4633 - val_loss: 0.5604
Epoch 40/1000

Epoch 00040: val_loss did not improve from 0.23455
15/15 - 0s - loss: 18.0990 - val_loss: 0.7903
Epoch 41/1000

Epoch 00041: val_loss did not improve from 0.23455
15/15 - 0s - loss: 3.0318 - val_loss: 1.0571
Epoch 42/1000

Epoch 00042: val_loss did not improve from 0.23455
15/15 - 0s - loss: 16.0970 - val_loss: 1.0216
Epoch 43/1000

Epoch 00043: val_loss did not improve from 0.23455
15/15 - 0s - loss: 2.1675 - val_loss: 0.9324
Epoch 44/1000

Epoch 00044: val_loss did not improve from 0.23455
15/15 - 0s - loss: 9.1392 - val_loss: 1.0573
Epoch 45/1000

Epoch 00045: val_loss did not improve from 0.23455
15/15 - 0s - loss: 3.4525 - val_loss: 1.3552
Epoch 46/1000

Epoch 00046: val_loss did not improve from 0.23455
15/15 - 0s - loss: 5.9991 - val_loss: 1.5036
Epoch 47/1000

Epoch 00047: val_loss did not improve from 0.23455
15/15 - 1s - loss: 3.4271 - val_loss: 1.4081
Epoch 48/1000

Epoch 00048: val_loss did not improve from 0.23455
15/15 - 0s - loss: 4.5800 - val_loss: 1.4428
Epoch 49/1000

Epoch 00049: val_loss did not improve from 0.23455
15/15 - 0s - loss: 3.5899 - val_loss: 1.7804
Epoch 50/1000

Epoch 00050: val_loss did not improve from 0.23455
15/15 - 0s - loss: 3.1575 - val_loss: 1.9754
Epoch 51/1000

Epoch 00051: val_loss did not improve from 0.23455
15/15 - 0s - loss: 2.6790 - val_loss: 1.8711
Epoch 00051: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      44.741559
Mean squared error (MSE):       9982.044877
Root mean squared error (RMSE): 99.910184
R square (R^2):                 -1.527107
[6.32319711e+02 1.35288228e+01 1.07056664e+03 3.82117643e+04]
##############################################
   Model8_filters_2_dense_0_denseSize_32_Dropout_0_20191029-232418
##############################################
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_4 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 567, 756, 16)      448       
_________________________________________________________________
activation_6 (Activation)    (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_6 (Batch (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 283, 378, 16)      0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 283, 378, 32)      4640      
_________________________________________________________________
activation_7 (Activation)    (None, 283, 378, 32)      0         
_________________________________________________________________
batch_normalization_7 (Batch (None, 283, 378, 32)      128       
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 141, 189, 32)      0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 852768)            0         
_________________________________________________________________
dense_3 (Dense)              (None, 4)                 3411076   
=================================================================
Total params: 3,416,356
Trainable params: 3,416,260
Non-trainable params: 96
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/1000
2019-10-29 23:24:19.742839: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 23:24:19.903687: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 110 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 22.59601, saving model to Models\Model8_filters_2_dense_0_denseSize_32_Dropout_0_20191029-232418_best_model.h5
15/15 - 1s - loss: 100032.8042 - val_loss: 22.5960
Epoch 2/1000

Epoch 00002: val_loss improved from 22.59601 to 3.27272, saving model to Models\Model8_filters_2_dense_0_denseSize_32_Dropout_0_20191029-232418_best_model.h5
15/15 - 1s - loss: 31166.2469 - val_loss: 3.2727
Epoch 3/1000

Epoch 00003: val_loss did not improve from 3.27272
15/15 - 1s - loss: 85540.3602 - val_loss: 395.1833
Epoch 4/1000

Epoch 00004: val_loss did not improve from 3.27272
15/15 - 1s - loss: 8861.5904 - val_loss: 1107.9558
Epoch 5/1000

Epoch 00005: val_loss did not improve from 3.27272
15/15 - 1s - loss: 37084.0474 - val_loss: 969.7521
Epoch 6/1000

Epoch 00006: val_loss did not improve from 3.27272
15/15 - 0s - loss: 18855.2955 - val_loss: 499.5411
Epoch 7/1000

Epoch 00007: val_loss did not improve from 3.27272
15/15 - 0s - loss: 5054.6561 - val_loss: 224.0636
Epoch 8/1000

Epoch 00008: val_loss did not improve from 3.27272
15/15 - 1s - loss: 18289.1594 - val_loss: 114.1150
Epoch 9/1000

Epoch 00009: val_loss did not improve from 3.27272
15/15 - 0s - loss: 5681.1984 - val_loss: 58.5711
Epoch 10/1000

Epoch 00010: val_loss did not improve from 3.27272
15/15 - 1s - loss: 3066.4268 - val_loss: 28.9132
Epoch 11/1000

Epoch 00011: val_loss did not improve from 3.27272
15/15 - 1s - loss: 8390.7797 - val_loss: 19.5652
Epoch 12/1000

Epoch 00012: val_loss did not improve from 3.27272
15/15 - 1s - loss: 2384.4813 - val_loss: 24.9475
Epoch 13/1000

Epoch 00013: val_loss did not improve from 3.27272
15/15 - 0s - loss: 2416.8897 - val_loss: 39.4468
Epoch 14/1000

Epoch 00014: val_loss did not improve from 3.27272
15/15 - 0s - loss: 4511.2204 - val_loss: 57.4861
Epoch 15/1000

Epoch 00015: val_loss did not improve from 3.27272
15/15 - 0s - loss: 1162.7492 - val_loss: 74.6725
Epoch 16/1000

Epoch 00016: val_loss did not improve from 3.27272
15/15 - 1s - loss: 1661.2939 - val_loss: 84.5453
Epoch 17/1000

Epoch 00017: val_loss did not improve from 3.27272
15/15 - 1s - loss: 2263.0579 - val_loss: 85.6168
Epoch 18/1000

Epoch 00018: val_loss did not improve from 3.27272
15/15 - 1s - loss: 496.7864 - val_loss: 86.5775
Epoch 19/1000

Epoch 00019: val_loss did not improve from 3.27272
15/15 - 0s - loss: 1076.4620 - val_loss: 92.0009
Epoch 20/1000

Epoch 00020: val_loss did not improve from 3.27272
15/15 - 0s - loss: 1144.2606 - val_loss: 99.5382
Epoch 21/1000

Epoch 00021: val_loss did not improve from 3.27272
15/15 - 0s - loss: 293.3524 - val_loss: 105.3114
Epoch 22/1000

Epoch 00022: val_loss did not improve from 3.27272
15/15 - 0s - loss: 727.3989 - val_loss: 104.2913
Epoch 00022: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      292.886515
Mean squared error (MSE):       208381.200769
Root mean squared error (RMSE): 456.487898
R square (R^2):                 -60.609234
[4.23143261e+04 2.19979727e+02 7.58415372e+03 7.83406343e+05]
##############################################
   Model8_filters_2_dense_0_denseSize_32_Dropout_0.4_20191029-232433
##############################################
Model: "model_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 567, 756, 16)      448       
_________________________________________________________________
activation_8 (Activation)    (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_8 (Batch (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 283, 378, 16)      0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 283, 378, 32)      4640      
_________________________________________________________________
activation_9 (Activation)    (None, 283, 378, 32)      0         
_________________________________________________________________
batch_normalization_9 (Batch (None, 283, 378, 32)      128       
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 141, 189, 32)      0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 852768)            0         
_________________________________________________________________
dense_4 (Dense)              (None, 4)                 3411076   
=================================================================
Total params: 3,416,356
Trainable params: 3,416,260
Non-trainable params: 96
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/1000
2019-10-29 23:24:34.911343: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 23:24:35.085243: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 110 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 446.63263, saving model to Models\Model8_filters_2_dense_0_denseSize_32_Dropout_0.4_20191029-232433_best_model.h5
15/15 - 1s - loss: 92249.8079 - val_loss: 446.6326
Epoch 2/1000

Epoch 00002: val_loss did not improve from 446.63263
15/15 - 0s - loss: 22966.2771 - val_loss: 4258.6465
Epoch 3/1000

Epoch 00003: val_loss did not improve from 446.63263
15/15 - 1s - loss: 81730.0966 - val_loss: 12248.2285
Epoch 4/1000

Epoch 00004: val_loss did not improve from 446.63263
15/15 - 1s - loss: 8087.1552 - val_loss: 22347.1797
Epoch 5/1000

Epoch 00005: val_loss did not improve from 446.63263
15/15 - 1s - loss: 37231.0008 - val_loss: 10956.4053
Epoch 6/1000

Epoch 00006: val_loss did not improve from 446.63263
15/15 - 1s - loss: 15892.9747 - val_loss: 464.8708
Epoch 7/1000

Epoch 00007: val_loss did not improve from 446.63263
15/15 - 1s - loss: 5682.0885 - val_loss: 1039.2878
Epoch 8/1000

Epoch 00008: val_loss did not improve from 446.63263
15/15 - 1s - loss: 18554.0969 - val_loss: 1320.9769
Epoch 9/1000

Epoch 00009: val_loss improved from 446.63263 to 330.60364, saving model to Models\Model8_filters_2_dense_0_denseSize_32_Dropout_0.4_20191029-232433_best_model.h5
15/15 - 1s - loss: 5265.4299 - val_loss: 330.6036
Epoch 10/1000

Epoch 00010: val_loss improved from 330.60364 to 125.35687, saving model to Models\Model8_filters_2_dense_0_denseSize_32_Dropout_0.4_20191029-232433_best_model.h5
15/15 - 1s - loss: 4240.7928 - val_loss: 125.3569
Epoch 11/1000

Epoch 00011: val_loss did not improve from 125.35687
15/15 - 1s - loss: 9723.5984 - val_loss: 629.8464
Epoch 12/1000

Epoch 00012: val_loss did not improve from 125.35687
15/15 - 1s - loss: 2094.7278 - val_loss: 2328.0713
Epoch 13/1000

Epoch 00013: val_loss did not improve from 125.35687
15/15 - 1s - loss: 2578.6167 - val_loss: 3743.8367
Epoch 14/1000

Epoch 00014: val_loss did not improve from 125.35687
15/15 - 1s - loss: 5184.8826 - val_loss: 3160.8213
Epoch 15/1000

Epoch 00015: val_loss did not improve from 125.35687
15/15 - 1s - loss: 1002.0353 - val_loss: 2004.3334
Epoch 16/1000

Epoch 00016: val_loss did not improve from 125.35687
15/15 - 0s - loss: 1376.3185 - val_loss: 1598.6431
Epoch 17/1000

Epoch 00017: val_loss did not improve from 125.35687
15/15 - 0s - loss: 2802.4159 - val_loss: 2046.5178
Epoch 18/1000

Epoch 00018: val_loss did not improve from 125.35687
15/15 - 0s - loss: 638.5237 - val_loss: 2953.2773
Epoch 19/1000

Epoch 00019: val_loss did not improve from 125.35687
15/15 - 0s - loss: 1153.8923 - val_loss: 3390.1323
Epoch 20/1000

Epoch 00020: val_loss did not improve from 125.35687
15/15 - 0s - loss: 1528.5989 - val_loss: 2916.0352
Epoch 21/1000

Epoch 00021: val_loss did not improve from 125.35687
15/15 - 0s - loss: 138.7638 - val_loss: 2353.3281
Epoch 22/1000

Epoch 00022: val_loss did not improve from 125.35687
15/15 - 0s - loss: 665.3379 - val_loss: 2183.7681
Epoch 23/1000

Epoch 00023: val_loss did not improve from 125.35687
15/15 - 0s - loss: 694.4372 - val_loss: 2486.9375
Epoch 24/1000

Epoch 00024: val_loss did not improve from 125.35687
15/15 - 1s - loss: 85.9111 - val_loss: 2864.2729
Epoch 25/1000

Epoch 00025: val_loss did not improve from 125.35687
15/15 - 0s - loss: 445.5160 - val_loss: 2867.5784
Epoch 26/1000

Epoch 00026: val_loss did not improve from 125.35687
15/15 - 0s - loss: 295.0278 - val_loss: 2537.2998
Epoch 27/1000

Epoch 00027: val_loss did not improve from 125.35687
15/15 - 0s - loss: 69.8434 - val_loss: 2282.4683
Epoch 28/1000

Epoch 00028: val_loss did not improve from 125.35687
15/15 - 0s - loss: 311.4836 - val_loss: 2310.1477
Epoch 29/1000

Epoch 00029: val_loss did not improve from 125.35687
15/15 - 0s - loss: 100.4530 - val_loss: 2502.4189
Epoch 30/1000

Epoch 00030: val_loss did not improve from 125.35687
15/15 - 0s - loss: 127.3435 - val_loss: 2592.6348
Epoch 00030: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      1754.289157
Mean squared error (MSE):       6108259.263716
Root mean squared error (RMSE): 2471.489281
R square (R^2):                 -4565.066496
[3.79435261e+06 6.18576519e+03 2.28588819e+05 2.04039099e+07]
##############################################
   Model8_filters_2_dense_0_denseSize_32_Dropout_0.6_20191029-232453
##############################################
Model: "model_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 567, 756, 16)      448       
_________________________________________________________________
activation_10 (Activation)   (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_10 (Batc (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 283, 378, 16)      0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 283, 378, 32)      4640      
_________________________________________________________________
activation_11 (Activation)   (None, 283, 378, 32)      0         
_________________________________________________________________
batch_normalization_11 (Batc (None, 283, 378, 32)      128       
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 141, 189, 32)      0         
_________________________________________________________________
flatten_5 (Flatten)          (None, 852768)            0         
_________________________________________________________________
dense_5 (Dense)              (None, 4)                 3411076   
=================================================================
Total params: 3,416,356
Trainable params: 3,416,260
Non-trainable params: 96
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/1000
2019-10-29 23:24:54.511273: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 23:24:54.670700: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 110 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 4.71247, saving model to Models\Model8_filters_2_dense_0_denseSize_32_Dropout_0.6_20191029-232453_best_model.h5
15/15 - 1s - loss: 109039.1459 - val_loss: 4.7125
Epoch 2/1000

Epoch 00002: val_loss did not improve from 4.71247
15/15 - 0s - loss: 30511.2336 - val_loss: 27.0529
Epoch 3/1000

Epoch 00003: val_loss did not improve from 4.71247
15/15 - 1s - loss: 91632.5599 - val_loss: 47.0000
Epoch 4/1000

Epoch 00004: val_loss did not improve from 4.71247
15/15 - 1s - loss: 8378.9004 - val_loss: 17.9220
Epoch 5/1000

Epoch 00005: val_loss improved from 4.71247 to 1.03996, saving model to Models\Model8_filters_2_dense_0_denseSize_32_Dropout_0.6_20191029-232453_best_model.h5
15/15 - 1s - loss: 34683.8898 - val_loss: 1.0400
Epoch 6/1000

Epoch 00006: val_loss improved from 1.03996 to 0.32264, saving model to Models\Model8_filters_2_dense_0_denseSize_32_Dropout_0.6_20191029-232453_best_model.h5
15/15 - 1s - loss: 22560.4564 - val_loss: 0.3226
Epoch 7/1000

Epoch 00007: val_loss did not improve from 0.32264
15/15 - 1s - loss: 4315.6340 - val_loss: 1.8350
Epoch 8/1000

Epoch 00008: val_loss did not improve from 0.32264
15/15 - 0s - loss: 20296.9496 - val_loss: 1.0228
Epoch 9/1000

Epoch 00009: val_loss did not improve from 0.32264
15/15 - 1s - loss: 5120.8046 - val_loss: 3.1926
Epoch 10/1000

Epoch 00010: val_loss did not improve from 0.32264
15/15 - 1s - loss: 3595.5053 - val_loss: 10.5311
Epoch 11/1000

Epoch 00011: val_loss did not improve from 0.32264
15/15 - 0s - loss: 4937.8265 - val_loss: 9.1986
Epoch 12/1000

Epoch 00012: val_loss did not improve from 0.32264
15/15 - 0s - loss: 1126.3931 - val_loss: 3.5396
Epoch 13/1000

Epoch 00013: val_loss did not improve from 0.32264
15/15 - 0s - loss: 782.2208 - val_loss: 0.8810
Epoch 14/1000

Epoch 00014: val_loss did not improve from 0.32264
15/15 - 0s - loss: 1962.2846 - val_loss: 1.5146
Epoch 15/1000

Epoch 00015: val_loss did not improve from 0.32264
15/15 - 0s - loss: 500.4804 - val_loss: 4.8115
Epoch 16/1000

Epoch 00016: val_loss did not improve from 0.32264
15/15 - 1s - loss: 457.5806 - val_loss: 7.5452
Epoch 17/1000

Epoch 00017: val_loss did not improve from 0.32264
15/15 - 0s - loss: 1097.0123 - val_loss: 6.2484
Epoch 18/1000

Epoch 00018: val_loss did not improve from 0.32264
15/15 - 0s - loss: 210.2490 - val_loss: 3.8546
Epoch 19/1000

Epoch 00019: val_loss did not improve from 0.32264
15/15 - 0s - loss: 455.8907 - val_loss: 3.0696
Epoch 20/1000

Epoch 00020: val_loss did not improve from 0.32264
15/15 - 0s - loss: 628.6982 - val_loss: 3.8625
Epoch 21/1000

Epoch 00021: val_loss did not improve from 0.32264
15/15 - 1s - loss: 86.0751 - val_loss: 5.1303
Epoch 22/1000

Epoch 00022: val_loss did not improve from 0.32264
15/15 - 0s - loss: 372.9949 - val_loss: 5.3680
Epoch 23/1000

Epoch 00023: val_loss did not improve from 0.32264
15/15 - 1s - loss: 281.2960 - val_loss: 4.6091
Epoch 24/1000

Epoch 00024: val_loss did not improve from 0.32264
15/15 - 0s - loss: 78.9544 - val_loss: 4.0121
Epoch 25/1000

Epoch 00025: val_loss did not improve from 0.32264
15/15 - 0s - loss: 284.0138 - val_loss: 4.0764
Epoch 26/1000

Epoch 00026: val_loss did not improve from 0.32264
15/15 - 0s - loss: 86.4175 - val_loss: 4.4048
Epoch 00026: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      61.672213
Mean squared error (MSE):       11177.153071
Root mean squared error (RMSE): 105.722056
R square (R^2):                 -1.424190
[1.18207751e+03 4.29378760e+01 4.55708608e+02 4.30278883e+04]
##############################################
   Model8_filters_2_dense_0_denseSize_64_Dropout_0_20191029-232509
##############################################
Model: "model_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 567, 756, 16)      448       
_________________________________________________________________
activation_12 (Activation)   (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_12 (Batc (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_12 (MaxPooling (None, 283, 378, 16)      0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 283, 378, 32)      4640      
_________________________________________________________________
activation_13 (Activation)   (None, 283, 378, 32)      0         
_________________________________________________________________
batch_normalization_13 (Batc (None, 283, 378, 32)      128       
_________________________________________________________________
max_pooling2d_13 (MaxPooling (None, 141, 189, 32)      0         
_________________________________________________________________
flatten_6 (Flatten)          (None, 852768)            0         
_________________________________________________________________
dense_6 (Dense)              (None, 4)                 3411076   
=================================================================
Total params: 3,416,356
Trainable params: 3,416,260
Non-trainable params: 96
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/1000
2019-10-29 23:25:10.877786: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 23:25:11.045066: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 110 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 310.46594, saving model to Models\Model8_filters_2_dense_0_denseSize_64_Dropout_0_20191029-232509_best_model.h5
15/15 - 1s - loss: 98086.6808 - val_loss: 310.4659
Epoch 2/1000

Epoch 00002: val_loss did not improve from 310.46594
15/15 - 0s - loss: 27072.4013 - val_loss: 374.6237
Epoch 3/1000

Epoch 00003: val_loss did not improve from 310.46594
15/15 - 1s - loss: 92793.3859 - val_loss: 1079.8311
Epoch 4/1000

Epoch 00004: val_loss did not improve from 310.46594
15/15 - 0s - loss: 8525.5906 - val_loss: 1355.1033
Epoch 5/1000

Epoch 00005: val_loss did not improve from 310.46594
15/15 - 0s - loss: 37126.4263 - val_loss: 874.2581
Epoch 6/1000

Epoch 00006: val_loss improved from 310.46594 to 200.20071, saving model to Models\Model8_filters_2_dense_0_denseSize_64_Dropout_0_20191029-232509_best_model.h5
15/15 - 1s - loss: 33107.7092 - val_loss: 200.2007
Epoch 7/1000

Epoch 00007: val_loss improved from 200.20071 to 118.59830, saving model to Models\Model8_filters_2_dense_0_denseSize_64_Dropout_0_20191029-232509_best_model.h5
15/15 - 1s - loss: 3157.4833 - val_loss: 118.5983
Epoch 8/1000

Epoch 00008: val_loss did not improve from 118.59830
15/15 - 1s - loss: 17230.6480 - val_loss: 226.2411
Epoch 9/1000

Epoch 00009: val_loss did not improve from 118.59830
15/15 - 1s - loss: 13773.9740 - val_loss: 214.1421
Epoch 10/1000

Epoch 00010: val_loss did not improve from 118.59830
15/15 - 1s - loss: 2015.4268 - val_loss: 203.9332
Epoch 11/1000

Epoch 00011: val_loss did not improve from 118.59830
15/15 - 1s - loss: 8114.5097 - val_loss: 258.6575
Epoch 12/1000

Epoch 00012: val_loss did not improve from 118.59830
15/15 - 1s - loss: 6683.1409 - val_loss: 380.0059
Epoch 13/1000

Epoch 00013: val_loss did not improve from 118.59830
15/15 - 0s - loss: 1074.5698 - val_loss: 512.1169
Epoch 14/1000

Epoch 00014: val_loss did not improve from 118.59830
15/15 - 0s - loss: 3963.5219 - val_loss: 539.9617
Epoch 15/1000

Epoch 00015: val_loss did not improve from 118.59830
15/15 - 1s - loss: 3709.6401 - val_loss: 445.8791
Epoch 16/1000

Epoch 00016: val_loss did not improve from 118.59830
15/15 - 1s - loss: 811.1698 - val_loss: 354.2074
Epoch 17/1000

Epoch 00017: val_loss did not improve from 118.59830
15/15 - 1s - loss: 1978.7864 - val_loss: 395.7957
Epoch 18/1000

Epoch 00018: val_loss did not improve from 118.59830
15/15 - 0s - loss: 2045.6626 - val_loss: 596.8427
Epoch 19/1000

Epoch 00019: val_loss did not improve from 118.59830
15/15 - 0s - loss: 501.5270 - val_loss: 864.9514
Epoch 20/1000

Epoch 00020: val_loss did not improve from 118.59830
15/15 - 0s - loss: 782.7699 - val_loss: 960.2793
Epoch 21/1000

Epoch 00021: val_loss did not improve from 118.59830
15/15 - 0s - loss: 1117.9243 - val_loss: 832.4127
Epoch 22/1000

Epoch 00022: val_loss did not improve from 118.59830
15/15 - 1s - loss: 337.5718 - val_loss: 635.4356
Epoch 23/1000

Epoch 00023: val_loss did not improve from 118.59830
15/15 - 1s - loss: 367.7017 - val_loss: 558.8823
Epoch 24/1000

Epoch 00024: val_loss did not improve from 118.59830
15/15 - 1s - loss: 619.0697 - val_loss: 634.7841
Epoch 25/1000

Epoch 00025: val_loss did not improve from 118.59830
15/15 - 1s - loss: 211.3783 - val_loss: 771.8392
Epoch 26/1000

Epoch 00026: val_loss did not improve from 118.59830
15/15 - 0s - loss: 179.5384 - val_loss: 832.2183
Epoch 27/1000

Epoch 00027: val_loss did not improve from 118.59830
15/15 - 0s - loss: 354.5806 - val_loss: 755.6646
Epoch 00027: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      2735.855369
Mean squared error (MSE):       29529913.787468
Root mean squared error (RMSE): 5434.143335
R square (R^2):                 -935.915002
[4.73829530e+02 1.37810952e+01 3.18690654e+03 1.18115981e+08]
##############################################
   Model8_filters_2_dense_0_denseSize_64_Dropout_0.4_20191029-232526
##############################################
Model: "model_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_8 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 567, 756, 16)      448       
_________________________________________________________________
activation_14 (Activation)   (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_14 (Batc (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_14 (MaxPooling (None, 283, 378, 16)      0         
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 283, 378, 32)      4640      
_________________________________________________________________
activation_15 (Activation)   (None, 283, 378, 32)      0         
_________________________________________________________________
batch_normalization_15 (Batc (None, 283, 378, 32)      128       
_________________________________________________________________
max_pooling2d_15 (MaxPooling (None, 141, 189, 32)      0         
_________________________________________________________________
flatten_7 (Flatten)          (None, 852768)            0         
_________________________________________________________________
dense_7 (Dense)              (None, 4)                 3411076   
=================================================================
Total params: 3,416,356
Trainable params: 3,416,260
Non-trainable params: 96
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/1000
2019-10-29 23:25:28.282780: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 23:25:28.451406: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 110 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 123.31092, saving model to Models\Model8_filters_2_dense_0_denseSize_64_Dropout_0.4_20191029-232526_best_model.h5
15/15 - 1s - loss: 108167.2155 - val_loss: 123.3109
Epoch 2/1000

Epoch 00002: val_loss did not improve from 123.31092
15/15 - 0s - loss: 28429.7687 - val_loss: 1613.2465
Epoch 3/1000

Epoch 00003: val_loss did not improve from 123.31092
15/15 - 0s - loss: 101786.2865 - val_loss: 4001.7012
Epoch 4/1000

Epoch 00004: val_loss did not improve from 123.31092
15/15 - 0s - loss: 11144.9153 - val_loss: 8004.0425
Epoch 5/1000

Epoch 00005: val_loss did not improve from 123.31092
15/15 - 0s - loss: 39745.4008 - val_loss: 5480.7656
Epoch 6/1000

Epoch 00006: val_loss did not improve from 123.31092
15/15 - 0s - loss: 23721.5952 - val_loss: 1275.1859
Epoch 7/1000

Epoch 00007: val_loss did not improve from 123.31092
15/15 - 1s - loss: 4683.8396 - val_loss: 169.0266
Epoch 8/1000

Epoch 00008: val_loss did not improve from 123.31092
15/15 - 1s - loss: 20103.7392 - val_loss: 181.2386
Epoch 9/1000

Epoch 00009: val_loss did not improve from 123.31092
15/15 - 1s - loss: 8114.1670 - val_loss: 130.2541
Epoch 10/1000

Epoch 00010: val_loss did not improve from 123.31092
15/15 - 1s - loss: 3500.5341 - val_loss: 127.1574
Epoch 11/1000

Epoch 00011: val_loss did not improve from 123.31092
15/15 - 1s - loss: 9226.2747 - val_loss: 166.2775
Epoch 12/1000

Epoch 00012: val_loss did not improve from 123.31092
15/15 - 0s - loss: 3763.9925 - val_loss: 244.4595
Epoch 13/1000

Epoch 00013: val_loss did not improve from 123.31092
15/15 - 1s - loss: 1166.9623 - val_loss: 326.2452
Epoch 14/1000

Epoch 00014: val_loss did not improve from 123.31092
15/15 - 1s - loss: 4155.8312 - val_loss: 375.4630
Epoch 15/1000

Epoch 00015: val_loss did not improve from 123.31092
15/15 - 1s - loss: 1771.3809 - val_loss: 405.0168
Epoch 16/1000

Epoch 00016: val_loss did not improve from 123.31092
15/15 - 1s - loss: 705.7962 - val_loss: 431.3352
Epoch 17/1000

Epoch 00017: val_loss did not improve from 123.31092
15/15 - 0s - loss: 2059.8723 - val_loss: 468.8036
Epoch 18/1000

Epoch 00018: val_loss did not improve from 123.31092
15/15 - 1s - loss: 853.7022 - val_loss: 512.8663
Epoch 19/1000

Epoch 00019: val_loss did not improve from 123.31092
15/15 - 1s - loss: 542.7540 - val_loss: 543.5752
Epoch 20/1000

Epoch 00020: val_loss did not improve from 123.31092
15/15 - 1s - loss: 1163.4756 - val_loss: 545.0737
Epoch 21/1000

Epoch 00021: val_loss did not improve from 123.31092
15/15 - 1s - loss: 450.0481 - val_loss: 525.8822
Epoch 00021: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      2014.856186
Mean squared error (MSE):       9450734.981496
Root mean squared error (RMSE): 3074.204772
R square (R^2):                 -3236.460720
[2.44872715e+06 5.88944697e+03 2.45219139e+05 3.51031042e+07]
##############################################
   Model8_filters_2_dense_0_denseSize_64_Dropout_0.6_20191029-232541
##############################################
Model: "model_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_9 (InputLayer)         [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_16 (Conv2D)           (None, 567, 756, 16)      448       
_________________________________________________________________
activation_16 (Activation)   (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_16 (Batc (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_16 (MaxPooling (None, 283, 378, 16)      0         
_________________________________________________________________
conv2d_17 (Conv2D)           (None, 283, 378, 32)      4640      
_________________________________________________________________
activation_17 (Activation)   (None, 283, 378, 32)      0         
_________________________________________________________________
batch_normalization_17 (Batc (None, 283, 378, 32)      128       
_________________________________________________________________
max_pooling2d_17 (MaxPooling (None, 141, 189, 32)      0         
_________________________________________________________________
flatten_8 (Flatten)          (None, 852768)            0         
_________________________________________________________________
dense_8 (Dense)              (None, 4)                 3411076   
=================================================================
Total params: 3,416,356
Trainable params: 3,416,260
Non-trainable params: 96
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/1000
2019-10-29 23:25:43.439188: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 23:25:43.599417: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 110 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 185.78561, saving model to Models\Model8_filters_2_dense_0_denseSize_64_Dropout_0.6_20191029-232541_best_model.h5
15/15 - 1s - loss: 91464.1571 - val_loss: 185.7856
Epoch 2/1000

Epoch 00002: val_loss did not improve from 185.78561
15/15 - 0s - loss: 24468.5456 - val_loss: 1742.9878
Epoch 3/1000

Epoch 00003: val_loss did not improve from 185.78561
15/15 - 1s - loss: 86595.7646 - val_loss: 4144.6821
Epoch 4/1000

Epoch 00004: val_loss did not improve from 185.78561
15/15 - 1s - loss: 11023.9506 - val_loss: 7798.3945
Epoch 5/1000

Epoch 00005: val_loss did not improve from 185.78561
15/15 - 1s - loss: 34042.2169 - val_loss: 4573.2988
Epoch 6/1000

Epoch 00006: val_loss did not improve from 185.78561
15/15 - 1s - loss: 18748.4667 - val_loss: 388.6306
Epoch 7/1000

Epoch 00007: val_loss did not improve from 185.78561
15/15 - 1s - loss: 9800.6713 - val_loss: 256.5746
Epoch 8/1000

Epoch 00008: val_loss did not improve from 185.78561
15/15 - 0s - loss: 20126.1791 - val_loss: 371.9818
Epoch 9/1000

Epoch 00009: val_loss improved from 185.78561 to 84.21823, saving model to Models\Model8_filters_2_dense_0_denseSize_64_Dropout_0.6_20191029-232541_best_model.h5
15/15 - 1s - loss: 4130.5360 - val_loss: 84.2182
Epoch 10/1000

Epoch 00010: val_loss did not improve from 84.21823
15/15 - 1s - loss: 5329.4331 - val_loss: 94.1820
Epoch 11/1000

Epoch 00011: val_loss did not improve from 84.21823
15/15 - 0s - loss: 9545.8182 - val_loss: 985.7908
Epoch 12/1000

Epoch 00012: val_loss did not improve from 84.21823
15/15 - 1s - loss: 1703.2096 - val_loss: 3469.7324
Epoch 13/1000

Epoch 00013: val_loss did not improve from 84.21823
15/15 - 1s - loss: 4202.7484 - val_loss: 5015.7915
Epoch 14/1000

Epoch 00014: val_loss did not improve from 84.21823
15/15 - 0s - loss: 4795.9636 - val_loss: 4097.1084
Epoch 15/1000

Epoch 00015: val_loss did not improve from 84.21823
15/15 - 1s - loss: 780.7116 - val_loss: 2912.1138
Epoch 16/1000

Epoch 00016: val_loss did not improve from 84.21823
15/15 - 1s - loss: 2895.4372 - val_loss: 2980.9309
Epoch 17/1000

Epoch 00017: val_loss did not improve from 84.21823
15/15 - 0s - loss: 2403.1829 - val_loss: 4436.2520
Epoch 18/1000

Epoch 00018: val_loss did not improve from 84.21823
15/15 - 0s - loss: 180.6270 - val_loss: 6044.5996
Epoch 19/1000

Epoch 00019: val_loss did not improve from 84.21823
15/15 - 0s - loss: 1513.0193 - val_loss: 6234.5723
Epoch 20/1000

Epoch 00020: val_loss did not improve from 84.21823
15/15 - 0s - loss: 831.4218 - val_loss: 5166.7139
Epoch 21/1000

Epoch 00021: val_loss did not improve from 84.21823
15/15 - 0s - loss: 186.7742 - val_loss: 4367.7715
Epoch 22/1000

Epoch 00022: val_loss did not improve from 84.21823
15/15 - 1s - loss: 980.2173 - val_loss: 4596.0645
Epoch 23/1000

Epoch 00023: val_loss did not improve from 84.21823
15/15 - 0s - loss: 371.9552 - val_loss: 5494.5083
Epoch 24/1000

Epoch 00024: val_loss did not improve from 84.21823
15/15 - 0s - loss: 294.6618 - val_loss: 5972.8545
Epoch 25/1000

Epoch 00025: val_loss did not improve from 84.21823
15/15 - 0s - loss: 564.4050 - val_loss: 5447.9502
Epoch 26/1000

Epoch 00026: val_loss did not improve from 84.21823
15/15 - 0s - loss: 84.6983 - val_loss: 4713.5674
Epoch 27/1000

Epoch 00027: val_loss did not improve from 84.21823
15/15 - 0s - loss: 230.3152 - val_loss: 4513.6733
Epoch 28/1000

Epoch 00028: val_loss did not improve from 84.21823
15/15 - 1s - loss: 212.7827 - val_loss: 4884.7476
Epoch 29/1000

Epoch 00029: val_loss did not improve from 84.21823
15/15 - 0s - loss: 27.4150 - val_loss: 5208.0239
Epoch 00029: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      1583.143898
Mean squared error (MSE):       5570426.893897
Root mean squared error (RMSE): 2360.175183
R square (R^2):                 -2237.450954
[1.66327998e+06 3.52548929e+03 2.21940221e+05 2.03929619e+07]
##############################################
   Model8_filters_2_dense_1_denseSize_16_Dropout_0_20191029-232600
##############################################
16
Model: "model_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_10 (InputLayer)        [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_18 (Conv2D)           (None, 567, 756, 16)      448       
_________________________________________________________________
activation_18 (Activation)   (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_18 (Batc (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_18 (MaxPooling (None, 283, 378, 16)      0         
_________________________________________________________________
conv2d_19 (Conv2D)           (None, 283, 378, 32)      4640      
_________________________________________________________________
activation_19 (Activation)   (None, 283, 378, 32)      0         
_________________________________________________________________
batch_normalization_19 (Batc (None, 283, 378, 32)      128       
_________________________________________________________________
max_pooling2d_19 (MaxPooling (None, 141, 189, 32)      0         
_________________________________________________________________
flatten_9 (Flatten)          (None, 852768)            0         
_________________________________________________________________
dense_9 (Dense)              (None, 16)                13644304  
_________________________________________________________________
activation_20 (Activation)   (None, 16)                0         
_________________________________________________________________
dropout (Dropout)            (None, 16)                0         
_________________________________________________________________
dense_10 (Dense)             (None, 4)                 68        
=================================================================
Total params: 13,649,652
Trainable params: 13,649,556
Non-trainable params: 96
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/1000
2019-10-29 23:26:02.206092: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 23:26:02.376602: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 124 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 8672.00195, saving model to Models\Model8_filters_2_dense_1_denseSize_16_Dropout_0_20191029-232600_best_model.h5
15/15 - 3s - loss: 141912.4999 - val_loss: 8672.0020
Epoch 2/1000

Epoch 00002: val_loss did not improve from 8672.00195
15/15 - 2s - loss: 6647.2891 - val_loss: 13238.9434
Epoch 3/1000

Epoch 00003: val_loss did not improve from 8672.00195
15/15 - 1s - loss: 0.3445 - val_loss: 17679.1367
Epoch 4/1000

Epoch 00004: val_loss did not improve from 8672.00195
15/15 - 1s - loss: 0.3450 - val_loss: 24130.1680
Epoch 5/1000

Epoch 00005: val_loss did not improve from 8672.00195
15/15 - 1s - loss: 0.3453 - val_loss: 31543.9668
Epoch 6/1000

Epoch 00006: val_loss did not improve from 8672.00195
15/15 - 2s - loss: 0.3456 - val_loss: 39251.1406
Epoch 7/1000

Epoch 00007: val_loss did not improve from 8672.00195
15/15 - 1s - loss: 0.3458 - val_loss: 46762.7734
Epoch 8/1000

Epoch 00008: val_loss did not improve from 8672.00195
15/15 - 1s - loss: 0.3460 - val_loss: 53763.1250
Epoch 9/1000

Epoch 00009: val_loss did not improve from 8672.00195
15/15 - 1s - loss: 0.3461 - val_loss: 60062.7930
Epoch 10/1000

Epoch 00010: val_loss did not improve from 8672.00195
15/15 - 1s - loss: 0.3462 - val_loss: 65572.3594
Epoch 11/1000

Epoch 00011: val_loss did not improve from 8672.00195
15/15 - 1s - loss: 0.3463 - val_loss: 70268.4062
Epoch 12/1000

Epoch 00012: val_loss did not improve from 8672.00195
15/15 - 0s - loss: 0.3464 - val_loss: 74173.1875
Epoch 13/1000

Epoch 00013: val_loss did not improve from 8672.00195
15/15 - 0s - loss: 0.3464 - val_loss: 77336.0938
Epoch 14/1000

Epoch 00014: val_loss did not improve from 8672.00195
15/15 - 0s - loss: 0.3465 - val_loss: 79822.6562
Epoch 15/1000

Epoch 00015: val_loss did not improve from 8672.00195
15/15 - 0s - loss: 0.3465 - val_loss: 81705.4531
Epoch 16/1000

Epoch 00016: val_loss did not improve from 8672.00195
15/15 - 0s - loss: 0.3465 - val_loss: 83057.5703
Epoch 17/1000

Epoch 00017: val_loss did not improve from 8672.00195
15/15 - 0s - loss: 0.3466 - val_loss: 83949.0781
Epoch 18/1000

Epoch 00018: val_loss did not improve from 8672.00195
15/15 - 0s - loss: 0.3466 - val_loss: 84445.5547
Epoch 19/1000

Epoch 00019: val_loss did not improve from 8672.00195
15/15 - 0s - loss: 0.3466 - val_loss: 84605.5391
Epoch 20/1000

Epoch 00020: val_loss did not improve from 8672.00195
15/15 - 0s - loss: 0.3466 - val_loss: 84481.9609
Epoch 21/1000

Epoch 00021: val_loss did not improve from 8672.00195
15/15 - 0s - loss: 0.3466 - val_loss: 84120.9062
Epoch 00021: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      15031.166212
Mean squared error (MSE):       673333966.144087
Root mean squared error (RMSE): 25948.679468
R square (R^2):                 -63317.805270
[3.62413933e+07 1.06458156e+06 2.43402640e+06 2.65359586e+09]
##############################################
   Model8_filters_2_dense_1_denseSize_16_Dropout_0.4_20191029-232621
##############################################
16
Model: "model_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_11 (InputLayer)        [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_20 (Conv2D)           (None, 567, 756, 16)      448       
_________________________________________________________________
activation_21 (Activation)   (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_20 (Batc (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_20 (MaxPooling (None, 283, 378, 16)      0         
_________________________________________________________________
conv2d_21 (Conv2D)           (None, 283, 378, 32)      4640      
_________________________________________________________________
activation_22 (Activation)   (None, 283, 378, 32)      0         
_________________________________________________________________
batch_normalization_21 (Batc (None, 283, 378, 32)      128       
_________________________________________________________________
max_pooling2d_21 (MaxPooling (None, 141, 189, 32)      0         
_________________________________________________________________
flatten_10 (Flatten)         (None, 852768)            0         
_________________________________________________________________
dense_11 (Dense)             (None, 16)                13644304  
_________________________________________________________________
activation_23 (Activation)   (None, 16)                0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 4)                 68        
=================================================================
Total params: 13,649,652
Trainable params: 13,649,556
Non-trainable params: 96
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/1000
2019-10-29 23:26:23.888822: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 23:26:24.078164: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 130 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 17.66208, saving model to Models\Model8_filters_2_dense_1_denseSize_16_Dropout_0.4_20191029-232621_best_model.h5
15/15 - 3s - loss: 28321.0878 - val_loss: 17.6621
Epoch 2/1000

Epoch 00002: val_loss improved from 17.66208 to 0.34216, saving model to Models\Model8_filters_2_dense_1_denseSize_16_Dropout_0.4_20191029-232621_best_model.h5
15/15 - 2s - loss: 5655.1885 - val_loss: 0.3422
Epoch 3/1000

Epoch 00003: val_loss did not improve from 0.34216
15/15 - 0s - loss: 0.3440 - val_loss: 103.6589
Epoch 4/1000

Epoch 00004: val_loss did not improve from 0.34216
15/15 - 1s - loss: 0.3443 - val_loss: 857.5360
Epoch 5/1000

Epoch 00005: val_loss did not improve from 0.34216
15/15 - 1s - loss: 0.3445 - val_loss: 2242.6067
Epoch 6/1000

Epoch 00006: val_loss did not improve from 0.34216
15/15 - 1s - loss: 0.3446 - val_loss: 4044.9167
Epoch 7/1000

Epoch 00007: val_loss did not improve from 0.34216
15/15 - 0s - loss: 0.3447 - val_loss: 6050.7842
Epoch 8/1000

Epoch 00008: val_loss did not improve from 0.34216
15/15 - 0s - loss: 0.3448 - val_loss: 8086.6958
Epoch 9/1000

Epoch 00009: val_loss did not improve from 0.34216
15/15 - 0s - loss: 0.3452 - val_loss: 9670.0332
Epoch 10/1000

Epoch 00010: val_loss did not improve from 0.34216
15/15 - 0s - loss: 0.3445 - val_loss: 11105.4570
Epoch 11/1000

Epoch 00011: val_loss did not improve from 0.34216
15/15 - 1s - loss: 6212.3439 - val_loss: 12097.1904
Epoch 12/1000

Epoch 00012: val_loss did not improve from 0.34216
15/15 - 0s - loss: 0.3453 - val_loss: 12741.3359
Epoch 13/1000

Epoch 00013: val_loss did not improve from 0.34216
15/15 - 0s - loss: 0.3456 - val_loss: 13243.8496
Epoch 14/1000

Epoch 00014: val_loss did not improve from 0.34216
15/15 - 0s - loss: 0.3458 - val_loss: 13636.8369
Epoch 15/1000

Epoch 00015: val_loss did not improve from 0.34216
15/15 - 0s - loss: 0.3459 - val_loss: 13934.6035
Epoch 16/1000

Epoch 00016: val_loss did not improve from 0.34216
15/15 - 0s - loss: 0.3461 - val_loss: 14143.8516
Epoch 17/1000

Epoch 00017: val_loss did not improve from 0.34216
15/15 - 0s - loss: 0.3461 - val_loss: 14269.1230
Epoch 18/1000

Epoch 00018: val_loss did not improve from 0.34216
15/15 - 0s - loss: 0.3462 - val_loss: 14315.2773
Epoch 19/1000

Epoch 00019: val_loss did not improve from 0.34216
15/15 - 0s - loss: 0.3463 - val_loss: 14288.7559
Epoch 20/1000

Epoch 00020: val_loss did not improve from 0.34216
15/15 - 0s - loss: 0.3463 - val_loss: 14196.4736
Epoch 21/1000

Epoch 00021: val_loss did not improve from 0.34216
15/15 - 0s - loss: 0.3463 - val_loss: 14046.6582
Epoch 22/1000

Epoch 00022: val_loss did not improve from 0.34216
15/15 - 0s - loss: 0.3463 - val_loss: 13847.0732
Epoch 00022: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      70.429071
Mean squared error (MSE):       18181.595810
Root mean squared error (RMSE): 134.839148
R square (R^2):                 -5.135720
[3.99937318e+03 2.60961409e+01 8.29116860e+02 6.78717971e+04]
##############################################
   Model8_filters_2_dense_1_denseSize_16_Dropout_0.6_20191029-232641
##############################################
16
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
Model: "model_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_12 (InputLayer)        [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_22 (Conv2D)           (None, 567, 756, 16)      448       
_________________________________________________________________
activation_24 (Activation)   (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_22 (Batc (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_22 (MaxPooling (None, 283, 378, 16)      0         
_________________________________________________________________
conv2d_23 (Conv2D)           (None, 283, 378, 32)      4640      
_________________________________________________________________
activation_25 (Activation)   (None, 283, 378, 32)      0         
_________________________________________________________________
batch_normalization_23 (Batc (None, 283, 378, 32)      128       
_________________________________________________________________
max_pooling2d_23 (MaxPooling (None, 141, 189, 32)      0         
_________________________________________________________________
flatten_11 (Flatten)         (None, 852768)            0         
_________________________________________________________________
dense_13 (Dense)             (None, 16)                13644304  
_________________________________________________________________
activation_26 (Activation)   (None, 16)                0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_14 (Dense)             (None, 4)                 68        
=================================================================
Total params: 13,649,652
Trainable params: 13,649,556
Non-trainable params: 96
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/1000
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
2019-10-29 23:26:44.083618: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 23:26:44.253095: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 130 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 756.74573, saving model to Models\Model8_filters_2_dense_1_denseSize_16_Dropout_0.6_20191029-232641_best_model.h5
15/15 - 3s - loss: 6031.4452 - val_loss: 756.7457
Epoch 2/1000

Epoch 00002: val_loss did not improve from 756.74573
15/15 - 0s - loss: 18386.8365 - val_loss: 1578.1527
Epoch 3/1000

Epoch 00003: val_loss did not improve from 756.74573
15/15 - 1s - loss: 136.9939 - val_loss: 2430.5952
Epoch 4/1000

Epoch 00004: val_loss did not improve from 756.74573
15/15 - 1s - loss: 0.3429 - val_loss: 3237.6506
Epoch 5/1000

Epoch 00005: val_loss did not improve from 756.74573
15/15 - 1s - loss: 0.3526 - val_loss: 4185.1226
Epoch 6/1000

Epoch 00006: val_loss did not improve from 756.74573
15/15 - 1s - loss: 0.3384 - val_loss: 5208.4229
Epoch 7/1000

Epoch 00007: val_loss did not improve from 756.74573
15/15 - 1s - loss: 0.3428 - val_loss: 5985.3208
Epoch 8/1000

Epoch 00008: val_loss did not improve from 756.74573
15/15 - 1s - loss: 0.3428 - val_loss: 6660.6372
Epoch 9/1000

Epoch 00009: val_loss did not improve from 756.74573
15/15 - 1s - loss: 0.3428 - val_loss: 7199.6631
Epoch 10/1000

Epoch 00010: val_loss did not improve from 756.74573
15/15 - 1s - loss: 0.3428 - val_loss: 7596.5557
Epoch 11/1000

Epoch 00011: val_loss did not improve from 756.74573
15/15 - 1s - loss: 0.3427 - val_loss: 7858.4844
Epoch 12/1000

Epoch 00012: val_loss did not improve from 756.74573
15/15 - 0s - loss: 0.3427 - val_loss: 7999.9863
Epoch 13/1000

Epoch 00013: val_loss did not improve from 756.74573
15/15 - 1s - loss: 0.3426 - val_loss: 8033.5342
Epoch 14/1000

Epoch 00014: val_loss did not improve from 756.74573
15/15 - 1s - loss: 0.3426 - val_loss: 7974.5215
Epoch 15/1000

Epoch 00015: val_loss did not improve from 756.74573
15/15 - 1s - loss: 0.3426 - val_loss: 7840.5625
Epoch 16/1000

Epoch 00016: val_loss did not improve from 756.74573
15/15 - 1s - loss: 0.3425 - val_loss: 7645.3364
Epoch 17/1000

Epoch 00017: val_loss did not improve from 756.74573
15/15 - 1s - loss: 0.3425 - val_loss: 7419.7104
Epoch 18/1000

Epoch 00018: val_loss did not improve from 756.74573
15/15 - 1s - loss: 0.3424 - val_loss: 7152.0869
Epoch 19/1000

Epoch 00019: val_loss did not improve from 756.74573
15/15 - 1s - loss: 0.3424 - val_loss: 6851.2607
Epoch 20/1000

Epoch 00020: val_loss did not improve from 756.74573
15/15 - 1s - loss: 0.3423 - val_loss: 6525.6685
Epoch 21/1000

Epoch 00021: val_loss did not improve from 756.74573
15/15 - 1s - loss: 0.3423 - val_loss: 6182.9834
Epoch 00021: early stopping
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      2174.454277
Mean squared error (MSE):       11635591.424141
Root mean squared error (RMSE): 3411.098272
R square (R^2):                 -2176.174153
[ 1472023.92442866   135573.40301771   184209.79199356 44750558.57712346]
##############################################
   Model8_filters_2_dense_1_denseSize_32_Dropout_0_20191029-232707
##############################################
32
Model: "model_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_13 (InputLayer)        [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_24 (Conv2D)           (None, 567, 756, 16)      448       
_________________________________________________________________
activation_27 (Activation)   (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_24 (Batc (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_24 (MaxPooling (None, 283, 378, 16)      0         
_________________________________________________________________
conv2d_25 (Conv2D)           (None, 283, 378, 32)      4640      
_________________________________________________________________
activation_28 (Activation)   (None, 283, 378, 32)      0         
_________________________________________________________________
batch_normalization_25 (Batc (None, 283, 378, 32)      128       
_________________________________________________________________
max_pooling2d_25 (MaxPooling (None, 141, 189, 32)      0         
_________________________________________________________________
flatten_12 (Flatten)         (None, 852768)            0         
_________________________________________________________________
dense_15 (Dense)             (None, 32)                27288608  
_________________________________________________________________
activation_29 (Activation)   (None, 32)                0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_16 (Dense)             (None, 4)                 132       
=================================================================
Total params: 27,294,020
Trainable params: 27,293,924
Non-trainable params: 96
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/1000
2019-10-29 23:27:09.983822: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 23:27:10.172131: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 124 kernel records, 11 memcpy records.

Epoch 00001: val_loss improved from inf to 15433.99805, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0_20191029-232707_best_model.h5
15/15 - 5s - loss: 205082.6174 - val_loss: 15433.9980
Epoch 2/1000

Epoch 00002: val_loss did not improve from 15433.99805
15/15 - 0s - loss: 10494.2851 - val_loss: 26598.7539
Epoch 3/1000

Epoch 00003: val_loss did not improve from 15433.99805
15/15 - 0s - loss: 1703.0456 - val_loss: 40060.8555
Epoch 4/1000

Epoch 00004: val_loss did not improve from 15433.99805
15/15 - 1s - loss: 0.3450 - val_loss: 56232.4570
Epoch 5/1000

Epoch 00005: val_loss did not improve from 15433.99805
15/15 - 1s - loss: 0.3458 - val_loss: 73939.9531
Epoch 6/1000

Epoch 00006: val_loss did not improve from 15433.99805
15/15 - 1s - loss: 0.3453 - val_loss: 92003.8438
Epoch 7/1000

Epoch 00007: val_loss did not improve from 15433.99805
15/15 - 1s - loss: 0.3455 - val_loss: 108303.6719
Epoch 8/1000

Epoch 00008: val_loss did not improve from 15433.99805
15/15 - 1s - loss: 0.3455 - val_loss: 122536.2031
Epoch 9/1000

Epoch 00009: val_loss did not improve from 15433.99805
15/15 - 0s - loss: 0.3461 - val_loss: 132749.7500
Epoch 10/1000

Epoch 00010: val_loss did not improve from 15433.99805
15/15 - 0s - loss: 0.3457 - val_loss: 139666.4062
Epoch 11/1000

Epoch 00011: val_loss did not improve from 15433.99805
15/15 - 1s - loss: 0.3457 - val_loss: 145443.7500
Epoch 12/1000

Epoch 00012: val_loss did not improve from 15433.99805
15/15 - 1s - loss: 0.3458 - val_loss: 150095.6875
Epoch 13/1000

Epoch 00013: val_loss did not improve from 15433.99805
15/15 - 0s - loss: 0.3458 - val_loss: 153692.7500
Epoch 14/1000

Epoch 00014: val_loss did not improve from 15433.99805
15/15 - 0s - loss: 0.3458 - val_loss: 156330.8125
Epoch 15/1000

Epoch 00015: val_loss did not improve from 15433.99805
15/15 - 0s - loss: 0.3458 - val_loss: 158118.2812
Epoch 16/1000

Epoch 00016: val_loss did not improve from 15433.99805
15/15 - 0s - loss: 0.3458 - val_loss: 159164.5938
Epoch 17/1000

Epoch 00017: val_loss did not improve from 15433.99805
15/15 - 1s - loss: 0.3458 - val_loss: 159572.5000
Epoch 18/1000

Epoch 00018: val_loss did not improve from 15433.99805
15/15 - 1s - loss: 0.3458 - val_loss: 159437.5312
Epoch 19/1000

Epoch 00019: val_loss did not improve from 15433.99805
15/15 - 1s - loss: 0.3458 - val_loss: 158845.5781
Epoch 20/1000

Epoch 00020: val_loss did not improve from 15433.99805
15/15 - 0s - loss: 0.3458 - val_loss: 157871.9375
Epoch 21/1000

Epoch 00021: val_loss did not improve from 15433.99805
15/15 - 1s - loss: 0.3457 - val_loss: 156581.9375
Epoch 00021: early stopping
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      27152.509409
Mean squared error (MSE):       2389733424.693492
Root mean squared error (RMSE): 48884.899762
R square (R^2):                 -145160.428792
[5.62802342e+07 8.82056329e+05 7.45414713e+06 9.49431726e+09]
##############################################
   Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731
##############################################
32
Model: "model_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_14 (InputLayer)        [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_26 (Conv2D)           (None, 567, 756, 16)      448       
_________________________________________________________________
activation_30 (Activation)   (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_26 (Batc (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_26 (MaxPooling (None, 283, 378, 16)      0         
_________________________________________________________________
conv2d_27 (Conv2D)           (None, 283, 378, 32)      4640      
_________________________________________________________________
activation_31 (Activation)   (None, 283, 378, 32)      0         
_________________________________________________________________
batch_normalization_27 (Batc (None, 283, 378, 32)      128       
_________________________________________________________________
max_pooling2d_27 (MaxPooling (None, 141, 189, 32)      0         
_________________________________________________________________
flatten_13 (Flatten)         (None, 852768)            0         
_________________________________________________________________
dense_17 (Dense)             (None, 32)                27288608  
_________________________________________________________________
activation_32 (Activation)   (None, 32)                0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_18 (Dense)             (None, 4)                 132       
=================================================================
Total params: 27,294,020
Trainable params: 27,293,924
Non-trainable params: 96
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/1000

Epoch 00001: val_loss improved from inf to 431.78082, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
2019-10-29 23:27:33.560390: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
2019-10-29 23:27:33.734683: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 130 kernel records, 11 memcpy records.
15/15 - 6s - loss: 183104.6845 - val_loss: 431.7808
Epoch 2/1000

Epoch 00002: val_loss did not improve from 431.78082
15/15 - 1s - loss: 15820.0873 - val_loss: 575.9312
Epoch 3/1000

Epoch 00003: val_loss did not improve from 431.78082
15/15 - 1s - loss: 1781.1313 - val_loss: 796.7319
Epoch 4/1000

Epoch 00004: val_loss did not improve from 431.78082
15/15 - 0s - loss: 0.3439 - val_loss: 984.0989
Epoch 5/1000

Epoch 00005: val_loss did not improve from 431.78082
15/15 - 0s - loss: 0.3444 - val_loss: 1091.9978
Epoch 6/1000

Epoch 00006: val_loss did not improve from 431.78082
15/15 - 1s - loss: 0.3447 - val_loss: 1204.7803
Epoch 7/1000

Epoch 00007: val_loss did not improve from 431.78082
15/15 - 1s - loss: 0.3450 - val_loss: 1279.1990
Epoch 8/1000

Epoch 00008: val_loss did not improve from 431.78082
15/15 - 1s - loss: 0.3452 - val_loss: 1310.5901
Epoch 9/1000

Epoch 00009: val_loss did not improve from 431.78082
15/15 - 1s - loss: 0.3453 - val_loss: 1305.9292
Epoch 10/1000

Epoch 00010: val_loss did not improve from 431.78082
15/15 - 1s - loss: 0.3455 - val_loss: 1282.2944
Epoch 11/1000

Epoch 00011: val_loss did not improve from 431.78082
15/15 - 0s - loss: 0.3456 - val_loss: 1237.2676
Epoch 12/1000

Epoch 00012: val_loss did not improve from 431.78082
15/15 - 1s - loss: 0.3457 - val_loss: 1172.8890
Epoch 13/1000

Epoch 00013: val_loss did not improve from 431.78082
15/15 - 1s - loss: 0.3458 - val_loss: 1110.5919
Epoch 14/1000

Epoch 00014: val_loss did not improve from 431.78082
15/15 - 1s - loss: 0.3458 - val_loss: 1034.4904
Epoch 15/1000

Epoch 00015: val_loss did not improve from 431.78082
15/15 - 1s - loss: 0.3458 - val_loss: 948.4825
Epoch 16/1000

Epoch 00016: val_loss did not improve from 431.78082
15/15 - 1s - loss: 0.3458 - val_loss: 856.1858
Epoch 17/1000

Epoch 00017: val_loss did not improve from 431.78082
15/15 - 0s - loss: 0.3458 - val_loss: 760.7155
Epoch 18/1000

Epoch 00018: val_loss did not improve from 431.78082
15/15 - 0s - loss: 0.3458 - val_loss: 664.8643
Epoch 19/1000

Epoch 00019: val_loss did not improve from 431.78082
15/15 - 0s - loss: 0.3458 - val_loss: 570.8836
Epoch 20/1000

Epoch 00020: val_loss did not improve from 431.78082
15/15 - 0s - loss: 0.3458 - val_loss: 480.6549
Epoch 21/1000

Epoch 00021: val_loss improved from 431.78082 to 395.67496, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3458 - val_loss: 395.6750
Epoch 22/1000

Epoch 00022: val_loss improved from 395.67496 to 317.17181, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3458 - val_loss: 317.1718
Epoch 23/1000

Epoch 00023: val_loss improved from 317.17181 to 246.10080, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3458 - val_loss: 246.1008
Epoch 24/1000

Epoch 00024: val_loss improved from 246.10080 to 183.23300, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3458 - val_loss: 183.2330
Epoch 25/1000

Epoch 00025: val_loss improved from 183.23300 to 124.27602, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3457 - val_loss: 124.2760
Epoch 26/1000

Epoch 00026: val_loss improved from 124.27602 to 76.00393, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3457 - val_loss: 76.0039
Epoch 27/1000

Epoch 00027: val_loss improved from 76.00393 to 40.26729, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3457 - val_loss: 40.2673
Epoch 28/1000

Epoch 00028: val_loss improved from 40.26729 to 17.30889, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3456 - val_loss: 17.3089
Epoch 29/1000

Epoch 00029: val_loss improved from 17.30889 to 5.30697, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3456 - val_loss: 5.3070
Epoch 30/1000

Epoch 00030: val_loss improved from 5.30697 to 0.54268, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3456 - val_loss: 0.5427
Epoch 31/1000

Epoch 00031: val_loss improved from 0.54268 to 0.37281, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3455 - val_loss: 0.3728
Epoch 32/1000

Epoch 00032: val_loss did not improve from 0.37281
15/15 - 1s - loss: 0.3455 - val_loss: 0.3810
Epoch 33/1000

Epoch 00033: val_loss did not improve from 0.37281
15/15 - 1s - loss: 0.3454 - val_loss: 0.3796
Epoch 34/1000

Epoch 00034: val_loss did not improve from 0.37281
15/15 - 0s - loss: 0.3454 - val_loss: 0.3783
Epoch 35/1000

Epoch 00035: val_loss did not improve from 0.37281
15/15 - 1s - loss: 0.3454 - val_loss: 0.3771
Epoch 36/1000

Epoch 00036: val_loss did not improve from 0.37281
15/15 - 0s - loss: 0.3453 - val_loss: 0.3760
Epoch 37/1000

Epoch 00037: val_loss did not improve from 0.37281
15/15 - 0s - loss: 0.3453 - val_loss: 0.3749
Epoch 38/1000

Epoch 00038: val_loss did not improve from 0.37281
15/15 - 1s - loss: 0.3452 - val_loss: 0.3738
Epoch 39/1000

Epoch 00039: val_loss did not improve from 0.37281
15/15 - 0s - loss: 0.3452 - val_loss: 0.3728
Epoch 40/1000

Epoch 00040: val_loss improved from 0.37281 to 0.37185, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3451 - val_loss: 0.3718
Epoch 41/1000

Epoch 00041: val_loss improved from 0.37185 to 0.37086, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3451 - val_loss: 0.3709
Epoch 42/1000

Epoch 00042: val_loss improved from 0.37086 to 0.36986, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3450 - val_loss: 0.3699
Epoch 43/1000

Epoch 00043: val_loss improved from 0.36986 to 0.36882, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3450 - val_loss: 0.3688
Epoch 44/1000

Epoch 00044: val_loss improved from 0.36882 to 0.36777, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3449 - val_loss: 0.3678
Epoch 45/1000

Epoch 00045: val_loss improved from 0.36777 to 0.36674, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3449 - val_loss: 0.3667
Epoch 46/1000

Epoch 00046: val_loss improved from 0.36674 to 0.36570, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3448 - val_loss: 0.3657
Epoch 47/1000

Epoch 00047: val_loss improved from 0.36570 to 0.36468, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3448 - val_loss: 0.3647
Epoch 48/1000

Epoch 00048: val_loss improved from 0.36468 to 0.36367, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3447 - val_loss: 0.3637
Epoch 49/1000

Epoch 00049: val_loss improved from 0.36367 to 0.36266, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3447 - val_loss: 0.3627
Epoch 50/1000

Epoch 00050: val_loss improved from 0.36266 to 0.36166, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3446 - val_loss: 0.3617
Epoch 51/1000

Epoch 00051: val_loss improved from 0.36166 to 0.36067, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3446 - val_loss: 0.3607
Epoch 52/1000

Epoch 00052: val_loss improved from 0.36067 to 0.35969, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3445 - val_loss: 0.3597
Epoch 53/1000

Epoch 00053: val_loss improved from 0.35969 to 0.35872, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3445 - val_loss: 0.3587
Epoch 54/1000

Epoch 00054: val_loss improved from 0.35872 to 0.35774, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3444 - val_loss: 0.3577
Epoch 55/1000

Epoch 00055: val_loss improved from 0.35774 to 0.35675, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 9s - loss: 0.3444 - val_loss: 0.3568
Epoch 56/1000

Epoch 00056: val_loss improved from 0.35675 to 0.35576, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3443 - val_loss: 0.3558
Epoch 57/1000

Epoch 00057: val_loss improved from 0.35576 to 0.35477, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3442 - val_loss: 0.3548
Epoch 58/1000

Epoch 00058: val_loss improved from 0.35477 to 0.35379, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3442 - val_loss: 0.3538
Epoch 59/1000

Epoch 00059: val_loss improved from 0.35379 to 0.35282, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3441 - val_loss: 0.3528
Epoch 60/1000

Epoch 00060: val_loss improved from 0.35282 to 0.35184, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3441 - val_loss: 0.3518
Epoch 61/1000

Epoch 00061: val_loss improved from 0.35184 to 0.35088, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3440 - val_loss: 0.3509
Epoch 62/1000

Epoch 00062: val_loss improved from 0.35088 to 0.34991, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3439 - val_loss: 0.3499
Epoch 63/1000

Epoch 00063: val_loss improved from 0.34991 to 0.34899, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3439 - val_loss: 0.3490
Epoch 64/1000

Epoch 00064: val_loss improved from 0.34899 to 0.34821, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3438 - val_loss: 0.3482
Epoch 65/1000

Epoch 00065: val_loss improved from 0.34821 to 0.34748, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3438 - val_loss: 0.3475
Epoch 66/1000

Epoch 00066: val_loss improved from 0.34748 to 0.34681, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3437 - val_loss: 0.3468
Epoch 67/1000

Epoch 00067: val_loss improved from 0.34681 to 0.34614, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3436 - val_loss: 0.3461
Epoch 68/1000

Epoch 00068: val_loss improved from 0.34614 to 0.34546, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3436 - val_loss: 0.3455
Epoch 69/1000

Epoch 00069: val_loss improved from 0.34546 to 0.34493, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3435 - val_loss: 0.3449
Epoch 70/1000

Epoch 00070: val_loss improved from 0.34493 to 0.34463, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3435 - val_loss: 0.3446
Epoch 71/1000

Epoch 00071: val_loss improved from 0.34463 to 0.34434, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3434 - val_loss: 0.3443
Epoch 72/1000

Epoch 00072: val_loss improved from 0.34434 to 0.34405, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3433 - val_loss: 0.3441
Epoch 73/1000

Epoch 00073: val_loss improved from 0.34405 to 0.34376, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3433 - val_loss: 0.3438
Epoch 74/1000

Epoch 00074: val_loss improved from 0.34376 to 0.34366, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3432 - val_loss: 0.3437
Epoch 75/1000

Epoch 00075: val_loss improved from 0.34366 to 0.34358, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3431 - val_loss: 0.3436
Epoch 76/1000

Epoch 00076: val_loss improved from 0.34358 to 0.34349, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3431 - val_loss: 0.3435
Epoch 77/1000

Epoch 00077: val_loss improved from 0.34349 to 0.34340, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3430 - val_loss: 0.3434
Epoch 78/1000

Epoch 00078: val_loss improved from 0.34340 to 0.34331, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3429 - val_loss: 0.3433
Epoch 79/1000

Epoch 00079: val_loss improved from 0.34331 to 0.34322, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3429 - val_loss: 0.3432
Epoch 80/1000

Epoch 00080: val_loss improved from 0.34322 to 0.34313, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3428 - val_loss: 0.3431
Epoch 81/1000

Epoch 00081: val_loss improved from 0.34313 to 0.34303, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3427 - val_loss: 0.3430
Epoch 82/1000

Epoch 00082: val_loss improved from 0.34303 to 0.34294, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3427 - val_loss: 0.3429
Epoch 83/1000

Epoch 00083: val_loss improved from 0.34294 to 0.34284, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3426 - val_loss: 0.3428
Epoch 84/1000

Epoch 00084: val_loss improved from 0.34284 to 0.34275, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3425 - val_loss: 0.3427
Epoch 85/1000

Epoch 00085: val_loss improved from 0.34275 to 0.34271, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3424 - val_loss: 0.3427
Epoch 86/1000

Epoch 00086: val_loss improved from 0.34271 to 0.34267, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3424 - val_loss: 0.3427
Epoch 87/1000

Epoch 00087: val_loss improved from 0.34267 to 0.34263, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3423 - val_loss: 0.3426
Epoch 88/1000

Epoch 00088: val_loss improved from 0.34263 to 0.34258, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3422 - val_loss: 0.3426
Epoch 89/1000

Epoch 00089: val_loss improved from 0.34258 to 0.34253, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3422 - val_loss: 0.3425
Epoch 90/1000

Epoch 00090: val_loss improved from 0.34253 to 0.34247, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3421 - val_loss: 0.3425
Epoch 91/1000

Epoch 00091: val_loss improved from 0.34247 to 0.34241, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3420 - val_loss: 0.3424
Epoch 92/1000

Epoch 00092: val_loss improved from 0.34241 to 0.34235, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3419 - val_loss: 0.3423
Epoch 93/1000

Epoch 00093: val_loss improved from 0.34235 to 0.34229, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3419 - val_loss: 0.3423
Epoch 94/1000

Epoch 00094: val_loss improved from 0.34229 to 0.34223, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3418 - val_loss: 0.3422
Epoch 95/1000

Epoch 00095: val_loss improved from 0.34223 to 0.34218, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3417 - val_loss: 0.3422
Epoch 96/1000

Epoch 00096: val_loss improved from 0.34218 to 0.34212, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3417 - val_loss: 0.3421
Epoch 97/1000

Epoch 00097: val_loss improved from 0.34212 to 0.34206, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3416 - val_loss: 0.3421
Epoch 98/1000

Epoch 00098: val_loss improved from 0.34206 to 0.34200, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3415 - val_loss: 0.3420
Epoch 99/1000

Epoch 00099: val_loss improved from 0.34200 to 0.34194, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3414 - val_loss: 0.3419
Epoch 100/1000

Epoch 00100: val_loss improved from 0.34194 to 0.34189, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3413 - val_loss: 0.3419
Epoch 101/1000

Epoch 00101: val_loss improved from 0.34189 to 0.34183, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3413 - val_loss: 0.3418
Epoch 102/1000

Epoch 00102: val_loss improved from 0.34183 to 0.34178, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3412 - val_loss: 0.3418
Epoch 103/1000

Epoch 00103: val_loss improved from 0.34178 to 0.34174, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3411 - val_loss: 0.3417
Epoch 104/1000

Epoch 00104: val_loss improved from 0.34174 to 0.34169, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3410 - val_loss: 0.3417
Epoch 105/1000

Epoch 00105: val_loss improved from 0.34169 to 0.34164, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3410 - val_loss: 0.3416
Epoch 106/1000

Epoch 00106: val_loss improved from 0.34164 to 0.34159, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3409 - val_loss: 0.3416
Epoch 107/1000

Epoch 00107: val_loss improved from 0.34159 to 0.34154, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3408 - val_loss: 0.3415
Epoch 108/1000

Epoch 00108: val_loss improved from 0.34154 to 0.34149, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3407 - val_loss: 0.3415
Epoch 109/1000

Epoch 00109: val_loss improved from 0.34149 to 0.34143, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3406 - val_loss: 0.3414
Epoch 110/1000

Epoch 00110: val_loss improved from 0.34143 to 0.34137, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3406 - val_loss: 0.3414
Epoch 111/1000

Epoch 00111: val_loss improved from 0.34137 to 0.34131, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3405 - val_loss: 0.3413
Epoch 112/1000

Epoch 00112: val_loss improved from 0.34131 to 0.34126, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3404 - val_loss: 0.3413
Epoch 113/1000

Epoch 00113: val_loss improved from 0.34126 to 0.34120, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3403 - val_loss: 0.3412
Epoch 114/1000

Epoch 00114: val_loss improved from 0.34120 to 0.34114, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3402 - val_loss: 0.3411
Epoch 115/1000

Epoch 00115: val_loss improved from 0.34114 to 0.34108, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3402 - val_loss: 0.3411
Epoch 116/1000

Epoch 00116: val_loss improved from 0.34108 to 0.34102, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3401 - val_loss: 0.3410
Epoch 117/1000

Epoch 00117: val_loss improved from 0.34102 to 0.34096, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3400 - val_loss: 0.3410
Epoch 118/1000

Epoch 00118: val_loss improved from 0.34096 to 0.34090, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3399 - val_loss: 0.3409
Epoch 119/1000

Epoch 00119: val_loss improved from 0.34090 to 0.34085, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3398 - val_loss: 0.3408
Epoch 120/1000

Epoch 00120: val_loss improved from 0.34085 to 0.34079, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 8s - loss: 0.3397 - val_loss: 0.3408
Epoch 121/1000

Epoch 00121: val_loss improved from 0.34079 to 0.34073, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3397 - val_loss: 0.3407
Epoch 122/1000

Epoch 00122: val_loss improved from 0.34073 to 0.34067, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3396 - val_loss: 0.3407
Epoch 123/1000

Epoch 00123: val_loss improved from 0.34067 to 0.34061, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3395 - val_loss: 0.3406
Epoch 124/1000

Epoch 00124: val_loss improved from 0.34061 to 0.34056, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3394 - val_loss: 0.3406
Epoch 125/1000

Epoch 00125: val_loss improved from 0.34056 to 0.34050, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3393 - val_loss: 0.3405
Epoch 126/1000

Epoch 00126: val_loss improved from 0.34050 to 0.34044, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3392 - val_loss: 0.3404
Epoch 127/1000

Epoch 00127: val_loss improved from 0.34044 to 0.34038, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3392 - val_loss: 0.3404
Epoch 128/1000

Epoch 00128: val_loss improved from 0.34038 to 0.34032, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3391 - val_loss: 0.3403
Epoch 129/1000

Epoch 00129: val_loss improved from 0.34032 to 0.34026, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3390 - val_loss: 0.3403
Epoch 130/1000

Epoch 00130: val_loss improved from 0.34026 to 0.34020, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3389 - val_loss: 0.3402
Epoch 131/1000

Epoch 00131: val_loss improved from 0.34020 to 0.34014, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3388 - val_loss: 0.3401
Epoch 132/1000

Epoch 00132: val_loss improved from 0.34014 to 0.34008, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3387 - val_loss: 0.3401
Epoch 133/1000

Epoch 00133: val_loss improved from 0.34008 to 0.34002, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3386 - val_loss: 0.3400
Epoch 134/1000

Epoch 00134: val_loss improved from 0.34002 to 0.33998, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3385 - val_loss: 0.3400
Epoch 135/1000

Epoch 00135: val_loss improved from 0.33998 to 0.33994, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3385 - val_loss: 0.3399
Epoch 136/1000

Epoch 00136: val_loss improved from 0.33994 to 0.33990, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3384 - val_loss: 0.3399
Epoch 137/1000

Epoch 00137: val_loss improved from 0.33990 to 0.33987, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3383 - val_loss: 0.3399
Epoch 138/1000

Epoch 00138: val_loss improved from 0.33987 to 0.33983, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3382 - val_loss: 0.3398
Epoch 139/1000

Epoch 00139: val_loss improved from 0.33983 to 0.33979, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3381 - val_loss: 0.3398
Epoch 140/1000

Epoch 00140: val_loss improved from 0.33979 to 0.33975, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3380 - val_loss: 0.3398
Epoch 141/1000

Epoch 00141: val_loss improved from 0.33975 to 0.33970, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3379 - val_loss: 0.3397
Epoch 142/1000

Epoch 00142: val_loss improved from 0.33970 to 0.33963, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3378 - val_loss: 0.3396
Epoch 143/1000

Epoch 00143: val_loss improved from 0.33963 to 0.33957, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3377 - val_loss: 0.3396
Epoch 144/1000

Epoch 00144: val_loss improved from 0.33957 to 0.33950, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3376 - val_loss: 0.3395
Epoch 145/1000

Epoch 00145: val_loss improved from 0.33950 to 0.33944, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3375 - val_loss: 0.3394
Epoch 146/1000

Epoch 00146: val_loss improved from 0.33944 to 0.33938, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3375 - val_loss: 0.3394
Epoch 147/1000

Epoch 00147: val_loss improved from 0.33938 to 0.33931, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3374 - val_loss: 0.3393
Epoch 148/1000

Epoch 00148: val_loss improved from 0.33931 to 0.33925, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3373 - val_loss: 0.3392
Epoch 149/1000

Epoch 00149: val_loss improved from 0.33925 to 0.33918, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3372 - val_loss: 0.3392
Epoch 150/1000

Epoch 00150: val_loss improved from 0.33918 to 0.33911, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3371 - val_loss: 0.3391
Epoch 151/1000

Epoch 00151: val_loss improved from 0.33911 to 0.33905, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3370 - val_loss: 0.3390
Epoch 152/1000

Epoch 00152: val_loss improved from 0.33905 to 0.33898, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3369 - val_loss: 0.3390
Epoch 153/1000

Epoch 00153: val_loss improved from 0.33898 to 0.33891, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3368 - val_loss: 0.3389
Epoch 154/1000

Epoch 00154: val_loss improved from 0.33891 to 0.33884, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3367 - val_loss: 0.3388
Epoch 155/1000

Epoch 00155: val_loss improved from 0.33884 to 0.33877, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3366 - val_loss: 0.3388
Epoch 156/1000

Epoch 00156: val_loss improved from 0.33877 to 0.33870, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 8s - loss: 0.3365 - val_loss: 0.3387
Epoch 157/1000

Epoch 00157: val_loss improved from 0.33870 to 0.33863, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3364 - val_loss: 0.3386
Epoch 158/1000

Epoch 00158: val_loss improved from 0.33863 to 0.33856, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3363 - val_loss: 0.3386
Epoch 159/1000

Epoch 00159: val_loss improved from 0.33856 to 0.33849, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3362 - val_loss: 0.3385
Epoch 160/1000

Epoch 00160: val_loss improved from 0.33849 to 0.33842, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3361 - val_loss: 0.3384
Epoch 161/1000

Epoch 00161: val_loss improved from 0.33842 to 0.33834, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3360 - val_loss: 0.3383
Epoch 162/1000

Epoch 00162: val_loss improved from 0.33834 to 0.33827, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3359 - val_loss: 0.3383
Epoch 163/1000

Epoch 00163: val_loss improved from 0.33827 to 0.33820, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3358 - val_loss: 0.3382
Epoch 164/1000

Epoch 00164: val_loss improved from 0.33820 to 0.33812, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3357 - val_loss: 0.3381
Epoch 165/1000

Epoch 00165: val_loss improved from 0.33812 to 0.33805, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3356 - val_loss: 0.3380
Epoch 166/1000

Epoch 00166: val_loss improved from 0.33805 to 0.33797, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3355 - val_loss: 0.3380
Epoch 167/1000

Epoch 00167: val_loss improved from 0.33797 to 0.33789, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3354 - val_loss: 0.3379
Epoch 168/1000

Epoch 00168: val_loss improved from 0.33789 to 0.33782, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3353 - val_loss: 0.3378
Epoch 169/1000

Epoch 00169: val_loss improved from 0.33782 to 0.33774, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3352 - val_loss: 0.3377
Epoch 170/1000

Epoch 00170: val_loss improved from 0.33774 to 0.33767, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3351 - val_loss: 0.3377
Epoch 171/1000

Epoch 00171: val_loss improved from 0.33767 to 0.33759, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3350 - val_loss: 0.3376
Epoch 172/1000

Epoch 00172: val_loss improved from 0.33759 to 0.33751, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3349 - val_loss: 0.3375
Epoch 173/1000

Epoch 00173: val_loss improved from 0.33751 to 0.33744, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3348 - val_loss: 0.3374
Epoch 174/1000

Epoch 00174: val_loss improved from 0.33744 to 0.33736, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3347 - val_loss: 0.3374
Epoch 175/1000

Epoch 00175: val_loss improved from 0.33736 to 0.33729, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3346 - val_loss: 0.3373
Epoch 176/1000

Epoch 00176: val_loss improved from 0.33729 to 0.33721, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3345 - val_loss: 0.3372
Epoch 177/1000

Epoch 00177: val_loss improved from 0.33721 to 0.33713, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3344 - val_loss: 0.3371
Epoch 178/1000

Epoch 00178: val_loss improved from 0.33713 to 0.33705, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3343 - val_loss: 0.3371
Epoch 179/1000

Epoch 00179: val_loss improved from 0.33705 to 0.33697, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 10s - loss: 0.3342 - val_loss: 0.3370
Epoch 180/1000

Epoch 00180: val_loss improved from 0.33697 to 0.33689, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3341 - val_loss: 0.3369
Epoch 181/1000

Epoch 00181: val_loss improved from 0.33689 to 0.33681, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3340 - val_loss: 0.3368
Epoch 182/1000

Epoch 00182: val_loss improved from 0.33681 to 0.33673, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3339 - val_loss: 0.3367
Epoch 183/1000

Epoch 00183: val_loss improved from 0.33673 to 0.33665, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3338 - val_loss: 0.3367
Epoch 184/1000

Epoch 00184: val_loss improved from 0.33665 to 0.33657, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3337 - val_loss: 0.3366
Epoch 185/1000

Epoch 00185: val_loss improved from 0.33657 to 0.33649, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3336 - val_loss: 0.3365
Epoch 186/1000

Epoch 00186: val_loss improved from 0.33649 to 0.33641, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3335 - val_loss: 0.3364
Epoch 187/1000

Epoch 00187: val_loss improved from 0.33641 to 0.33633, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3334 - val_loss: 0.3363
Epoch 188/1000

Epoch 00188: val_loss improved from 0.33633 to 0.33625, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3333 - val_loss: 0.3362
Epoch 189/1000

Epoch 00189: val_loss improved from 0.33625 to 0.33617, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 8s - loss: 0.3332 - val_loss: 0.3362
Epoch 190/1000

Epoch 00190: val_loss improved from 0.33617 to 0.33608, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3331 - val_loss: 0.3361
Epoch 191/1000

Epoch 00191: val_loss improved from 0.33608 to 0.33600, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3330 - val_loss: 0.3360
Epoch 192/1000

Epoch 00192: val_loss improved from 0.33600 to 0.33591, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3329 - val_loss: 0.3359
Epoch 193/1000

Epoch 00193: val_loss improved from 0.33591 to 0.33583, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3328 - val_loss: 0.3358
Epoch 194/1000

Epoch 00194: val_loss improved from 0.33583 to 0.33575, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3327 - val_loss: 0.3357
Epoch 195/1000

Epoch 00195: val_loss improved from 0.33575 to 0.33566, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3326 - val_loss: 0.3357
Epoch 196/1000

Epoch 00196: val_loss improved from 0.33566 to 0.33558, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3325 - val_loss: 0.3356
Epoch 197/1000

Epoch 00197: val_loss improved from 0.33558 to 0.33549, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3323 - val_loss: 0.3355
Epoch 198/1000

Epoch 00198: val_loss improved from 0.33549 to 0.33541, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3322 - val_loss: 0.3354
Epoch 199/1000

Epoch 00199: val_loss improved from 0.33541 to 0.33532, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 9s - loss: 0.3321 - val_loss: 0.3353
Epoch 200/1000

Epoch 00200: val_loss improved from 0.33532 to 0.33524, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3320 - val_loss: 0.3352
Epoch 201/1000

Epoch 00201: val_loss improved from 0.33524 to 0.33515, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3319 - val_loss: 0.3352
Epoch 202/1000

Epoch 00202: val_loss improved from 0.33515 to 0.33507, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3318 - val_loss: 0.3351
Epoch 203/1000

Epoch 00203: val_loss improved from 0.33507 to 0.33498, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3317 - val_loss: 0.3350
Epoch 204/1000

Epoch 00204: val_loss improved from 0.33498 to 0.33489, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3316 - val_loss: 0.3349
Epoch 205/1000

Epoch 00205: val_loss improved from 0.33489 to 0.33481, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3315 - val_loss: 0.3348
Epoch 206/1000

Epoch 00206: val_loss improved from 0.33481 to 0.33472, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3314 - val_loss: 0.3347
Epoch 207/1000

Epoch 00207: val_loss improved from 0.33472 to 0.33463, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3313 - val_loss: 0.3346
Epoch 208/1000

Epoch 00208: val_loss improved from 0.33463 to 0.33454, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3312 - val_loss: 0.3345
Epoch 209/1000

Epoch 00209: val_loss improved from 0.33454 to 0.33446, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3310 - val_loss: 0.3345
Epoch 210/1000

Epoch 00210: val_loss improved from 0.33446 to 0.33437, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3309 - val_loss: 0.3344
Epoch 211/1000

Epoch 00211: val_loss improved from 0.33437 to 0.33428, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3308 - val_loss: 0.3343
Epoch 212/1000

Epoch 00212: val_loss improved from 0.33428 to 0.33419, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3307 - val_loss: 0.3342
Epoch 213/1000

Epoch 00213: val_loss improved from 0.33419 to 0.33409, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3306 - val_loss: 0.3341
Epoch 214/1000

Epoch 00214: val_loss improved from 0.33409 to 0.33400, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3305 - val_loss: 0.3340
Epoch 215/1000

Epoch 00215: val_loss improved from 0.33400 to 0.33391, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3304 - val_loss: 0.3339
Epoch 216/1000

Epoch 00216: val_loss improved from 0.33391 to 0.33382, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3303 - val_loss: 0.3338
Epoch 217/1000

Epoch 00217: val_loss improved from 0.33382 to 0.33373, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3301 - val_loss: 0.3337
Epoch 218/1000

Epoch 00218: val_loss improved from 0.33373 to 0.33364, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3300 - val_loss: 0.3336
Epoch 219/1000

Epoch 00219: val_loss improved from 0.33364 to 0.33354, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 10s - loss: 0.3299 - val_loss: 0.3335
Epoch 220/1000

Epoch 00220: val_loss improved from 0.33354 to 0.33345, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3298 - val_loss: 0.3335
Epoch 221/1000

Epoch 00221: val_loss improved from 0.33345 to 0.33336, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3297 - val_loss: 0.3334
Epoch 222/1000

Epoch 00222: val_loss improved from 0.33336 to 0.33327, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3296 - val_loss: 0.3333
Epoch 223/1000

Epoch 00223: val_loss improved from 0.33327 to 0.33317, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3295 - val_loss: 0.3332
Epoch 224/1000

Epoch 00224: val_loss improved from 0.33317 to 0.33308, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3294 - val_loss: 0.3331
Epoch 225/1000

Epoch 00225: val_loss improved from 0.33308 to 0.33299, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3292 - val_loss: 0.3330
Epoch 226/1000

Epoch 00226: val_loss improved from 0.33299 to 0.33289, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3291 - val_loss: 0.3329
Epoch 227/1000

Epoch 00227: val_loss improved from 0.33289 to 0.33280, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3290 - val_loss: 0.3328
Epoch 228/1000

Epoch 00228: val_loss improved from 0.33280 to 0.33269, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3289 - val_loss: 0.3327
Epoch 229/1000

Epoch 00229: val_loss improved from 0.33269 to 0.33258, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3288 - val_loss: 0.3326
Epoch 230/1000

Epoch 00230: val_loss improved from 0.33258 to 0.33246, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3287 - val_loss: 0.3325
Epoch 231/1000

Epoch 00231: val_loss improved from 0.33246 to 0.33235, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3285 - val_loss: 0.3323
Epoch 232/1000

Epoch 00232: val_loss improved from 0.33235 to 0.33223, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3284 - val_loss: 0.3322
Epoch 233/1000

Epoch 00233: val_loss improved from 0.33223 to 0.33212, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3283 - val_loss: 0.3321
Epoch 234/1000

Epoch 00234: val_loss improved from 0.33212 to 0.33201, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3282 - val_loss: 0.3320
Epoch 235/1000

Epoch 00235: val_loss improved from 0.33201 to 0.33189, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3281 - val_loss: 0.3319
Epoch 236/1000

Epoch 00236: val_loss improved from 0.33189 to 0.33178, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3280 - val_loss: 0.3318
Epoch 237/1000

Epoch 00237: val_loss improved from 0.33178 to 0.33167, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3278 - val_loss: 0.3317
Epoch 238/1000

Epoch 00238: val_loss improved from 0.33167 to 0.33155, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3277 - val_loss: 0.3316
Epoch 239/1000

Epoch 00239: val_loss improved from 0.33155 to 0.33144, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3276 - val_loss: 0.3314
Epoch 240/1000

Epoch 00240: val_loss improved from 0.33144 to 0.33132, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3275 - val_loss: 0.3313
Epoch 241/1000

Epoch 00241: val_loss improved from 0.33132 to 0.33120, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 8s - loss: 0.3274 - val_loss: 0.3312
Epoch 242/1000

Epoch 00242: val_loss improved from 0.33120 to 0.33109, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3273 - val_loss: 0.3311
Epoch 243/1000

Epoch 00243: val_loss improved from 0.33109 to 0.33097, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3271 - val_loss: 0.3310
Epoch 244/1000

Epoch 00244: val_loss improved from 0.33097 to 0.33085, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3270 - val_loss: 0.3309
Epoch 245/1000

Epoch 00245: val_loss improved from 0.33085 to 0.33073, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3269 - val_loss: 0.3307
Epoch 246/1000

Epoch 00246: val_loss improved from 0.33073 to 0.33061, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3268 - val_loss: 0.3306
Epoch 247/1000

Epoch 00247: val_loss improved from 0.33061 to 0.33049, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3267 - val_loss: 0.3305
Epoch 248/1000

Epoch 00248: val_loss improved from 0.33049 to 0.33037, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3265 - val_loss: 0.3304
Epoch 249/1000

Epoch 00249: val_loss improved from 0.33037 to 0.33025, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3264 - val_loss: 0.3303
Epoch 250/1000

Epoch 00250: val_loss improved from 0.33025 to 0.33013, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3263 - val_loss: 0.3301
Epoch 251/1000

Epoch 00251: val_loss improved from 0.33013 to 0.33001, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3262 - val_loss: 0.3300
Epoch 252/1000

Epoch 00252: val_loss improved from 0.33001 to 0.32989, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3261 - val_loss: 0.3299
Epoch 253/1000

Epoch 00253: val_loss improved from 0.32989 to 0.32977, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3259 - val_loss: 0.3298
Epoch 254/1000

Epoch 00254: val_loss improved from 0.32977 to 0.32965, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3258 - val_loss: 0.3297
Epoch 255/1000

Epoch 00255: val_loss improved from 0.32965 to 0.32953, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3257 - val_loss: 0.3295
Epoch 256/1000

Epoch 00256: val_loss improved from 0.32953 to 0.32941, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3256 - val_loss: 0.3294
Epoch 257/1000

Epoch 00257: val_loss improved from 0.32941 to 0.32929, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3255 - val_loss: 0.3293
Epoch 258/1000

Epoch 00258: val_loss improved from 0.32929 to 0.32917, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3253 - val_loss: 0.3292
Epoch 259/1000

Epoch 00259: val_loss improved from 0.32917 to 0.32905, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3252 - val_loss: 0.3291
Epoch 260/1000

Epoch 00260: val_loss improved from 0.32905 to 0.32893, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3251 - val_loss: 0.3289
Epoch 261/1000

Epoch 00261: val_loss improved from 0.32893 to 0.32881, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3250 - val_loss: 0.3288
Epoch 262/1000

Epoch 00262: val_loss improved from 0.32881 to 0.32869, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3248 - val_loss: 0.3287
Epoch 263/1000

Epoch 00263: val_loss improved from 0.32869 to 0.32857, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3247 - val_loss: 0.3286
Epoch 264/1000

Epoch 00264: val_loss improved from 0.32857 to 0.32845, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3246 - val_loss: 0.3284
Epoch 265/1000

Epoch 00265: val_loss improved from 0.32845 to 0.32833, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3245 - val_loss: 0.3283
Epoch 266/1000

Epoch 00266: val_loss improved from 0.32833 to 0.32820, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3243 - val_loss: 0.3282
Epoch 267/1000

Epoch 00267: val_loss improved from 0.32820 to 0.32808, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3242 - val_loss: 0.3281
Epoch 268/1000

Epoch 00268: val_loss improved from 0.32808 to 0.32796, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 8s - loss: 0.3241 - val_loss: 0.3280
Epoch 269/1000

Epoch 00269: val_loss improved from 0.32796 to 0.32784, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3240 - val_loss: 0.3278
Epoch 270/1000

Epoch 00270: val_loss improved from 0.32784 to 0.32774, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3239 - val_loss: 0.3277
Epoch 271/1000

Epoch 00271: val_loss improved from 0.32774 to 0.32764, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3237 - val_loss: 0.3276
Epoch 272/1000

Epoch 00272: val_loss improved from 0.32764 to 0.32754, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3236 - val_loss: 0.3275
Epoch 273/1000

Epoch 00273: val_loss improved from 0.32754 to 0.32744, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3235 - val_loss: 0.3274
Epoch 274/1000

Epoch 00274: val_loss improved from 0.32744 to 0.32734, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3234 - val_loss: 0.3273
Epoch 275/1000

Epoch 00275: val_loss improved from 0.32734 to 0.32725, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3232 - val_loss: 0.3272
Epoch 276/1000

Epoch 00276: val_loss improved from 0.32725 to 0.32715, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3231 - val_loss: 0.3271
Epoch 277/1000

Epoch 00277: val_loss improved from 0.32715 to 0.32705, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3230 - val_loss: 0.3270
Epoch 278/1000

Epoch 00278: val_loss improved from 0.32705 to 0.32695, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3228 - val_loss: 0.3269
Epoch 279/1000

Epoch 00279: val_loss improved from 0.32695 to 0.32685, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3227 - val_loss: 0.3268
Epoch 280/1000

Epoch 00280: val_loss improved from 0.32685 to 0.32675, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3226 - val_loss: 0.3267
Epoch 281/1000

Epoch 00281: val_loss improved from 0.32675 to 0.32665, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3225 - val_loss: 0.3266
Epoch 282/1000

Epoch 00282: val_loss improved from 0.32665 to 0.32654, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3223 - val_loss: 0.3265
Epoch 283/1000

Epoch 00283: val_loss improved from 0.32654 to 0.32644, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3222 - val_loss: 0.3264
Epoch 284/1000

Epoch 00284: val_loss improved from 0.32644 to 0.32634, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3221 - val_loss: 0.3263
Epoch 285/1000

Epoch 00285: val_loss improved from 0.32634 to 0.32624, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3220 - val_loss: 0.3262
Epoch 286/1000

Epoch 00286: val_loss improved from 0.32624 to 0.32614, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3218 - val_loss: 0.3261
Epoch 287/1000

Epoch 00287: val_loss improved from 0.32614 to 0.32604, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3217 - val_loss: 0.3260
Epoch 288/1000

Epoch 00288: val_loss improved from 0.32604 to 0.32594, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3216 - val_loss: 0.3259
Epoch 289/1000

Epoch 00289: val_loss improved from 0.32594 to 0.32584, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3214 - val_loss: 0.3258
Epoch 290/1000

Epoch 00290: val_loss improved from 0.32584 to 0.32573, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3213 - val_loss: 0.3257
Epoch 291/1000

Epoch 00291: val_loss improved from 0.32573 to 0.32563, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3212 - val_loss: 0.3256
Epoch 292/1000

Epoch 00292: val_loss improved from 0.32563 to 0.32553, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3211 - val_loss: 0.3255
Epoch 293/1000

Epoch 00293: val_loss improved from 0.32553 to 0.32543, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3209 - val_loss: 0.3254
Epoch 294/1000

Epoch 00294: val_loss improved from 0.32543 to 0.32533, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3208 - val_loss: 0.3253
Epoch 295/1000

Epoch 00295: val_loss improved from 0.32533 to 0.32522, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3207 - val_loss: 0.3252
Epoch 296/1000

Epoch 00296: val_loss improved from 0.32522 to 0.32512, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3205 - val_loss: 0.3251
Epoch 297/1000

Epoch 00297: val_loss improved from 0.32512 to 0.32502, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3204 - val_loss: 0.3250
Epoch 298/1000

Epoch 00298: val_loss improved from 0.32502 to 0.32492, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3203 - val_loss: 0.3249
Epoch 299/1000

Epoch 00299: val_loss improved from 0.32492 to 0.32481, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 8s - loss: 0.3201 - val_loss: 0.3248
Epoch 300/1000

Epoch 00300: val_loss improved from 0.32481 to 0.32471, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3200 - val_loss: 0.3247
Epoch 301/1000

Epoch 00301: val_loss improved from 0.32471 to 0.32461, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3199 - val_loss: 0.3246
Epoch 302/1000

Epoch 00302: val_loss improved from 0.32461 to 0.32450, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3198 - val_loss: 0.3245
Epoch 303/1000

Epoch 00303: val_loss improved from 0.32450 to 0.32440, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3196 - val_loss: 0.3244
Epoch 304/1000

Epoch 00304: val_loss improved from 0.32440 to 0.32429, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3195 - val_loss: 0.3243
Epoch 305/1000

Epoch 00305: val_loss improved from 0.32429 to 0.32419, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3194 - val_loss: 0.3242
Epoch 306/1000

Epoch 00306: val_loss improved from 0.32419 to 0.32409, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3192 - val_loss: 0.3241
Epoch 307/1000

Epoch 00307: val_loss improved from 0.32409 to 0.32398, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3191 - val_loss: 0.3240
Epoch 308/1000

Epoch 00308: val_loss improved from 0.32398 to 0.32388, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3190 - val_loss: 0.3239
Epoch 309/1000

Epoch 00309: val_loss improved from 0.32388 to 0.32377, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3188 - val_loss: 0.3238
Epoch 310/1000

Epoch 00310: val_loss improved from 0.32377 to 0.32367, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3187 - val_loss: 0.3237
Epoch 311/1000

Epoch 00311: val_loss improved from 0.32367 to 0.32356, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3186 - val_loss: 0.3236
Epoch 312/1000

Epoch 00312: val_loss improved from 0.32356 to 0.32346, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3184 - val_loss: 0.3235
Epoch 313/1000

Epoch 00313: val_loss improved from 0.32346 to 0.32336, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3183 - val_loss: 0.3234
Epoch 314/1000

Epoch 00314: val_loss improved from 0.32336 to 0.32325, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3182 - val_loss: 0.3233
Epoch 315/1000

Epoch 00315: val_loss improved from 0.32325 to 0.32314, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3180 - val_loss: 0.3231
Epoch 316/1000

Epoch 00316: val_loss improved from 0.32314 to 0.32304, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3179 - val_loss: 0.3230
Epoch 317/1000

Epoch 00317: val_loss improved from 0.32304 to 0.32293, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3178 - val_loss: 0.3229
Epoch 318/1000

Epoch 00318: val_loss improved from 0.32293 to 0.32283, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3176 - val_loss: 0.3228
Epoch 319/1000

Epoch 00319: val_loss improved from 0.32283 to 0.32272, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3175 - val_loss: 0.3227
Epoch 320/1000

Epoch 00320: val_loss improved from 0.32272 to 0.32262, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 8s - loss: 0.3174 - val_loss: 0.3226
Epoch 321/1000

Epoch 00321: val_loss improved from 0.32262 to 0.32251, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3172 - val_loss: 0.3225
Epoch 322/1000

Epoch 00322: val_loss improved from 0.32251 to 0.32240, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 8s - loss: 0.3171 - val_loss: 0.3224
Epoch 323/1000

Epoch 00323: val_loss improved from 0.32240 to 0.32230, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3170 - val_loss: 0.3223
Epoch 324/1000

Epoch 00324: val_loss improved from 0.32230 to 0.32219, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 9s - loss: 0.3168 - val_loss: 0.3222
Epoch 325/1000

Epoch 00325: val_loss improved from 0.32219 to 0.32208, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3167 - val_loss: 0.3221
Epoch 326/1000

Epoch 00326: val_loss improved from 0.32208 to 0.32198, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3166 - val_loss: 0.3220
Epoch 327/1000

Epoch 00327: val_loss improved from 0.32198 to 0.32187, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3164 - val_loss: 0.3219
Epoch 328/1000

Epoch 00328: val_loss improved from 0.32187 to 0.32176, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3163 - val_loss: 0.3218
Epoch 329/1000

Epoch 00329: val_loss improved from 0.32176 to 0.32166, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3161 - val_loss: 0.3217
Epoch 330/1000

Epoch 00330: val_loss improved from 0.32166 to 0.32155, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3160 - val_loss: 0.3215
Epoch 331/1000

Epoch 00331: val_loss improved from 0.32155 to 0.32144, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3159 - val_loss: 0.3214
Epoch 332/1000

Epoch 00332: val_loss improved from 0.32144 to 0.32133, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3157 - val_loss: 0.3213
Epoch 333/1000

Epoch 00333: val_loss improved from 0.32133 to 0.32123, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3156 - val_loss: 0.3212
Epoch 334/1000

Epoch 00334: val_loss improved from 0.32123 to 0.32112, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3155 - val_loss: 0.3211
Epoch 335/1000

Epoch 00335: val_loss improved from 0.32112 to 0.32101, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3153 - val_loss: 0.3210
Epoch 336/1000

Epoch 00336: val_loss improved from 0.32101 to 0.32090, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3152 - val_loss: 0.3209
Epoch 337/1000

Epoch 00337: val_loss improved from 0.32090 to 0.32079, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3151 - val_loss: 0.3208
Epoch 338/1000

Epoch 00338: val_loss improved from 0.32079 to 0.32068, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3149 - val_loss: 0.3207
Epoch 339/1000

Epoch 00339: val_loss improved from 0.32068 to 0.32058, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3148 - val_loss: 0.3206
Epoch 340/1000

Epoch 00340: val_loss improved from 0.32058 to 0.32047, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3146 - val_loss: 0.3205
Epoch 341/1000

Epoch 00341: val_loss improved from 0.32047 to 0.32036, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3145 - val_loss: 0.3204
Epoch 342/1000

Epoch 00342: val_loss improved from 0.32036 to 0.32025, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3144 - val_loss: 0.3202
Epoch 343/1000

Epoch 00343: val_loss improved from 0.32025 to 0.32014, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3142 - val_loss: 0.3201
Epoch 344/1000

Epoch 00344: val_loss improved from 0.32014 to 0.32003, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3141 - val_loss: 0.3200
Epoch 345/1000

Epoch 00345: val_loss improved from 0.32003 to 0.31992, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3139 - val_loss: 0.3199
Epoch 346/1000

Epoch 00346: val_loss improved from 0.31992 to 0.31981, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3138 - val_loss: 0.3198
Epoch 347/1000

Epoch 00347: val_loss improved from 0.31981 to 0.31970, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3137 - val_loss: 0.3197
Epoch 348/1000

Epoch 00348: val_loss improved from 0.31970 to 0.31959, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3135 - val_loss: 0.3196
Epoch 349/1000

Epoch 00349: val_loss improved from 0.31959 to 0.31948, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3134 - val_loss: 0.3195
Epoch 350/1000

Epoch 00350: val_loss improved from 0.31948 to 0.31937, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3132 - val_loss: 0.3194
Epoch 351/1000

Epoch 00351: val_loss improved from 0.31937 to 0.31926, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3131 - val_loss: 0.3193
Epoch 352/1000

Epoch 00352: val_loss improved from 0.31926 to 0.31915, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3130 - val_loss: 0.3192
Epoch 353/1000

Epoch 00353: val_loss improved from 0.31915 to 0.31904, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3128 - val_loss: 0.3190
Epoch 354/1000

Epoch 00354: val_loss improved from 0.31904 to 0.31893, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3127 - val_loss: 0.3189
Epoch 355/1000

Epoch 00355: val_loss improved from 0.31893 to 0.31882, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3125 - val_loss: 0.3188
Epoch 356/1000

Epoch 00356: val_loss improved from 0.31882 to 0.31871, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 8s - loss: 0.3124 - val_loss: 0.3187
Epoch 357/1000

Epoch 00357: val_loss improved from 0.31871 to 0.31860, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3123 - val_loss: 0.3186
Epoch 358/1000

Epoch 00358: val_loss improved from 0.31860 to 0.31849, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3121 - val_loss: 0.3185
Epoch 359/1000

Epoch 00359: val_loss improved from 0.31849 to 0.31838, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3120 - val_loss: 0.3184
Epoch 360/1000

Epoch 00360: val_loss improved from 0.31838 to 0.31827, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3118 - val_loss: 0.3183
Epoch 361/1000

Epoch 00361: val_loss improved from 0.31827 to 0.31816, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3117 - val_loss: 0.3182
Epoch 362/1000

Epoch 00362: val_loss improved from 0.31816 to 0.31805, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3116 - val_loss: 0.3180
Epoch 363/1000

Epoch 00363: val_loss improved from 0.31805 to 0.31794, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3114 - val_loss: 0.3179
Epoch 364/1000

Epoch 00364: val_loss improved from 0.31794 to 0.31783, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3113 - val_loss: 0.3178
Epoch 365/1000

Epoch 00365: val_loss improved from 0.31783 to 0.31771, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3111 - val_loss: 0.3177
Epoch 366/1000

Epoch 00366: val_loss improved from 0.31771 to 0.31760, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3110 - val_loss: 0.3176
Epoch 367/1000

Epoch 00367: val_loss improved from 0.31760 to 0.31749, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 8s - loss: 0.3109 - val_loss: 0.3175
Epoch 368/1000

Epoch 00368: val_loss improved from 0.31749 to 0.31738, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3107 - val_loss: 0.3174
Epoch 369/1000

Epoch 00369: val_loss improved from 0.31738 to 0.31727, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3106 - val_loss: 0.3173
Epoch 370/1000

Epoch 00370: val_loss improved from 0.31727 to 0.31715, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3104 - val_loss: 0.3172
Epoch 371/1000

Epoch 00371: val_loss improved from 0.31715 to 0.31704, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.3103 - val_loss: 0.3170
Epoch 372/1000

Epoch 00372: val_loss improved from 0.31704 to 0.31693, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3101 - val_loss: 0.3169
Epoch 373/1000

Epoch 00373: val_loss improved from 0.31693 to 0.31682, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3100 - val_loss: 0.3168
Epoch 374/1000

Epoch 00374: val_loss improved from 0.31682 to 0.31671, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3099 - val_loss: 0.3167
Epoch 375/1000

Epoch 00375: val_loss improved from 0.31671 to 0.31659, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3097 - val_loss: 0.3166
Epoch 376/1000

Epoch 00376: val_loss improved from 0.31659 to 0.31648, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3096 - val_loss: 0.3165
Epoch 377/1000

Epoch 00377: val_loss improved from 0.31648 to 0.31637, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3094 - val_loss: 0.3164
Epoch 378/1000

Epoch 00378: val_loss improved from 0.31637 to 0.31625, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3093 - val_loss: 0.3163
Epoch 379/1000

Epoch 00379: val_loss improved from 0.31625 to 0.31614, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3091 - val_loss: 0.3161
Epoch 380/1000

Epoch 00380: val_loss improved from 0.31614 to 0.31603, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3090 - val_loss: 0.3160
Epoch 381/1000

Epoch 00381: val_loss improved from 0.31603 to 0.31591, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3088 - val_loss: 0.3159
Epoch 382/1000

Epoch 00382: val_loss improved from 0.31591 to 0.31580, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3087 - val_loss: 0.3158
Epoch 383/1000

Epoch 00383: val_loss improved from 0.31580 to 0.31569, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3086 - val_loss: 0.3157
Epoch 384/1000

Epoch 00384: val_loss improved from 0.31569 to 0.31557, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3084 - val_loss: 0.3156
Epoch 385/1000

Epoch 00385: val_loss improved from 0.31557 to 0.31546, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3083 - val_loss: 0.3155
Epoch 386/1000

Epoch 00386: val_loss improved from 0.31546 to 0.31535, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3081 - val_loss: 0.3153
Epoch 387/1000

Epoch 00387: val_loss improved from 0.31535 to 0.31523, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3080 - val_loss: 0.3152
Epoch 388/1000

Epoch 00388: val_loss improved from 0.31523 to 0.31512, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3078 - val_loss: 0.3151
Epoch 389/1000

Epoch 00389: val_loss improved from 0.31512 to 0.31500, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3077 - val_loss: 0.3150
Epoch 390/1000

Epoch 00390: val_loss improved from 0.31500 to 0.31489, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3075 - val_loss: 0.3149
Epoch 391/1000

Epoch 00391: val_loss improved from 0.31489 to 0.31478, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3074 - val_loss: 0.3148
Epoch 392/1000

Epoch 00392: val_loss improved from 0.31478 to 0.31466, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3072 - val_loss: 0.3147
Epoch 393/1000

Epoch 00393: val_loss improved from 0.31466 to 0.31455, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3071 - val_loss: 0.3145
Epoch 394/1000

Epoch 00394: val_loss improved from 0.31455 to 0.31443, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3070 - val_loss: 0.3144
Epoch 395/1000

Epoch 00395: val_loss improved from 0.31443 to 0.31432, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3068 - val_loss: 0.3143
Epoch 396/1000

Epoch 00396: val_loss improved from 0.31432 to 0.31420, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3067 - val_loss: 0.3142
Epoch 397/1000

Epoch 00397: val_loss improved from 0.31420 to 0.31409, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3065 - val_loss: 0.3141
Epoch 398/1000

Epoch 00398: val_loss improved from 0.31409 to 0.31397, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3064 - val_loss: 0.3140
Epoch 399/1000

Epoch 00399: val_loss improved from 0.31397 to 0.31386, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3062 - val_loss: 0.3139
Epoch 400/1000

Epoch 00400: val_loss improved from 0.31386 to 0.31374, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3061 - val_loss: 0.3137
Epoch 401/1000

Epoch 00401: val_loss improved from 0.31374 to 0.31363, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3059 - val_loss: 0.3136
Epoch 402/1000

Epoch 00402: val_loss improved from 0.31363 to 0.31351, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3058 - val_loss: 0.3135
Epoch 403/1000

Epoch 00403: val_loss improved from 0.31351 to 0.31340, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3056 - val_loss: 0.3134
Epoch 404/1000

Epoch 00404: val_loss improved from 0.31340 to 0.31328, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3055 - val_loss: 0.3133
Epoch 405/1000

Epoch 00405: val_loss improved from 0.31328 to 0.31317, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3053 - val_loss: 0.3132
Epoch 406/1000

Epoch 00406: val_loss improved from 0.31317 to 0.31305, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3052 - val_loss: 0.3130
Epoch 407/1000

Epoch 00407: val_loss improved from 0.31305 to 0.31293, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3050 - val_loss: 0.3129
Epoch 408/1000

Epoch 00408: val_loss improved from 0.31293 to 0.31282, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3049 - val_loss: 0.3128
Epoch 409/1000

Epoch 00409: val_loss improved from 0.31282 to 0.31270, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3047 - val_loss: 0.3127
Epoch 410/1000

Epoch 00410: val_loss improved from 0.31270 to 0.31259, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3046 - val_loss: 0.3126
Epoch 411/1000

Epoch 00411: val_loss improved from 0.31259 to 0.31247, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3045 - val_loss: 0.3125
Epoch 412/1000

Epoch 00412: val_loss improved from 0.31247 to 0.31235, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3043 - val_loss: 0.3124
Epoch 413/1000

Epoch 00413: val_loss improved from 0.31235 to 0.31224, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3042 - val_loss: 0.3122
Epoch 414/1000

Epoch 00414: val_loss improved from 0.31224 to 0.31212, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3040 - val_loss: 0.3121
Epoch 415/1000

Epoch 00415: val_loss improved from 0.31212 to 0.31200, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3039 - val_loss: 0.3120
Epoch 416/1000

Epoch 00416: val_loss improved from 0.31200 to 0.31189, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3037 - val_loss: 0.3119
Epoch 417/1000

Epoch 00417: val_loss improved from 0.31189 to 0.31177, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3036 - val_loss: 0.3118
Epoch 418/1000

Epoch 00418: val_loss improved from 0.31177 to 0.31165, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3034 - val_loss: 0.3117
Epoch 419/1000

Epoch 00419: val_loss improved from 0.31165 to 0.31154, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3033 - val_loss: 0.3115
Epoch 420/1000

Epoch 00420: val_loss improved from 0.31154 to 0.31142, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3031 - val_loss: 0.3114
Epoch 421/1000

Epoch 00421: val_loss improved from 0.31142 to 0.31130, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3030 - val_loss: 0.3113
Epoch 422/1000

Epoch 00422: val_loss improved from 0.31130 to 0.31118, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3028 - val_loss: 0.3112
Epoch 423/1000

Epoch 00423: val_loss improved from 0.31118 to 0.31107, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3027 - val_loss: 0.3111
Epoch 424/1000

Epoch 00424: val_loss improved from 0.31107 to 0.31095, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3025 - val_loss: 0.3110
Epoch 425/1000

Epoch 00425: val_loss improved from 0.31095 to 0.31083, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3024 - val_loss: 0.3108
Epoch 426/1000

Epoch 00426: val_loss improved from 0.31083 to 0.31072, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3022 - val_loss: 0.3107
Epoch 427/1000

Epoch 00427: val_loss improved from 0.31072 to 0.31060, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3021 - val_loss: 0.3106
Epoch 428/1000

Epoch 00428: val_loss improved from 0.31060 to 0.31048, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3019 - val_loss: 0.3105
Epoch 429/1000

Epoch 00429: val_loss improved from 0.31048 to 0.31036, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3018 - val_loss: 0.3104
Epoch 430/1000

Epoch 00430: val_loss improved from 0.31036 to 0.31024, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3016 - val_loss: 0.3102
Epoch 431/1000

Epoch 00431: val_loss improved from 0.31024 to 0.31013, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3015 - val_loss: 0.3101
Epoch 432/1000

Epoch 00432: val_loss improved from 0.31013 to 0.31001, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3013 - val_loss: 0.3100
Epoch 433/1000

Epoch 00433: val_loss improved from 0.31001 to 0.30989, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.3012 - val_loss: 0.3099
Epoch 434/1000

Epoch 00434: val_loss improved from 0.30989 to 0.30977, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3010 - val_loss: 0.3098
Epoch 435/1000

Epoch 00435: val_loss improved from 0.30977 to 0.30965, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3009 - val_loss: 0.3097
Epoch 436/1000

Epoch 00436: val_loss improved from 0.30965 to 0.30953, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3007 - val_loss: 0.3095
Epoch 437/1000

Epoch 00437: val_loss improved from 0.30953 to 0.30942, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.3006 - val_loss: 0.3094
Epoch 438/1000

Epoch 00438: val_loss improved from 0.30942 to 0.30930, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3004 - val_loss: 0.3093
Epoch 439/1000

Epoch 00439: val_loss improved from 0.30930 to 0.30918, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.3002 - val_loss: 0.3092
Epoch 440/1000

Epoch 00440: val_loss improved from 0.30918 to 0.30906, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.3001 - val_loss: 0.3091
Epoch 441/1000

Epoch 00441: val_loss improved from 0.30906 to 0.30894, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2999 - val_loss: 0.3089
Epoch 442/1000

Epoch 00442: val_loss improved from 0.30894 to 0.30882, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.2998 - val_loss: 0.3088
Epoch 443/1000

Epoch 00443: val_loss improved from 0.30882 to 0.30870, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2996 - val_loss: 0.3087
Epoch 444/1000

Epoch 00444: val_loss improved from 0.30870 to 0.30859, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2995 - val_loss: 0.3086
Epoch 445/1000

Epoch 00445: val_loss improved from 0.30859 to 0.30847, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2993 - val_loss: 0.3085
Epoch 446/1000

Epoch 00446: val_loss improved from 0.30847 to 0.30835, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2992 - val_loss: 0.3083
Epoch 447/1000

Epoch 00447: val_loss improved from 0.30835 to 0.30823, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2990 - val_loss: 0.3082
Epoch 448/1000

Epoch 00448: val_loss improved from 0.30823 to 0.30811, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2989 - val_loss: 0.3081
Epoch 449/1000

Epoch 00449: val_loss improved from 0.30811 to 0.30799, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2987 - val_loss: 0.3080
Epoch 450/1000

Epoch 00450: val_loss improved from 0.30799 to 0.30787, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2986 - val_loss: 0.3079
Epoch 451/1000

Epoch 00451: val_loss improved from 0.30787 to 0.30775, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2984 - val_loss: 0.3077
Epoch 452/1000

Epoch 00452: val_loss improved from 0.30775 to 0.30763, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2983 - val_loss: 0.3076
Epoch 453/1000

Epoch 00453: val_loss improved from 0.30763 to 0.30751, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2981 - val_loss: 0.3075
Epoch 454/1000

Epoch 00454: val_loss improved from 0.30751 to 0.30739, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2980 - val_loss: 0.3074
Epoch 455/1000

Epoch 00455: val_loss improved from 0.30739 to 0.30727, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2978 - val_loss: 0.3073
Epoch 456/1000

Epoch 00456: val_loss improved from 0.30727 to 0.30715, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2976 - val_loss: 0.3072
Epoch 457/1000

Epoch 00457: val_loss improved from 0.30715 to 0.30703, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2975 - val_loss: 0.3070
Epoch 458/1000

Epoch 00458: val_loss improved from 0.30703 to 0.30691, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2973 - val_loss: 0.3069
Epoch 459/1000

Epoch 00459: val_loss improved from 0.30691 to 0.30679, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2972 - val_loss: 0.3068
Epoch 460/1000

Epoch 00460: val_loss improved from 0.30679 to 0.30667, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2970 - val_loss: 0.3067
Epoch 461/1000

Epoch 00461: val_loss improved from 0.30667 to 0.30655, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2969 - val_loss: 0.3065
Epoch 462/1000

Epoch 00462: val_loss improved from 0.30655 to 0.30643, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2967 - val_loss: 0.3064
Epoch 463/1000

Epoch 00463: val_loss improved from 0.30643 to 0.30631, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2966 - val_loss: 0.3063
Epoch 464/1000

Epoch 00464: val_loss improved from 0.30631 to 0.30619, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2964 - val_loss: 0.3062
Epoch 465/1000

Epoch 00465: val_loss improved from 0.30619 to 0.30607, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2963 - val_loss: 0.3061
Epoch 466/1000

Epoch 00466: val_loss improved from 0.30607 to 0.30595, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2961 - val_loss: 0.3059
Epoch 467/1000

Epoch 00467: val_loss improved from 0.30595 to 0.30583, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2960 - val_loss: 0.3058
Epoch 468/1000

Epoch 00468: val_loss improved from 0.30583 to 0.30570, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2958 - val_loss: 0.3057
Epoch 469/1000

Epoch 00469: val_loss improved from 0.30570 to 0.30558, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2956 - val_loss: 0.3056
Epoch 470/1000

Epoch 00470: val_loss improved from 0.30558 to 0.30546, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2955 - val_loss: 0.3055
Epoch 471/1000

Epoch 00471: val_loss improved from 0.30546 to 0.30534, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2953 - val_loss: 0.3053
Epoch 472/1000

Epoch 00472: val_loss improved from 0.30534 to 0.30522, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2952 - val_loss: 0.3052
Epoch 473/1000

Epoch 00473: val_loss improved from 0.30522 to 0.30510, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2950 - val_loss: 0.3051
Epoch 474/1000

Epoch 00474: val_loss improved from 0.30510 to 0.30498, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2949 - val_loss: 0.3050
Epoch 475/1000

Epoch 00475: val_loss improved from 0.30498 to 0.30486, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2947 - val_loss: 0.3049
Epoch 476/1000

Epoch 00476: val_loss improved from 0.30486 to 0.30474, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2945 - val_loss: 0.3047
Epoch 477/1000

Epoch 00477: val_loss improved from 0.30474 to 0.30461, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2944 - val_loss: 0.3046
Epoch 478/1000

Epoch 00478: val_loss improved from 0.30461 to 0.30449, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2942 - val_loss: 0.3045
Epoch 479/1000

Epoch 00479: val_loss improved from 0.30449 to 0.30437, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2941 - val_loss: 0.3044
Epoch 480/1000

Epoch 00480: val_loss improved from 0.30437 to 0.30425, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2939 - val_loss: 0.3042
Epoch 481/1000

Epoch 00481: val_loss improved from 0.30425 to 0.30413, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2938 - val_loss: 0.3041
Epoch 482/1000

Epoch 00482: val_loss improved from 0.30413 to 0.30401, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2936 - val_loss: 0.3040
Epoch 483/1000

Epoch 00483: val_loss improved from 0.30401 to 0.30388, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2935 - val_loss: 0.3039
Epoch 484/1000

Epoch 00484: val_loss improved from 0.30388 to 0.30376, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2933 - val_loss: 0.3038
Epoch 485/1000

Epoch 00485: val_loss improved from 0.30376 to 0.30364, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2931 - val_loss: 0.3036
Epoch 486/1000

Epoch 00486: val_loss improved from 0.30364 to 0.30352, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.2930 - val_loss: 0.3035
Epoch 487/1000

Epoch 00487: val_loss improved from 0.30352 to 0.30339, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2928 - val_loss: 0.3034
Epoch 488/1000

Epoch 00488: val_loss improved from 0.30339 to 0.30327, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2927 - val_loss: 0.3033
Epoch 489/1000

Epoch 00489: val_loss improved from 0.30327 to 0.30315, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2925 - val_loss: 0.3032
Epoch 490/1000

Epoch 00490: val_loss improved from 0.30315 to 0.30303, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2924 - val_loss: 0.3030
Epoch 491/1000

Epoch 00491: val_loss improved from 0.30303 to 0.30291, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2922 - val_loss: 0.3029
Epoch 492/1000

Epoch 00492: val_loss improved from 0.30291 to 0.30278, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.2920 - val_loss: 0.3028
Epoch 493/1000

Epoch 00493: val_loss improved from 0.30278 to 0.30266, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2919 - val_loss: 0.3027
Epoch 494/1000

Epoch 00494: val_loss improved from 0.30266 to 0.30254, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2917 - val_loss: 0.3025
Epoch 495/1000

Epoch 00495: val_loss improved from 0.30254 to 0.30242, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2916 - val_loss: 0.3024
Epoch 496/1000

Epoch 00496: val_loss improved from 0.30242 to 0.30229, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2914 - val_loss: 0.3023
Epoch 497/1000

Epoch 00497: val_loss improved from 0.30229 to 0.30217, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2913 - val_loss: 0.3022
Epoch 498/1000

Epoch 00498: val_loss improved from 0.30217 to 0.30205, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2911 - val_loss: 0.3020
Epoch 499/1000

Epoch 00499: val_loss improved from 0.30205 to 0.30193, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2909 - val_loss: 0.3019
Epoch 500/1000

Epoch 00500: val_loss improved from 0.30193 to 0.30180, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2908 - val_loss: 0.3018
Epoch 501/1000

Epoch 00501: val_loss improved from 0.30180 to 0.30168, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2906 - val_loss: 0.3017
Epoch 502/1000

Epoch 00502: val_loss improved from 0.30168 to 0.30156, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2905 - val_loss: 0.3016
Epoch 503/1000

Epoch 00503: val_loss improved from 0.30156 to 0.30143, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2903 - val_loss: 0.3014
Epoch 504/1000

Epoch 00504: val_loss improved from 0.30143 to 0.30131, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2901 - val_loss: 0.3013
Epoch 505/1000

Epoch 00505: val_loss improved from 0.30131 to 0.30119, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2900 - val_loss: 0.3012
Epoch 506/1000

Epoch 00506: val_loss improved from 0.30119 to 0.30107, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2898 - val_loss: 0.3011
Epoch 507/1000

Epoch 00507: val_loss improved from 0.30107 to 0.30094, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2897 - val_loss: 0.3009
Epoch 508/1000

Epoch 00508: val_loss improved from 0.30094 to 0.30082, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2895 - val_loss: 0.3008
Epoch 509/1000

Epoch 00509: val_loss improved from 0.30082 to 0.30070, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2894 - val_loss: 0.3007
Epoch 510/1000

Epoch 00510: val_loss improved from 0.30070 to 0.30057, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2892 - val_loss: 0.3006
Epoch 511/1000

Epoch 00511: val_loss improved from 0.30057 to 0.30045, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2890 - val_loss: 0.3004
Epoch 512/1000

Epoch 00512: val_loss improved from 0.30045 to 0.30033, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2889 - val_loss: 0.3003
Epoch 513/1000

Epoch 00513: val_loss improved from 0.30033 to 0.30020, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2887 - val_loss: 0.3002
Epoch 514/1000

Epoch 00514: val_loss improved from 0.30020 to 0.30008, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2886 - val_loss: 0.3001
Epoch 515/1000

Epoch 00515: val_loss improved from 0.30008 to 0.29995, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2884 - val_loss: 0.3000
Epoch 516/1000

Epoch 00516: val_loss improved from 0.29995 to 0.29983, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2882 - val_loss: 0.2998
Epoch 517/1000

Epoch 00517: val_loss improved from 0.29983 to 0.29971, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2881 - val_loss: 0.2997
Epoch 518/1000

Epoch 00518: val_loss improved from 0.29971 to 0.29958, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2879 - val_loss: 0.2996
Epoch 519/1000

Epoch 00519: val_loss improved from 0.29958 to 0.29946, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2878 - val_loss: 0.2995
Epoch 520/1000

Epoch 00520: val_loss improved from 0.29946 to 0.29934, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2876 - val_loss: 0.2993
Epoch 521/1000

Epoch 00521: val_loss improved from 0.29934 to 0.29921, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2874 - val_loss: 0.2992
Epoch 522/1000

Epoch 00522: val_loss improved from 0.29921 to 0.29909, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2873 - val_loss: 0.2991
Epoch 523/1000

Epoch 00523: val_loss improved from 0.29909 to 0.29896, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2871 - val_loss: 0.2990
Epoch 524/1000

Epoch 00524: val_loss improved from 0.29896 to 0.29884, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2870 - val_loss: 0.2988
Epoch 525/1000

Epoch 00525: val_loss improved from 0.29884 to 0.29871, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.2868 - val_loss: 0.2987
Epoch 526/1000

Epoch 00526: val_loss improved from 0.29871 to 0.29859, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2866 - val_loss: 0.2986
Epoch 527/1000

Epoch 00527: val_loss improved from 0.29859 to 0.29847, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2865 - val_loss: 0.2985
Epoch 528/1000

Epoch 00528: val_loss improved from 0.29847 to 0.29834, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2863 - val_loss: 0.2983
Epoch 529/1000

Epoch 00529: val_loss improved from 0.29834 to 0.29822, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2862 - val_loss: 0.2982
Epoch 530/1000

Epoch 00530: val_loss improved from 0.29822 to 0.29809, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2860 - val_loss: 0.2981
Epoch 531/1000

Epoch 00531: val_loss improved from 0.29809 to 0.29797, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2858 - val_loss: 0.2980
Epoch 532/1000

Epoch 00532: val_loss improved from 0.29797 to 0.29784, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2857 - val_loss: 0.2978
Epoch 533/1000

Epoch 00533: val_loss improved from 0.29784 to 0.29772, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2855 - val_loss: 0.2977
Epoch 534/1000

Epoch 00534: val_loss improved from 0.29772 to 0.29759, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2854 - val_loss: 0.2976
Epoch 535/1000

Epoch 00535: val_loss improved from 0.29759 to 0.29747, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2852 - val_loss: 0.2975
Epoch 536/1000

Epoch 00536: val_loss improved from 0.29747 to 0.29735, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2850 - val_loss: 0.2973
Epoch 537/1000

Epoch 00537: val_loss improved from 0.29735 to 0.29722, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2849 - val_loss: 0.2972
Epoch 538/1000

Epoch 00538: val_loss improved from 0.29722 to 0.29710, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2847 - val_loss: 0.2971
Epoch 539/1000

Epoch 00539: val_loss improved from 0.29710 to 0.29697, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2846 - val_loss: 0.2970
Epoch 540/1000

Epoch 00540: val_loss improved from 0.29697 to 0.29685, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2844 - val_loss: 0.2968
Epoch 541/1000

Epoch 00541: val_loss improved from 0.29685 to 0.29672, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2842 - val_loss: 0.2967
Epoch 542/1000

Epoch 00542: val_loss improved from 0.29672 to 0.29660, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2841 - val_loss: 0.2966
Epoch 543/1000

Epoch 00543: val_loss improved from 0.29660 to 0.29647, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2839 - val_loss: 0.2965
Epoch 544/1000

Epoch 00544: val_loss improved from 0.29647 to 0.29635, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2837 - val_loss: 0.2963
Epoch 545/1000

Epoch 00545: val_loss improved from 0.29635 to 0.29622, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2836 - val_loss: 0.2962
Epoch 546/1000

Epoch 00546: val_loss improved from 0.29622 to 0.29610, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2834 - val_loss: 0.2961
Epoch 547/1000

Epoch 00547: val_loss improved from 0.29610 to 0.29597, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2833 - val_loss: 0.2960
Epoch 548/1000

Epoch 00548: val_loss improved from 0.29597 to 0.29585, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2831 - val_loss: 0.2958
Epoch 549/1000

Epoch 00549: val_loss improved from 0.29585 to 0.29572, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2829 - val_loss: 0.2957
Epoch 550/1000

Epoch 00550: val_loss improved from 0.29572 to 0.29560, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2828 - val_loss: 0.2956
Epoch 551/1000

Epoch 00551: val_loss improved from 0.29560 to 0.29547, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2826 - val_loss: 0.2955
Epoch 552/1000

Epoch 00552: val_loss improved from 0.29547 to 0.29535, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2825 - val_loss: 0.2953
Epoch 553/1000

Epoch 00553: val_loss improved from 0.29535 to 0.29522, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2823 - val_loss: 0.2952
Epoch 554/1000

Epoch 00554: val_loss improved from 0.29522 to 0.29510, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2821 - val_loss: 0.2951
Epoch 555/1000

Epoch 00555: val_loss improved from 0.29510 to 0.29497, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2820 - val_loss: 0.2950
Epoch 556/1000

Epoch 00556: val_loss improved from 0.29497 to 0.29484, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2818 - val_loss: 0.2948
Epoch 557/1000

Epoch 00557: val_loss improved from 0.29484 to 0.29472, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2816 - val_loss: 0.2947
Epoch 558/1000

Epoch 00558: val_loss improved from 0.29472 to 0.29459, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2815 - val_loss: 0.2946
Epoch 559/1000

Epoch 00559: val_loss improved from 0.29459 to 0.29447, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2813 - val_loss: 0.2945
Epoch 560/1000

Epoch 00560: val_loss improved from 0.29447 to 0.29434, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2812 - val_loss: 0.2943
Epoch 561/1000

Epoch 00561: val_loss improved from 0.29434 to 0.29422, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2810 - val_loss: 0.2942
Epoch 562/1000

Epoch 00562: val_loss improved from 0.29422 to 0.29409, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2808 - val_loss: 0.2941
Epoch 563/1000

Epoch 00563: val_loss improved from 0.29409 to 0.29396, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2807 - val_loss: 0.2940
Epoch 564/1000

Epoch 00564: val_loss improved from 0.29396 to 0.29384, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2805 - val_loss: 0.2938
Epoch 565/1000

Epoch 00565: val_loss improved from 0.29384 to 0.29371, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2803 - val_loss: 0.2937
Epoch 566/1000

Epoch 00566: val_loss improved from 0.29371 to 0.29359, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.2802 - val_loss: 0.2936
Epoch 567/1000

Epoch 00567: val_loss improved from 0.29359 to 0.29346, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2800 - val_loss: 0.2935
Epoch 568/1000

Epoch 00568: val_loss improved from 0.29346 to 0.29334, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2798 - val_loss: 0.2933
Epoch 569/1000

Epoch 00569: val_loss improved from 0.29334 to 0.29321, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2797 - val_loss: 0.2932
Epoch 570/1000

Epoch 00570: val_loss improved from 0.29321 to 0.29308, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2795 - val_loss: 0.2931
Epoch 571/1000

Epoch 00571: val_loss improved from 0.29308 to 0.29296, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2794 - val_loss: 0.2930
Epoch 572/1000

Epoch 00572: val_loss improved from 0.29296 to 0.29283, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2792 - val_loss: 0.2928
Epoch 573/1000

Epoch 00573: val_loss improved from 0.29283 to 0.29271, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2790 - val_loss: 0.2927
Epoch 574/1000

Epoch 00574: val_loss improved from 0.29271 to 0.29258, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2789 - val_loss: 0.2926
Epoch 575/1000

Epoch 00575: val_loss improved from 0.29258 to 0.29246, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2787 - val_loss: 0.2925
Epoch 576/1000

Epoch 00576: val_loss improved from 0.29246 to 0.29233, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2785 - val_loss: 0.2923
Epoch 577/1000

Epoch 00577: val_loss improved from 0.29233 to 0.29220, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2784 - val_loss: 0.2922
Epoch 578/1000

Epoch 00578: val_loss improved from 0.29220 to 0.29208, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2782 - val_loss: 0.2921
Epoch 579/1000

Epoch 00579: val_loss improved from 0.29208 to 0.29195, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2781 - val_loss: 0.2920
Epoch 580/1000

Epoch 00580: val_loss improved from 0.29195 to 0.29182, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2779 - val_loss: 0.2918
Epoch 581/1000

Epoch 00581: val_loss improved from 0.29182 to 0.29170, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2777 - val_loss: 0.2917
Epoch 582/1000

Epoch 00582: val_loss improved from 0.29170 to 0.29157, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2776 - val_loss: 0.2916
Epoch 583/1000

Epoch 00583: val_loss improved from 0.29157 to 0.29145, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2774 - val_loss: 0.2914
Epoch 584/1000

Epoch 00584: val_loss improved from 0.29145 to 0.29132, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2772 - val_loss: 0.2913
Epoch 585/1000

Epoch 00585: val_loss improved from 0.29132 to 0.29119, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2771 - val_loss: 0.2912
Epoch 586/1000

Epoch 00586: val_loss improved from 0.29119 to 0.29107, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2769 - val_loss: 0.2911
Epoch 587/1000

Epoch 00587: val_loss improved from 0.29107 to 0.29094, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2767 - val_loss: 0.2909
Epoch 588/1000

Epoch 00588: val_loss improved from 0.29094 to 0.29081, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2766 - val_loss: 0.2908
Epoch 589/1000

Epoch 00589: val_loss improved from 0.29081 to 0.29069, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2764 - val_loss: 0.2907
Epoch 590/1000

Epoch 00590: val_loss improved from 0.29069 to 0.29056, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2763 - val_loss: 0.2906
Epoch 591/1000

Epoch 00591: val_loss improved from 0.29056 to 0.29043, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2761 - val_loss: 0.2904
Epoch 592/1000

Epoch 00592: val_loss improved from 0.29043 to 0.29031, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2759 - val_loss: 0.2903
Epoch 593/1000

Epoch 00593: val_loss improved from 0.29031 to 0.29018, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2758 - val_loss: 0.2902
Epoch 594/1000

Epoch 00594: val_loss improved from 0.29018 to 0.29005, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2756 - val_loss: 0.2901
Epoch 595/1000

Epoch 00595: val_loss improved from 0.29005 to 0.28993, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2754 - val_loss: 0.2899
Epoch 596/1000

Epoch 00596: val_loss improved from 0.28993 to 0.28980, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2753 - val_loss: 0.2898
Epoch 597/1000

Epoch 00597: val_loss improved from 0.28980 to 0.28967, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2751 - val_loss: 0.2897
Epoch 598/1000

Epoch 00598: val_loss improved from 0.28967 to 0.28955, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2749 - val_loss: 0.2895
Epoch 599/1000

Epoch 00599: val_loss improved from 0.28955 to 0.28942, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2748 - val_loss: 0.2894
Epoch 600/1000

Epoch 00600: val_loss improved from 0.28942 to 0.28929, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2746 - val_loss: 0.2893
Epoch 601/1000

Epoch 00601: val_loss improved from 0.28929 to 0.28917, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2744 - val_loss: 0.2892
Epoch 602/1000

Epoch 00602: val_loss improved from 0.28917 to 0.28904, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2743 - val_loss: 0.2890
Epoch 603/1000

Epoch 00603: val_loss improved from 0.28904 to 0.28891, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2741 - val_loss: 0.2889
Epoch 604/1000

Epoch 00604: val_loss improved from 0.28891 to 0.28879, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2740 - val_loss: 0.2888
Epoch 605/1000

Epoch 00605: val_loss improved from 0.28879 to 0.28866, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2738 - val_loss: 0.2887
Epoch 606/1000

Epoch 00606: val_loss improved from 0.28866 to 0.28853, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2736 - val_loss: 0.2885
Epoch 607/1000

Epoch 00607: val_loss improved from 0.28853 to 0.28841, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2735 - val_loss: 0.2884
Epoch 608/1000

Epoch 00608: val_loss improved from 0.28841 to 0.28828, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2733 - val_loss: 0.2883
Epoch 609/1000

Epoch 00609: val_loss improved from 0.28828 to 0.28815, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2731 - val_loss: 0.2882
Epoch 610/1000

Epoch 00610: val_loss improved from 0.28815 to 0.28803, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2730 - val_loss: 0.2880
Epoch 611/1000

Epoch 00611: val_loss improved from 0.28803 to 0.28790, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2728 - val_loss: 0.2879
Epoch 612/1000

Epoch 00612: val_loss improved from 0.28790 to 0.28777, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2726 - val_loss: 0.2878
Epoch 613/1000

Epoch 00613: val_loss improved from 0.28777 to 0.28765, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2725 - val_loss: 0.2876
Epoch 614/1000

Epoch 00614: val_loss improved from 0.28765 to 0.28752, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2723 - val_loss: 0.2875
Epoch 615/1000

Epoch 00615: val_loss improved from 0.28752 to 0.28739, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2721 - val_loss: 0.2874
Epoch 616/1000

Epoch 00616: val_loss improved from 0.28739 to 0.28726, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2720 - val_loss: 0.2873
Epoch 617/1000

Epoch 00617: val_loss improved from 0.28726 to 0.28714, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2718 - val_loss: 0.2871
Epoch 618/1000

Epoch 00618: val_loss improved from 0.28714 to 0.28701, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2716 - val_loss: 0.2870
Epoch 619/1000

Epoch 00619: val_loss improved from 0.28701 to 0.28688, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2715 - val_loss: 0.2869
Epoch 620/1000

Epoch 00620: val_loss improved from 0.28688 to 0.28676, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2713 - val_loss: 0.2868
Epoch 621/1000

Epoch 00621: val_loss improved from 0.28676 to 0.28663, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2711 - val_loss: 0.2866
Epoch 622/1000

Epoch 00622: val_loss improved from 0.28663 to 0.28650, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2710 - val_loss: 0.2865
Epoch 623/1000

Epoch 00623: val_loss improved from 0.28650 to 0.28637, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2708 - val_loss: 0.2864
Epoch 624/1000

Epoch 00624: val_loss improved from 0.28637 to 0.28625, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2706 - val_loss: 0.2862
Epoch 625/1000

Epoch 00625: val_loss improved from 0.28625 to 0.28612, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2705 - val_loss: 0.2861
Epoch 626/1000

Epoch 00626: val_loss improved from 0.28612 to 0.28599, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2703 - val_loss: 0.2860
Epoch 627/1000

Epoch 00627: val_loss improved from 0.28599 to 0.28587, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2702 - val_loss: 0.2859
Epoch 628/1000

Epoch 00628: val_loss improved from 0.28587 to 0.28574, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2700 - val_loss: 0.2857
Epoch 629/1000

Epoch 00629: val_loss improved from 0.28574 to 0.28561, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2698 - val_loss: 0.2856
Epoch 630/1000

Epoch 00630: val_loss improved from 0.28561 to 0.28548, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 11s - loss: 0.2697 - val_loss: 0.2855
Epoch 631/1000

Epoch 00631: val_loss improved from 0.28548 to 0.28536, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2695 - val_loss: 0.2854
Epoch 632/1000

Epoch 00632: val_loss improved from 0.28536 to 0.28523, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2693 - val_loss: 0.2852
Epoch 633/1000

Epoch 00633: val_loss improved from 0.28523 to 0.28510, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2692 - val_loss: 0.2851
Epoch 634/1000

Epoch 00634: val_loss improved from 0.28510 to 0.28498, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2690 - val_loss: 0.2850
Epoch 635/1000

Epoch 00635: val_loss improved from 0.28498 to 0.28485, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2688 - val_loss: 0.2848
Epoch 636/1000

Epoch 00636: val_loss improved from 0.28485 to 0.28472, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2687 - val_loss: 0.2847
Epoch 637/1000

Epoch 00637: val_loss improved from 0.28472 to 0.28459, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2685 - val_loss: 0.2846
Epoch 638/1000

Epoch 00638: val_loss improved from 0.28459 to 0.28447, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2683 - val_loss: 0.2845
Epoch 639/1000

Epoch 00639: val_loss improved from 0.28447 to 0.28434, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2682 - val_loss: 0.2843
Epoch 640/1000

Epoch 00640: val_loss improved from 0.28434 to 0.28421, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2680 - val_loss: 0.2842
Epoch 641/1000

Epoch 00641: val_loss improved from 0.28421 to 0.28409, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2678 - val_loss: 0.2841
Epoch 642/1000

Epoch 00642: val_loss improved from 0.28409 to 0.28396, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2677 - val_loss: 0.2840
Epoch 643/1000

Epoch 00643: val_loss improved from 0.28396 to 0.28383, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2675 - val_loss: 0.2838
Epoch 644/1000

Epoch 00644: val_loss improved from 0.28383 to 0.28370, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2673 - val_loss: 0.2837
Epoch 645/1000

Epoch 00645: val_loss improved from 0.28370 to 0.28358, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2672 - val_loss: 0.2836
Epoch 646/1000

Epoch 00646: val_loss improved from 0.28358 to 0.28345, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2670 - val_loss: 0.2834
Epoch 647/1000

Epoch 00647: val_loss improved from 0.28345 to 0.28332, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2668 - val_loss: 0.2833
Epoch 648/1000

Epoch 00648: val_loss improved from 0.28332 to 0.28320, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2667 - val_loss: 0.2832
Epoch 649/1000

Epoch 00649: val_loss improved from 0.28320 to 0.28307, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2665 - val_loss: 0.2831
Epoch 650/1000

Epoch 00650: val_loss improved from 0.28307 to 0.28294, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2663 - val_loss: 0.2829
Epoch 651/1000

Epoch 00651: val_loss improved from 0.28294 to 0.28281, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2662 - val_loss: 0.2828
Epoch 652/1000

Epoch 00652: val_loss improved from 0.28281 to 0.28268, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2660 - val_loss: 0.2827
Epoch 653/1000

Epoch 00653: val_loss improved from 0.28268 to 0.28256, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2658 - val_loss: 0.2826
Epoch 654/1000

Epoch 00654: val_loss improved from 0.28256 to 0.28243, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2657 - val_loss: 0.2824
Epoch 655/1000

Epoch 00655: val_loss improved from 0.28243 to 0.28230, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2655 - val_loss: 0.2823
Epoch 656/1000

Epoch 00656: val_loss improved from 0.28230 to 0.28218, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2653 - val_loss: 0.2822
Epoch 657/1000

Epoch 00657: val_loss improved from 0.28218 to 0.28205, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2652 - val_loss: 0.2820
Epoch 658/1000

Epoch 00658: val_loss improved from 0.28205 to 0.28192, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2650 - val_loss: 0.2819
Epoch 659/1000

Epoch 00659: val_loss improved from 0.28192 to 0.28179, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2648 - val_loss: 0.2818
Epoch 660/1000

Epoch 00660: val_loss improved from 0.28179 to 0.28167, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2647 - val_loss: 0.2817
Epoch 661/1000

Epoch 00661: val_loss improved from 0.28167 to 0.28154, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2645 - val_loss: 0.2815
Epoch 662/1000

Epoch 00662: val_loss improved from 0.28154 to 0.28141, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2643 - val_loss: 0.2814
Epoch 663/1000

Epoch 00663: val_loss improved from 0.28141 to 0.28128, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2642 - val_loss: 0.2813
Epoch 664/1000

Epoch 00664: val_loss improved from 0.28128 to 0.28116, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2640 - val_loss: 0.2812
Epoch 665/1000

Epoch 00665: val_loss improved from 0.28116 to 0.28103, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2638 - val_loss: 0.2810
Epoch 666/1000

Epoch 00666: val_loss improved from 0.28103 to 0.28090, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2637 - val_loss: 0.2809
Epoch 667/1000

Epoch 00667: val_loss improved from 0.28090 to 0.28077, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2635 - val_loss: 0.2808
Epoch 668/1000

Epoch 00668: val_loss improved from 0.28077 to 0.28065, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2633 - val_loss: 0.2806
Epoch 669/1000

Epoch 00669: val_loss improved from 0.28065 to 0.28052, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 8s - loss: 0.2632 - val_loss: 0.2805
Epoch 670/1000

Epoch 00670: val_loss improved from 0.28052 to 0.28039, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2630 - val_loss: 0.2804
Epoch 671/1000

Epoch 00671: val_loss improved from 0.28039 to 0.28026, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2628 - val_loss: 0.2803
Epoch 672/1000

Epoch 00672: val_loss improved from 0.28026 to 0.28014, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2627 - val_loss: 0.2801
Epoch 673/1000

Epoch 00673: val_loss improved from 0.28014 to 0.28001, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2625 - val_loss: 0.2800
Epoch 674/1000

Epoch 00674: val_loss improved from 0.28001 to 0.27988, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2623 - val_loss: 0.2799
Epoch 675/1000

Epoch 00675: val_loss improved from 0.27988 to 0.27975, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2622 - val_loss: 0.2798
Epoch 676/1000

Epoch 00676: val_loss improved from 0.27975 to 0.27963, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2620 - val_loss: 0.2796
Epoch 677/1000

Epoch 00677: val_loss improved from 0.27963 to 0.27950, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2618 - val_loss: 0.2795
Epoch 678/1000

Epoch 00678: val_loss improved from 0.27950 to 0.27937, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2617 - val_loss: 0.2794
Epoch 679/1000

Epoch 00679: val_loss improved from 0.27937 to 0.27924, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2615 - val_loss: 0.2792
Epoch 680/1000

Epoch 00680: val_loss improved from 0.27924 to 0.27912, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2613 - val_loss: 0.2791
Epoch 681/1000

Epoch 00681: val_loss improved from 0.27912 to 0.27899, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2612 - val_loss: 0.2790
Epoch 682/1000

Epoch 00682: val_loss improved from 0.27899 to 0.27886, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2610 - val_loss: 0.2789
Epoch 683/1000

Epoch 00683: val_loss improved from 0.27886 to 0.27873, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2608 - val_loss: 0.2787
Epoch 684/1000

Epoch 00684: val_loss improved from 0.27873 to 0.27860, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2607 - val_loss: 0.2786
Epoch 685/1000

Epoch 00685: val_loss improved from 0.27860 to 0.27848, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2605 - val_loss: 0.2785
Epoch 686/1000

Epoch 00686: val_loss improved from 0.27848 to 0.27835, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2603 - val_loss: 0.2784
Epoch 687/1000

Epoch 00687: val_loss improved from 0.27835 to 0.27822, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2602 - val_loss: 0.2782
Epoch 688/1000

Epoch 00688: val_loss improved from 0.27822 to 0.27810, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2600 - val_loss: 0.2781
Epoch 689/1000

Epoch 00689: val_loss improved from 0.27810 to 0.27797, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2598 - val_loss: 0.2780
Epoch 690/1000

Epoch 00690: val_loss improved from 0.27797 to 0.27784, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2597 - val_loss: 0.2778
Epoch 691/1000

Epoch 00691: val_loss improved from 0.27784 to 0.27771, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2595 - val_loss: 0.2777
Epoch 692/1000

Epoch 00692: val_loss improved from 0.27771 to 0.27758, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.2593 - val_loss: 0.2776
Epoch 693/1000

Epoch 00693: val_loss improved from 0.27758 to 0.27746, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2592 - val_loss: 0.2775
Epoch 694/1000

Epoch 00694: val_loss improved from 0.27746 to 0.27733, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2590 - val_loss: 0.2773
Epoch 695/1000

Epoch 00695: val_loss improved from 0.27733 to 0.27720, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2588 - val_loss: 0.2772
Epoch 696/1000

Epoch 00696: val_loss improved from 0.27720 to 0.27707, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2587 - val_loss: 0.2771
Epoch 697/1000

Epoch 00697: val_loss improved from 0.27707 to 0.27695, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2585 - val_loss: 0.2769
Epoch 698/1000

Epoch 00698: val_loss improved from 0.27695 to 0.27682, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2583 - val_loss: 0.2768
Epoch 699/1000

Epoch 00699: val_loss improved from 0.27682 to 0.27669, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2582 - val_loss: 0.2767
Epoch 700/1000

Epoch 00700: val_loss improved from 0.27669 to 0.27657, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2580 - val_loss: 0.2766
Epoch 701/1000

Epoch 00701: val_loss improved from 0.27657 to 0.27644, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2578 - val_loss: 0.2764
Epoch 702/1000

Epoch 00702: val_loss improved from 0.27644 to 0.27631, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2577 - val_loss: 0.2763
Epoch 703/1000

Epoch 00703: val_loss improved from 0.27631 to 0.27618, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 10s - loss: 0.2575 - val_loss: 0.2762
Epoch 704/1000

Epoch 00704: val_loss improved from 0.27618 to 0.27606, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2573 - val_loss: 0.2761
Epoch 705/1000

Epoch 00705: val_loss improved from 0.27606 to 0.27593, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2572 - val_loss: 0.2759
Epoch 706/1000

Epoch 00706: val_loss improved from 0.27593 to 0.27580, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2570 - val_loss: 0.2758
Epoch 707/1000

Epoch 00707: val_loss improved from 0.27580 to 0.27567, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2568 - val_loss: 0.2757
Epoch 708/1000

Epoch 00708: val_loss improved from 0.27567 to 0.27555, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2567 - val_loss: 0.2755
Epoch 709/1000

Epoch 00709: val_loss improved from 0.27555 to 0.27542, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2565 - val_loss: 0.2754
Epoch 710/1000

Epoch 00710: val_loss improved from 0.27542 to 0.27529, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2563 - val_loss: 0.2753
Epoch 711/1000

Epoch 00711: val_loss improved from 0.27529 to 0.27517, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2562 - val_loss: 0.2752
Epoch 712/1000

Epoch 00712: val_loss improved from 0.27517 to 0.27504, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2560 - val_loss: 0.2750
Epoch 713/1000

Epoch 00713: val_loss improved from 0.27504 to 0.27491, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2558 - val_loss: 0.2749
Epoch 714/1000

Epoch 00714: val_loss improved from 0.27491 to 0.27478, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2557 - val_loss: 0.2748
Epoch 715/1000

Epoch 00715: val_loss improved from 0.27478 to 0.27466, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2555 - val_loss: 0.2747
Epoch 716/1000

Epoch 00716: val_loss improved from 0.27466 to 0.27453, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2553 - val_loss: 0.2745
Epoch 717/1000

Epoch 00717: val_loss improved from 0.27453 to 0.27440, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2552 - val_loss: 0.2744
Epoch 718/1000

Epoch 00718: val_loss improved from 0.27440 to 0.27428, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2550 - val_loss: 0.2743
Epoch 719/1000

Epoch 00719: val_loss improved from 0.27428 to 0.27415, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2548 - val_loss: 0.2741
Epoch 720/1000

Epoch 00720: val_loss improved from 0.27415 to 0.27402, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2546 - val_loss: 0.2740
Epoch 721/1000

Epoch 00721: val_loss improved from 0.27402 to 0.27389, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2545 - val_loss: 0.2739
Epoch 722/1000

Epoch 00722: val_loss improved from 0.27389 to 0.27377, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2543 - val_loss: 0.2738
Epoch 723/1000

Epoch 00723: val_loss improved from 0.27377 to 0.27364, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2541 - val_loss: 0.2736
Epoch 724/1000

Epoch 00724: val_loss improved from 0.27364 to 0.27351, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2540 - val_loss: 0.2735
Epoch 725/1000

Epoch 00725: val_loss improved from 0.27351 to 0.27339, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2538 - val_loss: 0.2734
Epoch 726/1000

Epoch 00726: val_loss improved from 0.27339 to 0.27326, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2536 - val_loss: 0.2733
Epoch 727/1000

Epoch 00727: val_loss improved from 0.27326 to 0.27313, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2535 - val_loss: 0.2731
Epoch 728/1000

Epoch 00728: val_loss improved from 0.27313 to 0.27300, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2533 - val_loss: 0.2730
Epoch 729/1000

Epoch 00729: val_loss improved from 0.27300 to 0.27288, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2531 - val_loss: 0.2729
Epoch 730/1000

Epoch 00730: val_loss improved from 0.27288 to 0.27275, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2530 - val_loss: 0.2728
Epoch 731/1000

Epoch 00731: val_loss improved from 0.27275 to 0.27262, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2528 - val_loss: 0.2726
Epoch 732/1000

Epoch 00732: val_loss improved from 0.27262 to 0.27250, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2526 - val_loss: 0.2725
Epoch 733/1000

Epoch 00733: val_loss improved from 0.27250 to 0.27237, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2525 - val_loss: 0.2724
Epoch 734/1000

Epoch 00734: val_loss improved from 0.27237 to 0.27224, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2523 - val_loss: 0.2722
Epoch 735/1000

Epoch 00735: val_loss improved from 0.27224 to 0.27212, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2521 - val_loss: 0.2721
Epoch 736/1000

Epoch 00736: val_loss improved from 0.27212 to 0.27199, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2520 - val_loss: 0.2720
Epoch 737/1000

Epoch 00737: val_loss improved from 0.27199 to 0.27186, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2518 - val_loss: 0.2719
Epoch 738/1000

Epoch 00738: val_loss improved from 0.27186 to 0.27173, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2516 - val_loss: 0.2717
Epoch 739/1000

Epoch 00739: val_loss improved from 0.27173 to 0.27161, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2515 - val_loss: 0.2716
Epoch 740/1000

Epoch 00740: val_loss improved from 0.27161 to 0.27148, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2513 - val_loss: 0.2715
Epoch 741/1000

Epoch 00741: val_loss improved from 0.27148 to 0.27135, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2511 - val_loss: 0.2714
Epoch 742/1000

Epoch 00742: val_loss improved from 0.27135 to 0.27123, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2510 - val_loss: 0.2712
Epoch 743/1000

Epoch 00743: val_loss improved from 0.27123 to 0.27110, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2508 - val_loss: 0.2711
Epoch 744/1000

Epoch 00744: val_loss improved from 0.27110 to 0.27097, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2506 - val_loss: 0.2710
Epoch 745/1000

Epoch 00745: val_loss improved from 0.27097 to 0.27085, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2505 - val_loss: 0.2708
Epoch 746/1000

Epoch 00746: val_loss improved from 0.27085 to 0.27072, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2503 - val_loss: 0.2707
Epoch 747/1000

Epoch 00747: val_loss improved from 0.27072 to 0.27059, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2501 - val_loss: 0.2706
Epoch 748/1000

Epoch 00748: val_loss improved from 0.27059 to 0.27047, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2500 - val_loss: 0.2705
Epoch 749/1000

Epoch 00749: val_loss improved from 0.27047 to 0.27034, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2498 - val_loss: 0.2703
Epoch 750/1000

Epoch 00750: val_loss improved from 0.27034 to 0.27021, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2496 - val_loss: 0.2702
Epoch 751/1000

Epoch 00751: val_loss improved from 0.27021 to 0.27009, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2495 - val_loss: 0.2701
Epoch 752/1000

Epoch 00752: val_loss improved from 0.27009 to 0.26996, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2493 - val_loss: 0.2700
Epoch 753/1000

Epoch 00753: val_loss improved from 0.26996 to 0.26983, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2491 - val_loss: 0.2698
Epoch 754/1000

Epoch 00754: val_loss improved from 0.26983 to 0.26971, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2490 - val_loss: 0.2697
Epoch 755/1000

Epoch 00755: val_loss improved from 0.26971 to 0.26958, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2488 - val_loss: 0.2696
Epoch 756/1000

Epoch 00756: val_loss improved from 0.26958 to 0.26945, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2486 - val_loss: 0.2695
Epoch 757/1000

Epoch 00757: val_loss improved from 0.26945 to 0.26933, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2485 - val_loss: 0.2693
Epoch 758/1000

Epoch 00758: val_loss improved from 0.26933 to 0.26920, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2483 - val_loss: 0.2692
Epoch 759/1000

Epoch 00759: val_loss improved from 0.26920 to 0.26907, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.2481 - val_loss: 0.2691
Epoch 760/1000

Epoch 00760: val_loss improved from 0.26907 to 0.26895, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2480 - val_loss: 0.2689
Epoch 761/1000

Epoch 00761: val_loss improved from 0.26895 to 0.26882, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2478 - val_loss: 0.2688
Epoch 762/1000

Epoch 00762: val_loss improved from 0.26882 to 0.26869, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2476 - val_loss: 0.2687
Epoch 763/1000

Epoch 00763: val_loss improved from 0.26869 to 0.26857, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2475 - val_loss: 0.2686
Epoch 764/1000

Epoch 00764: val_loss improved from 0.26857 to 0.26844, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2473 - val_loss: 0.2684
Epoch 765/1000

Epoch 00765: val_loss improved from 0.26844 to 0.26832, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2471 - val_loss: 0.2683
Epoch 766/1000

Epoch 00766: val_loss improved from 0.26832 to 0.26819, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2470 - val_loss: 0.2682
Epoch 767/1000

Epoch 00767: val_loss improved from 0.26819 to 0.26806, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2468 - val_loss: 0.2681
Epoch 768/1000

Epoch 00768: val_loss improved from 0.26806 to 0.26794, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2466 - val_loss: 0.2679
Epoch 769/1000

Epoch 00769: val_loss improved from 0.26794 to 0.26781, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2465 - val_loss: 0.2678
Epoch 770/1000

Epoch 00770: val_loss improved from 0.26781 to 0.26768, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2463 - val_loss: 0.2677
Epoch 771/1000

Epoch 00771: val_loss improved from 0.26768 to 0.26756, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2461 - val_loss: 0.2676
Epoch 772/1000

Epoch 00772: val_loss improved from 0.26756 to 0.26743, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2460 - val_loss: 0.2674
Epoch 773/1000

Epoch 00773: val_loss improved from 0.26743 to 0.26730, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2458 - val_loss: 0.2673
Epoch 774/1000

Epoch 00774: val_loss improved from 0.26730 to 0.26718, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2456 - val_loss: 0.2672
Epoch 775/1000

Epoch 00775: val_loss improved from 0.26718 to 0.26705, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 8s - loss: 0.2455 - val_loss: 0.2671
Epoch 776/1000

Epoch 00776: val_loss improved from 0.26705 to 0.26693, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2453 - val_loss: 0.2669
Epoch 777/1000

Epoch 00777: val_loss improved from 0.26693 to 0.26680, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2451 - val_loss: 0.2668
Epoch 778/1000

Epoch 00778: val_loss improved from 0.26680 to 0.26667, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2450 - val_loss: 0.2667
Epoch 779/1000

Epoch 00779: val_loss improved from 0.26667 to 0.26655, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2448 - val_loss: 0.2665
Epoch 780/1000

Epoch 00780: val_loss improved from 0.26655 to 0.26642, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2446 - val_loss: 0.2664
Epoch 781/1000

Epoch 00781: val_loss improved from 0.26642 to 0.26630, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2445 - val_loss: 0.2663
Epoch 782/1000

Epoch 00782: val_loss improved from 0.26630 to 0.26617, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2443 - val_loss: 0.2662
Epoch 783/1000

Epoch 00783: val_loss improved from 0.26617 to 0.26604, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2441 - val_loss: 0.2660
Epoch 784/1000

Epoch 00784: val_loss improved from 0.26604 to 0.26592, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2440 - val_loss: 0.2659
Epoch 785/1000

Epoch 00785: val_loss improved from 0.26592 to 0.26579, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2438 - val_loss: 0.2658
Epoch 786/1000

Epoch 00786: val_loss improved from 0.26579 to 0.26567, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2436 - val_loss: 0.2657
Epoch 787/1000

Epoch 00787: val_loss improved from 0.26567 to 0.26554, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2435 - val_loss: 0.2655
Epoch 788/1000

Epoch 00788: val_loss improved from 0.26554 to 0.26542, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2433 - val_loss: 0.2654
Epoch 789/1000

Epoch 00789: val_loss improved from 0.26542 to 0.26529, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2431 - val_loss: 0.2653
Epoch 790/1000

Epoch 00790: val_loss improved from 0.26529 to 0.26516, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2430 - val_loss: 0.2652
Epoch 791/1000

Epoch 00791: val_loss improved from 0.26516 to 0.26504, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2428 - val_loss: 0.2650
Epoch 792/1000

Epoch 00792: val_loss improved from 0.26504 to 0.26491, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2426 - val_loss: 0.2649
Epoch 793/1000

Epoch 00793: val_loss improved from 0.26491 to 0.26479, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2425 - val_loss: 0.2648
Epoch 794/1000

Epoch 00794: val_loss improved from 0.26479 to 0.26466, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2423 - val_loss: 0.2647
Epoch 795/1000

Epoch 00795: val_loss improved from 0.26466 to 0.26454, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2421 - val_loss: 0.2645
Epoch 796/1000

Epoch 00796: val_loss improved from 0.26454 to 0.26441, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2420 - val_loss: 0.2644
Epoch 797/1000

Epoch 00797: val_loss improved from 0.26441 to 0.26429, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2418 - val_loss: 0.2643
Epoch 798/1000

Epoch 00798: val_loss improved from 0.26429 to 0.26416, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2416 - val_loss: 0.2642
Epoch 799/1000

Epoch 00799: val_loss improved from 0.26416 to 0.26404, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2415 - val_loss: 0.2640
Epoch 800/1000

Epoch 00800: val_loss improved from 0.26404 to 0.26391, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2413 - val_loss: 0.2639
Epoch 801/1000

Epoch 00801: val_loss improved from 0.26391 to 0.26378, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2411 - val_loss: 0.2638
Epoch 802/1000

Epoch 00802: val_loss improved from 0.26378 to 0.26366, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2410 - val_loss: 0.2637
Epoch 803/1000

Epoch 00803: val_loss improved from 0.26366 to 0.26353, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2408 - val_loss: 0.2635
Epoch 804/1000

Epoch 00804: val_loss improved from 0.26353 to 0.26341, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2406 - val_loss: 0.2634
Epoch 805/1000

Epoch 00805: val_loss improved from 0.26341 to 0.26328, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2405 - val_loss: 0.2633
Epoch 806/1000

Epoch 00806: val_loss improved from 0.26328 to 0.26316, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2403 - val_loss: 0.2632
Epoch 807/1000

Epoch 00807: val_loss improved from 0.26316 to 0.26303, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2401 - val_loss: 0.2630
Epoch 808/1000

Epoch 00808: val_loss improved from 0.26303 to 0.26291, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2400 - val_loss: 0.2629
Epoch 809/1000

Epoch 00809: val_loss improved from 0.26291 to 0.26278, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2398 - val_loss: 0.2628
Epoch 810/1000

Epoch 00810: val_loss improved from 0.26278 to 0.26266, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2396 - val_loss: 0.2627
Epoch 811/1000

Epoch 00811: val_loss improved from 0.26266 to 0.26253, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2395 - val_loss: 0.2625
Epoch 812/1000

Epoch 00812: val_loss improved from 0.26253 to 0.26241, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2393 - val_loss: 0.2624
Epoch 813/1000

Epoch 00813: val_loss improved from 0.26241 to 0.26228, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2391 - val_loss: 0.2623
Epoch 814/1000

Epoch 00814: val_loss improved from 0.26228 to 0.26216, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2390 - val_loss: 0.2622
Epoch 815/1000

Epoch 00815: val_loss improved from 0.26216 to 0.26203, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2388 - val_loss: 0.2620
Epoch 816/1000

Epoch 00816: val_loss improved from 0.26203 to 0.26191, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2386 - val_loss: 0.2619
Epoch 817/1000

Epoch 00817: val_loss improved from 0.26191 to 0.26178, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2385 - val_loss: 0.2618
Epoch 818/1000

Epoch 00818: val_loss improved from 0.26178 to 0.26166, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2383 - val_loss: 0.2617
Epoch 819/1000

Epoch 00819: val_loss improved from 0.26166 to 0.26153, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.2381 - val_loss: 0.2615
Epoch 820/1000

Epoch 00820: val_loss improved from 0.26153 to 0.26141, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2380 - val_loss: 0.2614
Epoch 821/1000

Epoch 00821: val_loss improved from 0.26141 to 0.26128, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2378 - val_loss: 0.2613
Epoch 822/1000

Epoch 00822: val_loss improved from 0.26128 to 0.26116, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2376 - val_loss: 0.2612
Epoch 823/1000

Epoch 00823: val_loss improved from 0.26116 to 0.26103, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2375 - val_loss: 0.2610
Epoch 824/1000

Epoch 00824: val_loss improved from 0.26103 to 0.26091, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2373 - val_loss: 0.2609
Epoch 825/1000

Epoch 00825: val_loss improved from 0.26091 to 0.26078, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2372 - val_loss: 0.2608
Epoch 826/1000

Epoch 00826: val_loss improved from 0.26078 to 0.26066, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2370 - val_loss: 0.2607
Epoch 827/1000

Epoch 00827: val_loss improved from 0.26066 to 0.26054, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2368 - val_loss: 0.2605
Epoch 828/1000

Epoch 00828: val_loss improved from 0.26054 to 0.26041, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2367 - val_loss: 0.2604
Epoch 829/1000

Epoch 00829: val_loss improved from 0.26041 to 0.26029, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2365 - val_loss: 0.2603
Epoch 830/1000

Epoch 00830: val_loss improved from 0.26029 to 0.26016, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2363 - val_loss: 0.2602
Epoch 831/1000

Epoch 00831: val_loss improved from 0.26016 to 0.26004, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2362 - val_loss: 0.2600
Epoch 832/1000

Epoch 00832: val_loss improved from 0.26004 to 0.25991, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2360 - val_loss: 0.2599
Epoch 833/1000

Epoch 00833: val_loss improved from 0.25991 to 0.25979, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2358 - val_loss: 0.2598
Epoch 834/1000

Epoch 00834: val_loss improved from 0.25979 to 0.25966, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2357 - val_loss: 0.2597
Epoch 835/1000

Epoch 00835: val_loss improved from 0.25966 to 0.25954, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2355 - val_loss: 0.2595
Epoch 836/1000

Epoch 00836: val_loss improved from 0.25954 to 0.25942, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2353 - val_loss: 0.2594
Epoch 837/1000

Epoch 00837: val_loss improved from 0.25942 to 0.25929, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2352 - val_loss: 0.2593
Epoch 838/1000

Epoch 00838: val_loss improved from 0.25929 to 0.25917, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2350 - val_loss: 0.2592
Epoch 839/1000

Epoch 00839: val_loss improved from 0.25917 to 0.25904, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2348 - val_loss: 0.2590
Epoch 840/1000

Epoch 00840: val_loss improved from 0.25904 to 0.25892, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2347 - val_loss: 0.2589
Epoch 841/1000

Epoch 00841: val_loss improved from 0.25892 to 0.25879, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2345 - val_loss: 0.2588
Epoch 842/1000

Epoch 00842: val_loss improved from 0.25879 to 0.25867, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2343 - val_loss: 0.2587
Epoch 843/1000

Epoch 00843: val_loss improved from 0.25867 to 0.25855, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 8s - loss: 0.2342 - val_loss: 0.2585
Epoch 844/1000

Epoch 00844: val_loss improved from 0.25855 to 0.25842, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2340 - val_loss: 0.2584
Epoch 845/1000

Epoch 00845: val_loss improved from 0.25842 to 0.25830, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.2338 - val_loss: 0.2583
Epoch 846/1000

Epoch 00846: val_loss improved from 0.25830 to 0.25818, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2337 - val_loss: 0.2582
Epoch 847/1000

Epoch 00847: val_loss improved from 0.25818 to 0.25805, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2335 - val_loss: 0.2581
Epoch 848/1000

Epoch 00848: val_loss improved from 0.25805 to 0.25793, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2334 - val_loss: 0.2579
Epoch 849/1000

Epoch 00849: val_loss improved from 0.25793 to 0.25780, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2332 - val_loss: 0.2578
Epoch 850/1000

Epoch 00850: val_loss improved from 0.25780 to 0.25768, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2330 - val_loss: 0.2577
Epoch 851/1000

Epoch 00851: val_loss improved from 0.25768 to 0.25756, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2329 - val_loss: 0.2576
Epoch 852/1000

Epoch 00852: val_loss improved from 0.25756 to 0.25743, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2327 - val_loss: 0.2574
Epoch 853/1000

Epoch 00853: val_loss improved from 0.25743 to 0.25731, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2325 - val_loss: 0.2573
Epoch 854/1000

Epoch 00854: val_loss improved from 0.25731 to 0.25719, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2324 - val_loss: 0.2572
Epoch 855/1000

Epoch 00855: val_loss improved from 0.25719 to 0.25706, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2322 - val_loss: 0.2571
Epoch 856/1000

Epoch 00856: val_loss improved from 0.25706 to 0.25694, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2320 - val_loss: 0.2569
Epoch 857/1000

Epoch 00857: val_loss improved from 0.25694 to 0.25682, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2319 - val_loss: 0.2568
Epoch 858/1000

Epoch 00858: val_loss improved from 0.25682 to 0.25669, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2317 - val_loss: 0.2567
Epoch 859/1000

Epoch 00859: val_loss improved from 0.25669 to 0.25657, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2315 - val_loss: 0.2566
Epoch 860/1000

Epoch 00860: val_loss improved from 0.25657 to 0.25645, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2314 - val_loss: 0.2564
Epoch 861/1000

Epoch 00861: val_loss improved from 0.25645 to 0.25632, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2312 - val_loss: 0.2563
Epoch 862/1000

Epoch 00862: val_loss improved from 0.25632 to 0.25620, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2310 - val_loss: 0.2562
Epoch 863/1000

Epoch 00863: val_loss improved from 0.25620 to 0.25608, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2309 - val_loss: 0.2561
Epoch 864/1000

Epoch 00864: val_loss improved from 0.25608 to 0.25596, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2307 - val_loss: 0.2560
Epoch 865/1000

Epoch 00865: val_loss improved from 0.25596 to 0.25583, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2306 - val_loss: 0.2558
Epoch 866/1000

Epoch 00866: val_loss improved from 0.25583 to 0.25571, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2304 - val_loss: 0.2557
Epoch 867/1000

Epoch 00867: val_loss improved from 0.25571 to 0.25559, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2302 - val_loss: 0.2556
Epoch 868/1000

Epoch 00868: val_loss improved from 0.25559 to 0.25546, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2301 - val_loss: 0.2555
Epoch 869/1000

Epoch 00869: val_loss improved from 0.25546 to 0.25534, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2299 - val_loss: 0.2553
Epoch 870/1000

Epoch 00870: val_loss improved from 0.25534 to 0.25522, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2297 - val_loss: 0.2552
Epoch 871/1000

Epoch 00871: val_loss improved from 0.25522 to 0.25509, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2296 - val_loss: 0.2551
Epoch 872/1000

Epoch 00872: val_loss improved from 0.25509 to 0.25497, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2294 - val_loss: 0.2550
Epoch 873/1000

Epoch 00873: val_loss improved from 0.25497 to 0.25485, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2292 - val_loss: 0.2548
Epoch 874/1000

Epoch 00874: val_loss improved from 0.25485 to 0.25473, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2291 - val_loss: 0.2547
Epoch 875/1000

Epoch 00875: val_loss improved from 0.25473 to 0.25460, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2289 - val_loss: 0.2546
Epoch 876/1000

Epoch 00876: val_loss improved from 0.25460 to 0.25448, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2287 - val_loss: 0.2545
Epoch 877/1000

Epoch 00877: val_loss improved from 0.25448 to 0.25436, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2286 - val_loss: 0.2544
Epoch 878/1000

Epoch 00878: val_loss improved from 0.25436 to 0.25424, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2284 - val_loss: 0.2542
Epoch 879/1000

Epoch 00879: val_loss improved from 0.25424 to 0.25411, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2283 - val_loss: 0.2541
Epoch 880/1000

Epoch 00880: val_loss improved from 0.25411 to 0.25399, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2281 - val_loss: 0.2540
Epoch 881/1000

Epoch 00881: val_loss improved from 0.25399 to 0.25387, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2279 - val_loss: 0.2539
Epoch 882/1000

Epoch 00882: val_loss improved from 0.25387 to 0.25375, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2278 - val_loss: 0.2537
Epoch 883/1000

Epoch 00883: val_loss improved from 0.25375 to 0.25362, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2276 - val_loss: 0.2536
Epoch 884/1000

Epoch 00884: val_loss improved from 0.25362 to 0.25350, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2274 - val_loss: 0.2535
Epoch 885/1000

Epoch 00885: val_loss improved from 0.25350 to 0.25338, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2273 - val_loss: 0.2534
Epoch 886/1000

Epoch 00886: val_loss improved from 0.25338 to 0.25326, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2271 - val_loss: 0.2533
Epoch 887/1000

Epoch 00887: val_loss improved from 0.25326 to 0.25314, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2269 - val_loss: 0.2531
Epoch 888/1000

Epoch 00888: val_loss improved from 0.25314 to 0.25301, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 8s - loss: 0.2268 - val_loss: 0.2530
Epoch 889/1000

Epoch 00889: val_loss improved from 0.25301 to 0.25289, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2266 - val_loss: 0.2529
Epoch 890/1000

Epoch 00890: val_loss improved from 0.25289 to 0.25277, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2265 - val_loss: 0.2528
Epoch 891/1000

Epoch 00891: val_loss improved from 0.25277 to 0.25265, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2263 - val_loss: 0.2526
Epoch 892/1000

Epoch 00892: val_loss improved from 0.25265 to 0.25253, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2261 - val_loss: 0.2525
Epoch 893/1000

Epoch 00893: val_loss improved from 0.25253 to 0.25240, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2260 - val_loss: 0.2524
Epoch 894/1000

Epoch 00894: val_loss improved from 0.25240 to 0.25228, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2258 - val_loss: 0.2523
Epoch 895/1000

Epoch 00895: val_loss improved from 0.25228 to 0.25216, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2256 - val_loss: 0.2522
Epoch 896/1000

Epoch 00896: val_loss improved from 0.25216 to 0.25204, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2255 - val_loss: 0.2520
Epoch 897/1000

Epoch 00897: val_loss improved from 0.25204 to 0.25192, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2253 - val_loss: 0.2519
Epoch 898/1000

Epoch 00898: val_loss improved from 0.25192 to 0.25180, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2252 - val_loss: 0.2518
Epoch 899/1000

Epoch 00899: val_loss improved from 0.25180 to 0.25168, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2250 - val_loss: 0.2517
Epoch 900/1000

Epoch 00900: val_loss improved from 0.25168 to 0.25155, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2248 - val_loss: 0.2516
Epoch 901/1000

Epoch 00901: val_loss improved from 0.25155 to 0.25143, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2247 - val_loss: 0.2514
Epoch 902/1000

Epoch 00902: val_loss improved from 0.25143 to 0.25131, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2245 - val_loss: 0.2513
Epoch 903/1000

Epoch 00903: val_loss improved from 0.25131 to 0.25119, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2243 - val_loss: 0.2512
Epoch 904/1000

Epoch 00904: val_loss improved from 0.25119 to 0.25107, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2242 - val_loss: 0.2511
Epoch 905/1000

Epoch 00905: val_loss improved from 0.25107 to 0.25095, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2240 - val_loss: 0.2509
Epoch 906/1000

Epoch 00906: val_loss improved from 0.25095 to 0.25083, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2239 - val_loss: 0.2508
Epoch 907/1000

Epoch 00907: val_loss improved from 0.25083 to 0.25070, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2237 - val_loss: 0.2507
Epoch 908/1000

Epoch 00908: val_loss improved from 0.25070 to 0.25058, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2235 - val_loss: 0.2506
Epoch 909/1000

Epoch 00909: val_loss improved from 0.25058 to 0.25046, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2234 - val_loss: 0.2505
Epoch 910/1000

Epoch 00910: val_loss improved from 0.25046 to 0.25034, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2232 - val_loss: 0.2503
Epoch 911/1000

Epoch 00911: val_loss improved from 0.25034 to 0.25022, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2231 - val_loss: 0.2502
Epoch 912/1000

Epoch 00912: val_loss improved from 0.25022 to 0.25010, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2229 - val_loss: 0.2501
Epoch 913/1000

Epoch 00913: val_loss improved from 0.25010 to 0.24998, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2227 - val_loss: 0.2500
Epoch 914/1000

Epoch 00914: val_loss improved from 0.24998 to 0.24986, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2226 - val_loss: 0.2499
Epoch 915/1000

Epoch 00915: val_loss improved from 0.24986 to 0.24974, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2224 - val_loss: 0.2497
Epoch 916/1000

Epoch 00916: val_loss improved from 0.24974 to 0.24962, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2222 - val_loss: 0.2496
Epoch 917/1000

Epoch 00917: val_loss improved from 0.24962 to 0.24950, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2221 - val_loss: 0.2495
Epoch 918/1000

Epoch 00918: val_loss improved from 0.24950 to 0.24938, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2219 - val_loss: 0.2494
Epoch 919/1000

Epoch 00919: val_loss improved from 0.24938 to 0.24925, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2218 - val_loss: 0.2493
Epoch 920/1000

Epoch 00920: val_loss improved from 0.24925 to 0.24913, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2216 - val_loss: 0.2491
Epoch 921/1000

Epoch 00921: val_loss improved from 0.24913 to 0.24901, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2214 - val_loss: 0.2490
Epoch 922/1000

Epoch 00922: val_loss improved from 0.24901 to 0.24889, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 8s - loss: 0.2213 - val_loss: 0.2489
Epoch 923/1000

Epoch 00923: val_loss improved from 0.24889 to 0.24877, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2211 - val_loss: 0.2488
Epoch 924/1000

Epoch 00924: val_loss improved from 0.24877 to 0.24865, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2209 - val_loss: 0.2487
Epoch 925/1000

Epoch 00925: val_loss improved from 0.24865 to 0.24853, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2208 - val_loss: 0.2485
Epoch 926/1000

Epoch 00926: val_loss improved from 0.24853 to 0.24841, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2206 - val_loss: 0.2484
Epoch 927/1000

Epoch 00927: val_loss improved from 0.24841 to 0.24829, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2205 - val_loss: 0.2483
Epoch 928/1000

Epoch 00928: val_loss improved from 0.24829 to 0.24817, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2203 - val_loss: 0.2482
Epoch 929/1000

Epoch 00929: val_loss improved from 0.24817 to 0.24805, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2201 - val_loss: 0.2481
Epoch 930/1000

Epoch 00930: val_loss improved from 0.24805 to 0.24793, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2200 - val_loss: 0.2479
Epoch 931/1000

Epoch 00931: val_loss improved from 0.24793 to 0.24781, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2198 - val_loss: 0.2478
Epoch 932/1000

Epoch 00932: val_loss improved from 0.24781 to 0.24769, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2197 - val_loss: 0.2477
Epoch 933/1000

Epoch 00933: val_loss improved from 0.24769 to 0.24757, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2195 - val_loss: 0.2476
Epoch 934/1000

Epoch 00934: val_loss improved from 0.24757 to 0.24745, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2193 - val_loss: 0.2475
Epoch 935/1000

Epoch 00935: val_loss improved from 0.24745 to 0.24733, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2192 - val_loss: 0.2473
Epoch 936/1000

Epoch 00936: val_loss improved from 0.24733 to 0.24721, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2190 - val_loss: 0.2472
Epoch 937/1000

Epoch 00937: val_loss improved from 0.24721 to 0.24709, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2189 - val_loss: 0.2471
Epoch 938/1000

Epoch 00938: val_loss improved from 0.24709 to 0.24698, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2187 - val_loss: 0.2470
Epoch 939/1000

Epoch 00939: val_loss improved from 0.24698 to 0.24686, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2185 - val_loss: 0.2469
Epoch 940/1000

Epoch 00940: val_loss improved from 0.24686 to 0.24674, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2184 - val_loss: 0.2467
Epoch 941/1000

Epoch 00941: val_loss improved from 0.24674 to 0.24662, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2182 - val_loss: 0.2466
Epoch 942/1000

Epoch 00942: val_loss improved from 0.24662 to 0.24650, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2180 - val_loss: 0.2465
Epoch 943/1000

Epoch 00943: val_loss improved from 0.24650 to 0.24638, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2179 - val_loss: 0.2464
Epoch 944/1000

Epoch 00944: val_loss improved from 0.24638 to 0.24626, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2177 - val_loss: 0.2463
Epoch 945/1000

Epoch 00945: val_loss improved from 0.24626 to 0.24614, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2176 - val_loss: 0.2461
Epoch 946/1000

Epoch 00946: val_loss improved from 0.24614 to 0.24602, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2174 - val_loss: 0.2460
Epoch 947/1000

Epoch 00947: val_loss improved from 0.24602 to 0.24590, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2172 - val_loss: 0.2459
Epoch 948/1000

Epoch 00948: val_loss improved from 0.24590 to 0.24578, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2171 - val_loss: 0.2458
Epoch 949/1000

Epoch 00949: val_loss improved from 0.24578 to 0.24566, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2169 - val_loss: 0.2457
Epoch 950/1000

Epoch 00950: val_loss improved from 0.24566 to 0.24554, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2168 - val_loss: 0.2455
Epoch 951/1000

Epoch 00951: val_loss improved from 0.24554 to 0.24542, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2166 - val_loss: 0.2454
Epoch 952/1000

Epoch 00952: val_loss improved from 0.24542 to 0.24531, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2164 - val_loss: 0.2453
Epoch 953/1000

Epoch 00953: val_loss improved from 0.24531 to 0.24519, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 9s - loss: 0.2163 - val_loss: 0.2452
Epoch 954/1000

Epoch 00954: val_loss improved from 0.24519 to 0.24507, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2161 - val_loss: 0.2451
Epoch 955/1000

Epoch 00955: val_loss improved from 0.24507 to 0.24495, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2160 - val_loss: 0.2449
Epoch 956/1000

Epoch 00956: val_loss improved from 0.24495 to 0.24483, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2158 - val_loss: 0.2448
Epoch 957/1000

Epoch 00957: val_loss improved from 0.24483 to 0.24471, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2156 - val_loss: 0.2447
Epoch 958/1000

Epoch 00958: val_loss improved from 0.24471 to 0.24459, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2155 - val_loss: 0.2446
Epoch 959/1000

Epoch 00959: val_loss improved from 0.24459 to 0.24448, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2153 - val_loss: 0.2445
Epoch 960/1000

Epoch 00960: val_loss improved from 0.24448 to 0.24436, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2152 - val_loss: 0.2444
Epoch 961/1000

Epoch 00961: val_loss improved from 0.24436 to 0.24424, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2150 - val_loss: 0.2442
Epoch 962/1000

Epoch 00962: val_loss improved from 0.24424 to 0.24412, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2149 - val_loss: 0.2441
Epoch 963/1000

Epoch 00963: val_loss improved from 0.24412 to 0.24400, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2147 - val_loss: 0.2440
Epoch 964/1000

Epoch 00964: val_loss improved from 0.24400 to 0.24388, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2145 - val_loss: 0.2439
Epoch 965/1000

Epoch 00965: val_loss improved from 0.24388 to 0.24377, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2144 - val_loss: 0.2438
Epoch 966/1000

Epoch 00966: val_loss improved from 0.24377 to 0.24365, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2142 - val_loss: 0.2436
Epoch 967/1000

Epoch 00967: val_loss improved from 0.24365 to 0.24353, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2141 - val_loss: 0.2435
Epoch 968/1000

Epoch 00968: val_loss improved from 0.24353 to 0.24341, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2139 - val_loss: 0.2434
Epoch 969/1000

Epoch 00969: val_loss improved from 0.24341 to 0.24329, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2137 - val_loss: 0.2433
Epoch 970/1000

Epoch 00970: val_loss improved from 0.24329 to 0.24318, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2136 - val_loss: 0.2432
Epoch 971/1000

Epoch 00971: val_loss improved from 0.24318 to 0.24306, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2134 - val_loss: 0.2431
Epoch 972/1000

Epoch 00972: val_loss improved from 0.24306 to 0.24294, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2133 - val_loss: 0.2429
Epoch 973/1000

Epoch 00973: val_loss improved from 0.24294 to 0.24282, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2131 - val_loss: 0.2428
Epoch 974/1000

Epoch 00974: val_loss improved from 0.24282 to 0.24271, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2129 - val_loss: 0.2427
Epoch 975/1000

Epoch 00975: val_loss improved from 0.24271 to 0.24259, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2128 - val_loss: 0.2426
Epoch 976/1000

Epoch 00976: val_loss improved from 0.24259 to 0.24247, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2126 - val_loss: 0.2425
Epoch 977/1000

Epoch 00977: val_loss improved from 0.24247 to 0.24235, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2125 - val_loss: 0.2424
Epoch 978/1000

Epoch 00978: val_loss improved from 0.24235 to 0.24223, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2123 - val_loss: 0.2422
Epoch 979/1000

Epoch 00979: val_loss improved from 0.24223 to 0.24212, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2121 - val_loss: 0.2421
Epoch 980/1000

Epoch 00980: val_loss improved from 0.24212 to 0.24200, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2120 - val_loss: 0.2420
Epoch 981/1000

Epoch 00981: val_loss improved from 0.24200 to 0.24188, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2118 - val_loss: 0.2419
Epoch 982/1000

Epoch 00982: val_loss improved from 0.24188 to 0.24177, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.2117 - val_loss: 0.2418
Epoch 983/1000

Epoch 00983: val_loss improved from 0.24177 to 0.24165, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.2115 - val_loss: 0.2416
Epoch 984/1000

Epoch 00984: val_loss improved from 0.24165 to 0.24153, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2114 - val_loss: 0.2415
Epoch 985/1000

Epoch 00985: val_loss improved from 0.24153 to 0.24141, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 7s - loss: 0.2112 - val_loss: 0.2414
Epoch 986/1000

Epoch 00986: val_loss improved from 0.24141 to 0.24130, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2110 - val_loss: 0.2413
Epoch 987/1000

Epoch 00987: val_loss improved from 0.24130 to 0.24118, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2109 - val_loss: 0.2412
Epoch 988/1000

Epoch 00988: val_loss improved from 0.24118 to 0.24106, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2107 - val_loss: 0.2411
Epoch 989/1000

Epoch 00989: val_loss improved from 0.24106 to 0.24095, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2106 - val_loss: 0.2409
Epoch 990/1000

Epoch 00990: val_loss improved from 0.24095 to 0.24083, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 5s - loss: 0.2104 - val_loss: 0.2408
Epoch 991/1000

Epoch 00991: val_loss improved from 0.24083 to 0.24071, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2103 - val_loss: 0.2407
Epoch 992/1000

Epoch 00992: val_loss improved from 0.24071 to 0.24060, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2101 - val_loss: 0.2406
Epoch 993/1000

Epoch 00993: val_loss improved from 0.24060 to 0.24048, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2099 - val_loss: 0.2405
Epoch 994/1000

Epoch 00994: val_loss improved from 0.24048 to 0.24036, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2098 - val_loss: 0.2404
Epoch 995/1000

Epoch 00995: val_loss improved from 0.24036 to 0.24025, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2096 - val_loss: 0.2402
Epoch 996/1000

Epoch 00996: val_loss improved from 0.24025 to 0.24013, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 4s - loss: 0.2095 - val_loss: 0.2401
Epoch 997/1000

Epoch 00997: val_loss improved from 0.24013 to 0.24002, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2093 - val_loss: 0.2400
Epoch 998/1000

Epoch 00998: val_loss improved from 0.24002 to 0.23990, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 6s - loss: 0.2092 - val_loss: 0.2399
Epoch 999/1000

Epoch 00999: val_loss improved from 0.23990 to 0.23978, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2090 - val_loss: 0.2398
Epoch 1000/1000

Epoch 01000: val_loss improved from 0.23978 to 0.23967, saving model to Models\Model8_filters_2_dense_1_denseSize_32_Dropout_0.4_20191029-232731_best_model.h5
15/15 - 3s - loss: 0.2088 - val_loss: 0.2397
[INFO] predicting .............
[inverted] predicting .............
original  .............


Mean absolute error (MAE):      64.599945
Mean squared error (MSE):       17143.954784
Root mean squared error (RMSE): 130.934926
R square (R^2):                 -3.555946
[3.17314901e+03 2.06118785e+01 2.81372729e+02 6.51006855e+04]
##############################################
   Model8_filters_2_dense_1_denseSize_32_Dropout_0.6_20191030-003737
##############################################
32
WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
Model: "model_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_15 (InputLayer)        [(None, 567, 756, 3)]     0         
_________________________________________________________________
conv2d_28 (Conv2D)           (None, 567, 756, 16)      448       
_________________________________________________________________
activation_33 (Activation)   (None, 567, 756, 16)      0         
_________________________________________________________________
batch_normalization_28 (Batc (None, 567, 756, 16)      64        
_________________________________________________________________
max_pooling2d_28 (MaxPooling (None, 283, 378, 16)      0         
_________________________________________________________________
conv2d_29 (Conv2D)           (None, 283, 378, 32)      4640      
_________________________________________________________________
activation_34 (Activation)   (None, 283, 378, 32)      0         
_________________________________________________________________
batch_normalization_29 (Batc (None, 283, 378, 32)      128       
_________________________________________________________________
max_pooling2d_29 (MaxPooling (None, 141, 189, 32)      0         
_________________________________________________________________
flatten_14 (Flatten)         (None, 852768)            0         
_________________________________________________________________
dense_19 (Dense)             (None, 32)                27288608  
_________________________________________________________________
activation_35 (Activation)   (None, 32)                0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_20 (Dense)             (None, 4)                 132       
=================================================================
Total params: 27,294,020
Trainable params: 27,293,924
Non-trainable params: 96
_________________________________________________________________
None
[INFO] training model...
Train on 15 samples, validate on 4 samples
Epoch 1/1000
2019-10-30 00:37:49.575082: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 104.47MiB (rounded to 109541376).  Current allocation summary follows.
2019-10-30 00:37:49.575489: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (256): 	Total Chunks: 473, Chunks in use: 471. 118.3KiB allocated for chunks. 117.8KiB in use in bin. 37.7KiB client-requested in use in bin.
2019-10-30 00:37:49.575830: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (512): 	Total Chunks: 15, Chunks in use: 15. 7.8KiB allocated for chunks. 7.8KiB in use in bin. 7.5KiB client-requested in use in bin.
2019-10-30 00:37:49.576258: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (1024): 	Total Chunks: 32, Chunks in use: 32. 55.5KiB allocated for chunks. 55.5KiB in use in bin. 53.3KiB client-requested in use in bin.
2019-10-30 00:37:49.576664: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (2048): 	Total Chunks: 9, Chunks in use: 8. 24.5KiB allocated for chunks. 20.8KiB in use in bin. 13.5KiB client-requested in use in bin.
2019-10-30 00:37:49.577001: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 00:37:49.577295: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 00:37:49.577589: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (16384): 	Total Chunks: 33, Chunks in use: 33. 660.8KiB allocated for chunks. 660.8KiB in use in bin. 594.0KiB client-requested in use in bin.
2019-10-30 00:37:49.577909: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (32768): 	Total Chunks: 6, Chunks in use: 6. 205.5KiB allocated for chunks. 205.5KiB in use in bin. 108.0KiB client-requested in use in bin.
2019-10-30 00:37:49.578298: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (65536): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 00:37:49.578595: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 00:37:49.578891: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (262144): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 00:37:49.579187: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (524288): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 00:37:49.579485: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 00:37:49.579783: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 00:37:49.580156: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 00:37:49.580458: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (8388608): 	Total Chunks: 22, Chunks in use: 17. 285.51MiB allocated for chunks. 221.21MiB in use in bin. 221.21MiB client-requested in use in bin.
2019-10-30 00:37:49.580792: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (16777216): 	Total Chunks: 2, Chunks in use: 1. 51.95MiB allocated for chunks. 25.92MiB in use in bin. 13.01MiB client-requested in use in bin.
2019-10-30 00:37:49.582142: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (33554432): 	Total Chunks: 7, Chunks in use: 7. 364.53MiB allocated for chunks. 364.53MiB in use in bin. 364.53MiB client-requested in use in bin.
2019-10-30 00:37:49.582570: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (67108864): 	Total Chunks: 14, Chunks in use: 14. 1.40GiB allocated for chunks. 1.40GiB in use in bin. 1.36GiB client-requested in use in bin.
2019-10-30 00:37:49.582996: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (134217728): 	Total Chunks: 5, Chunks in use: 5. 868.38MiB allocated for chunks. 868.38MiB in use in bin. 731.27MiB client-requested in use in bin.
2019-10-30 00:37:49.583420: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 00:37:49.584159: I tensorflow/core/common_runtime/bfc_allocator.cc:885] Bin for 104.47MiB was 64.00MiB, Chunk State: 
2019-10-30 00:37:49.584347: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 3149043968
2019-10-30 00:37:49.584507: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400000 next 1 of size 1280
2019-10-30 00:37:49.584685: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400500 next 2 of size 256
2019-10-30 00:37:49.584863: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400600 next 5 of size 256
2019-10-30 00:37:49.585320: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400700 next 4 of size 256
2019-10-30 00:37:49.585592: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400800 next 7 of size 256
2019-10-30 00:37:49.585818: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400900 next 8 of size 256
2019-10-30 00:37:49.586107: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400A00 next 9 of size 256
2019-10-30 00:37:49.586339: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400B00 next 10 of size 256
2019-10-30 00:37:49.586570: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400C00 next 12 of size 256
2019-10-30 00:37:49.586801: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400D00 next 14 of size 256
2019-10-30 00:37:49.587073: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400E00 next 15 of size 256
2019-10-30 00:37:49.587301: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702400F00 next 16 of size 256
2019-10-30 00:37:49.587529: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702401000 next 17 of size 256
2019-10-30 00:37:49.587756: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702401100 next 75 of size 256
2019-10-30 00:37:49.588006: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702401200 next 32 of size 256
2019-10-30 00:37:49.588247: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702401300 next 195 of size 256
2019-10-30 00:37:49.588475: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702401400 next 194 of size 256
2019-10-30 00:37:49.588706: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702401500 next 3 of size 256
2019-10-30 00:37:49.588951: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702401600 next 6 of size 1792
2019-10-30 00:37:49.589208: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702401D00 next 130 of size 256
2019-10-30 00:37:49.589451: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702401E00 next 128 of size 256
2019-10-30 00:37:49.589686: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702401F00 next 127 of size 256
2019-10-30 00:37:49.589938: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702402000 next 109 of size 256
2019-10-30 00:37:49.590185: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702402100 next 140 of size 256
2019-10-30 00:37:49.590415: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702402200 next 220 of size 256
2019-10-30 00:37:49.590645: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702402300 next 88 of size 256
2019-10-30 00:37:49.590877: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702402400 next 192 of size 1792
2019-10-30 00:37:49.591156: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702402B00 next 222 of size 256
2019-10-30 00:37:49.591391: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702402C00 next 163 of size 256
2019-10-30 00:37:49.591621: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702402D00 next 228 of size 256
2019-10-30 00:37:49.591854: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702402E00 next 114 of size 256
2019-10-30 00:37:49.592088: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702402F00 next 115 of size 256
2019-10-30 00:37:49.592319: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702403000 next 276 of size 256
2019-10-30 00:37:49.592550: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702403100 next 277 of size 256
2019-10-30 00:37:49.592781: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702403200 next 230 of size 2304
2019-10-30 00:37:49.593068: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702403B00 next 207 of size 1792
2019-10-30 00:37:49.593332: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000702404200 next 13 of size 27392
2019-10-30 00:37:49.593567: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070240AD00 next 11 of size 18432
2019-10-30 00:37:49.593798: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070240F500 next 29 of size 13644288
2019-10-30 00:37:49.594071: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000703112700 next 20 of size 13644288
2019-10-30 00:37:49.594306: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000703E15900 next 18 of size 13644288
2019-10-30 00:37:49.594542: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000704B18B00 next 46 of size 13667840
2019-10-30 00:37:49.594784: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705821900 next 59 of size 256
2019-10-30 00:37:49.595061: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705821A00 next 70 of size 256
2019-10-30 00:37:49.595290: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705821B00 next 62 of size 256
2019-10-30 00:37:49.595521: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705821C00 next 53 of size 256
2019-10-30 00:37:49.595750: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705821D00 next 65 of size 256
2019-10-30 00:37:49.595981: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705821E00 next 60 of size 256
2019-10-30 00:37:49.596209: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705821F00 next 56 of size 256
2019-10-30 00:37:49.596438: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705822000 next 58 of size 256
2019-10-30 00:37:49.596668: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705822100 next 49 of size 256
2019-10-30 00:37:49.596915: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705822200 next 51 of size 256
2019-10-30 00:37:49.597205: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705822300 next 71 of size 256
2019-10-30 00:37:49.597433: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705822400 next 74 of size 256
2019-10-30 00:37:49.597658: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705822500 next 76 of size 256
2019-10-30 00:37:49.597883: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705822600 next 198 of size 256
2019-10-30 00:37:49.598166: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705822700 next 197 of size 256
2019-10-30 00:37:49.598397: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705822800 next 54 of size 256
2019-10-30 00:37:49.598624: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705822900 next 68 of size 256
2019-10-30 00:37:49.598854: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705822A00 next 69 of size 1792
2019-10-30 00:37:49.599124: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705823100 next 63 of size 1792
2019-10-30 00:37:49.599354: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000705823800 next 50 of size 35072
2019-10-30 00:37:49.599585: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070582C100 next 66 of size 13644288
2019-10-30 00:37:49.599817: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070652F300 next 169 of size 256
2019-10-30 00:37:49.600150: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070652F400 next 159 of size 256
2019-10-30 00:37:49.600400: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070652F500 next 167 of size 256
2019-10-30 00:37:49.600630: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070652F600 next 171 of size 256
2019-10-30 00:37:49.600863: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070652F700 next 168 of size 256
2019-10-30 00:37:49.601094: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070652F800 next 44 of size 256
2019-10-30 00:37:49.601322: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070652F900 next 43 of size 256
2019-10-30 00:37:49.601550: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070652FA00 next 41 of size 256
2019-10-30 00:37:49.601776: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070652FB00 next 24 of size 256
2019-10-30 00:37:49.602101: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070652FC00 next 25 of size 256
2019-10-30 00:37:49.602336: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070652FD00 next 26 of size 256
2019-10-30 00:37:49.602564: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070652FE00 next 27 of size 256
2019-10-30 00:37:49.602789: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070652FF00 next 123 of size 256
2019-10-30 00:37:49.603021: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706530000 next 368 of size 256
2019-10-30 00:37:49.603248: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706530100 next 343 of size 256
2019-10-30 00:37:49.603476: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706530200 next 355 of size 256
2019-10-30 00:37:49.603708: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706530300 next 164 of size 256
2019-10-30 00:37:49.603970: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706530400 next 161 of size 1792
2019-10-30 00:37:49.604203: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706530B00 next 237 of size 18432
2019-10-30 00:37:49.604434: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706535300 next 23 of size 18432
2019-10-30 00:37:49.604665: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706539B00 next 42 of size 18432
2019-10-30 00:37:49.604916: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653E300 next 294 of size 256
2019-10-30 00:37:49.605172: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653E400 next 293 of size 256
2019-10-30 00:37:49.605400: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653E500 next 371 of size 256
2019-10-30 00:37:49.605626: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653E600 next 361 of size 256
2019-10-30 00:37:49.605855: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653E700 next 359 of size 512
2019-10-30 00:37:49.606085: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653E900 next 370 of size 256
2019-10-30 00:37:49.606313: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653EA00 next 420 of size 256
2019-10-30 00:37:49.606538: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653EB00 next 286 of size 256
2019-10-30 00:37:49.606769: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653EC00 next 284 of size 256
2019-10-30 00:37:49.607045: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653ED00 next 280 of size 256
2019-10-30 00:37:49.607282: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653EE00 next 366 of size 256
2019-10-30 00:37:49.607516: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653EF00 next 347 of size 256
2019-10-30 00:37:49.607751: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653F000 next 281 of size 256
2019-10-30 00:37:49.608027: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653F100 next 333 of size 256
2019-10-30 00:37:49.608259: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653F200 next 429 of size 256
2019-10-30 00:37:49.608486: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653F300 next 319 of size 256
2019-10-30 00:37:49.608717: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653F400 next 478 of size 256
2019-10-30 00:37:49.608966: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653F500 next 468 of size 256
2019-10-30 00:37:49.609297: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653F600 next 439 of size 256
2019-10-30 00:37:49.609495: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653F700 next 55 of size 256
2019-10-30 00:37:49.609675: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653F800 next 364 of size 256
2019-10-30 00:37:49.609876: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653F900 next 331 of size 256
2019-10-30 00:37:49.610261: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653FA00 next 441 of size 256
2019-10-30 00:37:49.610494: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653FB00 next 473 of size 256
2019-10-30 00:37:49.610723: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653FC00 next 334 of size 256
2019-10-30 00:37:49.611030: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653FD00 next 433 of size 256
2019-10-30 00:37:49.611314: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653FE00 next 451 of size 256
2019-10-30 00:37:49.611547: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070653FF00 next 84 of size 256
2019-10-30 00:37:49.611775: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706540000 next 475 of size 256
2019-10-30 00:37:49.612040: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706540100 next 437 of size 256
2019-10-30 00:37:49.612271: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706540200 next 344 of size 512
2019-10-30 00:37:49.612497: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706540400 next 481 of size 256
2019-10-30 00:37:49.612724: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706540500 next 438 of size 256
2019-10-30 00:37:49.613002: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706540600 next 367 of size 256
2019-10-30 00:37:49.613234: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706540700 next 421 of size 256
2019-10-30 00:37:49.613462: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706540800 next 474 of size 256
2019-10-30 00:37:49.613690: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706540900 next 470 of size 1792
2019-10-30 00:37:49.613924: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706541000 next 19 of size 256
2019-10-30 00:37:49.614152: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706541100 next 435 of size 512
2019-10-30 00:37:49.614379: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706541300 next 463 of size 256
2019-10-30 00:37:49.614612: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706541400 next 453 of size 2048
2019-10-30 00:37:49.614881: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706541C00 next 440 of size 256
2019-10-30 00:37:49.615151: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706541D00 next 430 of size 256
2019-10-30 00:37:49.615413: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706541E00 next 422 of size 256
2019-10-30 00:37:49.615648: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706541F00 next 434 of size 256
2019-10-30 00:37:49.615905: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706542000 next 427 of size 256
2019-10-30 00:37:49.616154: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706542100 next 432 of size 256
2019-10-30 00:37:49.616386: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706542200 next 424 of size 256
2019-10-30 00:37:49.616622: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706542300 next 426 of size 512
2019-10-30 00:37:49.616869: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706542500 next 428 of size 256
2019-10-30 00:37:49.617127: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706542600 next 436 of size 256
2019-10-30 00:37:49.617358: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706542700 next 189 of size 256
2019-10-30 00:37:49.617586: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706542800 next 556 of size 256
2019-10-30 00:37:49.617815: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706542900 next 21 of size 256
2019-10-30 00:37:49.618047: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706542A00 next 82 of size 256
2019-10-30 00:37:49.618275: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706542B00 next 22 of size 256
2019-10-30 00:37:49.618502: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706542C00 next 423 of size 256
2019-10-30 00:37:49.618733: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706542D00 next 247 of size 256
2019-10-30 00:37:49.618999: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706542E00 next 225 of size 1792
2019-10-30 00:37:49.619229: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706543500 next 560 of size 256
2019-10-30 00:37:49.619457: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706543600 next 564 of size 256
2019-10-30 00:37:49.619685: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706543700 next 566 of size 256
2019-10-30 00:37:49.619988: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706543800 next 567 of size 256
2019-10-30 00:37:49.620220: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706543900 next 569 of size 256
2019-10-30 00:37:49.620451: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706543A00 next 574 of size 256
2019-10-30 00:37:49.620681: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706543B00 next 571 of size 256
2019-10-30 00:37:49.620913: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706543C00 next 573 of size 512
2019-10-30 00:37:49.621142: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706543E00 next 572 of size 256
2019-10-30 00:37:49.621372: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706543F00 next 575 of size 256
2019-10-30 00:37:49.621601: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706544000 next 576 of size 256
2019-10-30 00:37:49.621852: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706544100 next 72 of size 256
2019-10-30 00:37:49.622096: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706544200 next 61 of size 256
2019-10-30 00:37:49.622322: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706544300 next 180 of size 256
2019-10-30 00:37:49.622552: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706544400 next 175 of size 256
2019-10-30 00:37:49.622781: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706544500 next 47 of size 256
2019-10-30 00:37:49.623046: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706544600 next 48 of size 256
2019-10-30 00:37:49.623273: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706544700 next 184 of size 256
2019-10-30 00:37:49.623503: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706544800 next 181 of size 256
2019-10-30 00:37:49.623734: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706544900 next 173 of size 256
2019-10-30 00:37:49.624014: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706544A00 next 57 of size 256
2019-10-30 00:37:49.624242: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706544B00 next 179 of size 256
2019-10-30 00:37:49.624470: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706544C00 next 174 of size 256
2019-10-30 00:37:49.624702: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706544D00 next 216 of size 256
2019-10-30 00:37:49.624966: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706544E00 next 31 of size 256
2019-10-30 00:37:49.625191: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706544F00 next 260 of size 256
2019-10-30 00:37:49.625417: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706545000 next 255 of size 256
2019-10-30 00:37:49.625642: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706545100 next 244 of size 256
2019-10-30 00:37:49.625945: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706545200 next 257 of size 256
2019-10-30 00:37:49.626422: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706545300 next 246 of size 256
2019-10-30 00:37:49.626607: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706545400 next 227 of size 256
2019-10-30 00:37:49.626792: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706545500 next 342 of size 256
2019-10-30 00:37:49.626981: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706545600 next 358 of size 256
2019-10-30 00:37:49.627165: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706545700 next 290 of size 256
2019-10-30 00:37:49.627347: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706545800 next 341 of size 256
2019-10-30 00:37:49.627530: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706545900 next 67 of size 256
2019-10-30 00:37:49.627711: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706545A00 next 87 of size 1792
2019-10-30 00:37:49.628228: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706546100 next 182 of size 35072
2019-10-30 00:37:49.628463: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070654EA00 next 33 of size 18432
2019-10-30 00:37:49.628695: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706553200 next 117 of size 22784
2019-10-30 00:37:49.628967: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706558B00 next 203 of size 18432
2019-10-30 00:37:49.629200: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070655D300 next 221 of size 19200
2019-10-30 00:37:49.629433: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706561E00 next 64 of size 1792
2019-10-30 00:37:49.629665: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706562500 next 138 of size 2304
2019-10-30 00:37:49.629937: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706562E00 next 233 of size 256
2019-10-30 00:37:49.630191: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706562F00 next 193 of size 256
2019-10-30 00:37:49.630422: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706563000 next 249 of size 256
2019-10-30 00:37:49.630652: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706563100 next 40 of size 256
2019-10-30 00:37:49.630938: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706563200 next 243 of size 256
2019-10-30 00:37:49.631171: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706563300 next 232 of size 256
2019-10-30 00:37:49.631402: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706563400 next 240 of size 256
2019-10-30 00:37:49.631630: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706563500 next 38 of size 256
2019-10-30 00:37:49.631916: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706563600 next 30 of size 256
2019-10-30 00:37:49.632146: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706563700 next 34 of size 256
2019-10-30 00:37:49.632372: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706563800 next 241 of size 256
2019-10-30 00:37:49.632600: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706563900 next 245 of size 256
2019-10-30 00:37:49.632853: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706563A00 next 234 of size 256
2019-10-30 00:37:49.633092: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706563B00 next 35 of size 256
2019-10-30 00:37:49.633343: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706563C00 next 239 of size 256
2019-10-30 00:37:49.633569: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706563D00 next 301 of size 512
2019-10-30 00:37:49.633820: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706563F00 next 412 of size 256
2019-10-30 00:37:49.634063: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706564000 next 231 of size 256
2019-10-30 00:37:49.634290: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706564100 next 215 of size 256
2019-10-30 00:37:49.634518: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706564200 next 39 of size 256
2019-10-30 00:37:49.634742: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706564300 next 37 of size 1792
2019-10-30 00:37:49.635021: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706564A00 next 28 of size 1792
2019-10-30 00:37:49.635309: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706565100 next 471 of size 256
2019-10-30 00:37:49.635544: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706565200 next 469 of size 256
2019-10-30 00:37:49.635777: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706565300 next 458 of size 256
2019-10-30 00:37:49.636044: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706565400 next 442 of size 256
2019-10-30 00:37:49.636279: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706565500 next 459 of size 256
2019-10-30 00:37:49.636510: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706565600 next 455 of size 256
2019-10-30 00:37:49.636742: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706565700 next 172 of size 256
2019-10-30 00:37:49.637009: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706565800 next 252 of size 256
2019-10-30 00:37:49.637240: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706565900 next 394 of size 256
2019-10-30 00:37:49.637473: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706565A00 next 253 of size 256
2019-10-30 00:37:49.637706: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706565B00 next 272 of size 256
2019-10-30 00:37:49.637973: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706565C00 next 274 of size 256
2019-10-30 00:37:49.638205: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706565D00 next 262 of size 24064
2019-10-30 00:37:49.638437: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070656BB00 next 261 of size 256
2019-10-30 00:37:49.638667: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070656BC00 next 264 of size 256
2019-10-30 00:37:49.638924: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070656BD00 next 254 of size 256
2019-10-30 00:37:49.639170: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070656BE00 next 248 of size 256
2019-10-30 00:37:49.639401: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070656BF00 next 266 of size 256
2019-10-30 00:37:49.639631: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070656C000 next 267 of size 256
2019-10-30 00:37:49.639915: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070656C100 next 269 of size 256
2019-10-30 00:37:49.640200: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070656C200 next 271 of size 256
2019-10-30 00:37:49.640436: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070656C300 next 263 of size 256
2019-10-30 00:37:49.640666: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070656C400 next 265 of size 1792
2019-10-30 00:37:49.640968: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070656CB00 next 156 of size 256
2019-10-30 00:37:49.641209: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070656CC00 next 166 of size 256
2019-10-30 00:37:49.641447: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070656CD00 next 219 of size 256
2019-10-30 00:37:49.641684: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070656CE00 next 304 of size 28160
2019-10-30 00:37:49.641941: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706573C00 next 258 of size 256
2019-10-30 00:37:49.642171: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706573D00 next 309 of size 256
2019-10-30 00:37:49.642402: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706573E00 next 313 of size 256
2019-10-30 00:37:49.642634: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706573F00 next 329 of size 256
2019-10-30 00:37:49.643038: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706574000 next 318 of size 256
2019-10-30 00:37:49.643289: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706574100 next 185 of size 256
2019-10-30 00:37:49.643517: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706574200 next 176 of size 256
2019-10-30 00:37:49.643744: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706574300 next 170 of size 256
2019-10-30 00:37:49.644011: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706574400 next 177 of size 256
2019-10-30 00:37:49.644238: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706574500 next 186 of size 256
2019-10-30 00:37:49.644465: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706574600 next 406 of size 256
2019-10-30 00:37:49.644691: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706574700 next 397 of size 256
2019-10-30 00:37:49.644968: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706574800 next 81 of size 256
2019-10-30 00:37:49.645219: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706574900 next 325 of size 256
2019-10-30 00:37:49.645452: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706574A00 next 314 of size 256
2019-10-30 00:37:49.645681: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706574B00 next 324 of size 256
2019-10-30 00:37:49.645979: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706574C00 next 307 of size 256
2019-10-30 00:37:49.646165: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706574D00 next 89 of size 256
2019-10-30 00:37:49.646345: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706574E00 next 320 of size 256
2019-10-30 00:37:49.646528: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706574F00 next 321 of size 256
2019-10-30 00:37:49.646711: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706575000 next 308 of size 256
2019-10-30 00:37:49.646898: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706575100 next 191 of size 256
2019-10-30 00:37:49.647082: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706575200 next 322 of size 256
2019-10-30 00:37:49.647265: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706575300 next 315 of size 256
2019-10-30 00:37:49.647449: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706575400 next 356 of size 256
2019-10-30 00:37:49.647634: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706575500 next 369 of size 256
2019-10-30 00:37:49.648187: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706575600 next 357 of size 256
2019-10-30 00:37:49.648421: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706575700 next 395 of size 256
2019-10-30 00:37:49.648651: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706575800 next 310 of size 256
2019-10-30 00:37:49.648917: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706575900 next 337 of size 256
2019-10-30 00:37:49.649149: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706575A00 next 327 of size 256
2019-10-30 00:37:49.649376: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706575B00 next 235 of size 256
2019-10-30 00:37:49.649605: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706575C00 next 236 of size 256
2019-10-30 00:37:49.649870: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706575D00 next 251 of size 256
2019-10-30 00:37:49.650099: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706575E00 next 125 of size 256
2019-10-30 00:37:49.650330: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706575F00 next 316 of size 256
2019-10-30 00:37:49.650559: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706576000 next 105 of size 1792
2019-10-30 00:37:49.650823: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706576700 next 270 of size 31232
2019-10-30 00:37:49.651054: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070657E100 next 268 of size 18432
2019-10-30 00:37:49.651286: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706582900 next 295 of size 18432
2019-10-30 00:37:49.651518: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706587100 next 306 of size 1792
2019-10-30 00:37:49.651767: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706587800 next 317 of size 35072
2019-10-30 00:37:49.652023: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706590100 next 311 of size 1792
2019-10-30 00:37:49.652253: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706590800 next 483 of size 19968
2019-10-30 00:37:49.652484: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706595600 next 482 of size 256
2019-10-30 00:37:49.652712: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706595700 next 485 of size 256
2019-10-30 00:37:49.652975: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706595800 next 484 of size 256
2019-10-30 00:37:49.653203: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706595900 next 480 of size 256
2019-10-30 00:37:49.653434: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706595A00 next 472 of size 256
2019-10-30 00:37:49.653663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706595B00 next 292 of size 256
2019-10-30 00:37:49.653926: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706595C00 next 346 of size 256
2019-10-30 00:37:49.654156: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706595D00 next 351 of size 256
2019-10-30 00:37:49.654385: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706595E00 next 353 of size 256
2019-10-30 00:37:49.654615: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706595F00 next 278 of size 256
2019-10-30 00:37:49.654895: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706596000 next 350 of size 256
2019-10-30 00:37:49.655124: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706596100 next 291 of size 256
2019-10-30 00:37:49.655353: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706596200 next 289 of size 256
2019-10-30 00:37:49.655583: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706596300 next 348 of size 256
2019-10-30 00:37:49.655845: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706596400 next 287 of size 256
2019-10-30 00:37:49.656091: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706596500 next 349 of size 256
2019-10-30 00:37:49.656325: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706596600 next 345 of size 256
2019-10-30 00:37:49.656555: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706596700 next 407 of size 256
2019-10-30 00:37:49.656790: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706596800 next 410 of size 256
2019-10-30 00:37:49.657019: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706596900 next 416 of size 256
2019-10-30 00:37:49.657250: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706596A00 next 398 of size 256
2019-10-30 00:37:49.657479: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706596B00 next 490 of size 256
2019-10-30 00:37:49.657709: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706596C00 next 414 of size 256
2019-10-30 00:37:49.657941: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706596D00 next 489 of size 256
2019-10-30 00:37:49.658171: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706596E00 next 402 of size 256
2019-10-30 00:37:49.658401: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706596F00 next 330 of size 256
2019-10-30 00:37:49.658631: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706597000 next 190 of size 256
2019-10-30 00:37:49.659000: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706597100 next 326 of size 256
2019-10-30 00:37:49.659290: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706597200 next 305 of size 256
2019-10-30 00:37:49.659476: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706597300 next 285 of size 256
2019-10-30 00:37:49.659660: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706597400 next 340 of size 1792
2019-10-30 00:37:49.660105: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000706597B00 next 352 of size 35072
2019-10-30 00:37:49.660342: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A0400 next 374 of size 23808
2019-10-30 00:37:49.660575: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A6100 next 376 of size 256
2019-10-30 00:37:49.660841: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A6200 next 373 of size 256
2019-10-30 00:37:49.661072: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A6300 next 365 of size 256
2019-10-30 00:37:49.661301: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A6400 next 360 of size 256
2019-10-30 00:37:49.661528: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A6500 next 377 of size 256
2019-10-30 00:37:49.661785: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A6600 next 378 of size 256
2019-10-30 00:37:49.662034: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A6700 next 380 of size 256
2019-10-30 00:37:49.662267: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A6800 next 382 of size 256
2019-10-30 00:37:49.662497: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A6900 next 383 of size 256
2019-10-30 00:37:49.662767: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A6A00 next 384 of size 256
2019-10-30 00:37:49.663030: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A6B00 next 385 of size 256
2019-10-30 00:37:49.663285: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A6C00 next 387 of size 256
2019-10-30 00:37:49.663521: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A6D00 next 389 of size 256
2019-10-30 00:37:49.663758: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A6E00 next 390 of size 256
2019-10-30 00:37:49.663992: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A6F00 next 372 of size 512
2019-10-30 00:37:49.664226: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A7100 next 375 of size 1792
2019-10-30 00:37:49.664464: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065A7800 next 479 of size 18432
2019-10-30 00:37:49.664705: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065AC000 next 141 of size 3328
2019-10-30 00:37:49.664981: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ACD00 next 282 of size 256
2019-10-30 00:37:49.665213: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ACE00 next 300 of size 256
2019-10-30 00:37:49.665443: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ACF00 next 151 of size 256
2019-10-30 00:37:49.665673: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065AD000 next 283 of size 256
2019-10-30 00:37:49.666005: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065AD100 next 418 of size 256
2019-10-30 00:37:49.666240: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065AD200 next 409 of size 256
2019-10-30 00:37:49.666469: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065AD300 next 218 of size 256
2019-10-30 00:37:49.666700: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065AD400 next 413 of size 256
2019-10-30 00:37:49.666988: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065AD500 next 408 of size 256
2019-10-30 00:37:49.667219: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065AD600 next 299 of size 256
2019-10-30 00:37:49.667451: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065AD700 next 411 of size 256
2019-10-30 00:37:49.667680: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065AD800 next 36 of size 256
2019-10-30 00:37:49.667950: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065AD900 next 302 of size 256
2019-10-30 00:37:49.668180: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ADA00 next 162 of size 256
2019-10-30 00:37:49.668413: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ADB00 next 399 of size 256
2019-10-30 00:37:49.668643: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ADC00 next 477 of size 256
2019-10-30 00:37:49.668877: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ADD00 next 391 of size 256
2019-10-30 00:37:49.669107: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ADE00 next 492 of size 256
2019-10-30 00:37:49.669336: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ADF00 next 401 of size 256
2019-10-30 00:37:49.669565: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065AE000 next 403 of size 256
2019-10-30 00:37:49.669832: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065AE100 next 405 of size 512
2019-10-30 00:37:49.670064: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065AE300 next 354 of size 256
2019-10-30 00:37:49.670294: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065AE400 next 392 of size 256
2019-10-30 00:37:49.670526: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065AE500 next 303 of size 1792
2019-10-30 00:37:49.670792: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065AEC00 next 415 of size 18432
2019-10-30 00:37:49.671052: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065B3400 next 381 of size 21760
2019-10-30 00:37:49.671290: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065B8900 next 379 of size 18432
2019-10-30 00:37:49.671525: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BD100 next 204 of size 256
2019-10-30 00:37:49.671757: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BD200 next 45 of size 256
2019-10-30 00:37:49.671985: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BD300 next 158 of size 256
2019-10-30 00:37:49.672215: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BD400 next 120 of size 256
2019-10-30 00:37:49.672444: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BD500 next 79 of size 256
2019-10-30 00:37:49.672672: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BD600 next 80 of size 256
2019-10-30 00:37:49.672939: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BD700 next 112 of size 256
2019-10-30 00:37:49.673170: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BD800 next 298 of size 512
2019-10-30 00:37:49.673399: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BDA00 next 297 of size 256
2019-10-30 00:37:49.673628: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BDB00 next 362 of size 256
2019-10-30 00:37:49.673910: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BDC00 next 296 of size 256
2019-10-30 00:37:49.674139: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BDD00 next 443 of size 256
2019-10-30 00:37:49.674371: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BDE00 next 454 of size 256
2019-10-30 00:37:49.674602: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BDF00 next 449 of size 256
2019-10-30 00:37:49.674908: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BE000 next 447 of size 256
2019-10-30 00:37:49.675276: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BE100 next 467 of size 256
2019-10-30 00:37:49.675510: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BE200 next 465 of size 256
2019-10-30 00:37:49.675747: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BE300 next 450 of size 256
2019-10-30 00:37:49.675975: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BE400 next 464 of size 256
2019-10-30 00:37:49.676203: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BE500 next 445 of size 256
2019-10-30 00:37:49.676433: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BE600 next 461 of size 256
2019-10-30 00:37:49.676659: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BE700 next 460 of size 256
2019-10-30 00:37:49.676926: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BE800 next 466 of size 256
2019-10-30 00:37:49.677153: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BE900 next 446 of size 256
2019-10-30 00:37:49.677380: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BEA00 next 462 of size 256
2019-10-30 00:37:49.677607: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BEB00 next 448 of size 256
2019-10-30 00:37:49.677882: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BEC00 next 452 of size 2560
2019-10-30 00:37:49.678118: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BF600 next 444 of size 1792
2019-10-30 00:37:49.678355: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065BFD00 next 456 of size 35072
2019-10-30 00:37:49.678594: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065C8600 next 486 of size 26368
2019-10-30 00:37:49.678834: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065CED00 next 400 of size 256
2019-10-30 00:37:49.679065: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065CEE00 next 493 of size 256
2019-10-30 00:37:49.679294: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065CEF00 next 494 of size 256
2019-10-30 00:37:49.679522: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065CF000 next 497 of size 256
2019-10-30 00:37:49.679790: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065CF100 next 487 of size 256
2019-10-30 00:37:49.680024: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065CF200 next 498 of size 256
2019-10-30 00:37:49.680260: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065CF300 next 499 of size 256
2019-10-30 00:37:49.680494: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065CF400 next 501 of size 256
2019-10-30 00:37:49.680762: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065CF500 next 503 of size 256
2019-10-30 00:37:49.680996: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065CF600 next 504 of size 256
2019-10-30 00:37:49.681229: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065CF700 next 505 of size 256
2019-10-30 00:37:49.681458: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065CF800 next 506 of size 256
2019-10-30 00:37:49.681686: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065CF900 next 512 of size 256
2019-10-30 00:37:49.681914: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065CFA00 next 508 of size 256
2019-10-30 00:37:49.682141: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065CFB00 next 496 of size 768
2019-10-30 00:37:49.682369: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065CFE00 next 495 of size 1792
2019-10-30 00:37:49.682600: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D0500 next 510 of size 256
2019-10-30 00:37:49.682828: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D0600 next 511 of size 256
2019-10-30 00:37:49.683056: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D0700 next 513 of size 256
2019-10-30 00:37:49.683283: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D0800 next 514 of size 256
2019-10-30 00:37:49.683512: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D0900 next 515 of size 1792
2019-10-30 00:37:49.683778: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D1000 next 516 of size 256
2019-10-30 00:37:49.684006: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D1100 next 517 of size 256
2019-10-30 00:37:49.684233: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D1200 next 518 of size 256
2019-10-30 00:37:49.684461: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D1300 next 520 of size 256
2019-10-30 00:37:49.684723: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D1400 next 521 of size 256
2019-10-30 00:37:49.684997: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D1500 next 522 of size 256
2019-10-30 00:37:49.685242: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D1600 next 524 of size 256
2019-10-30 00:37:49.685476: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D1700 next 525 of size 512
2019-10-30 00:37:49.685733: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D1900 next 526 of size 256
2019-10-30 00:37:49.685977: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D1A00 next 527 of size 1792
2019-10-30 00:37:49.686208: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D2100 next 528 of size 256
2019-10-30 00:37:49.686437: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D2200 next 529 of size 256
2019-10-30 00:37:49.686687: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D2300 next 530 of size 256
2019-10-30 00:37:49.686935: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D2400 next 531 of size 256
2019-10-30 00:37:49.687164: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D2500 next 532 of size 256
2019-10-30 00:37:49.687394: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D2600 next 533 of size 256
2019-10-30 00:37:49.687624: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D2700 next 534 of size 256
2019-10-30 00:37:49.687954: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D2800 next 535 of size 512
2019-10-30 00:37:49.688187: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D2A00 next 536 of size 256
2019-10-30 00:37:49.688418: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D2B00 next 537 of size 256
2019-10-30 00:37:49.688672: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D2C00 next 538 of size 256
2019-10-30 00:37:49.688976: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D2D00 next 539 of size 256
2019-10-30 00:37:49.689210: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D2E00 next 540 of size 256
2019-10-30 00:37:49.689441: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D2F00 next 541 of size 256
2019-10-30 00:37:49.689690: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D3000 next 562 of size 256
2019-10-30 00:37:49.689931: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D3100 next 550 of size 256
2019-10-30 00:37:49.690177: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D3200 next 551 of size 256
2019-10-30 00:37:49.690408: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D3300 next 557 of size 256
2019-10-30 00:37:49.690639: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D3400 next 396 of size 256
2019-10-30 00:37:49.690924: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D3500 next 545 of size 256
2019-10-30 00:37:49.691153: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D3600 next 488 of size 1792
2019-10-30 00:37:49.691385: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D3D00 next 491 of size 20480
2019-10-30 00:37:49.691619: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065D8D00 next 519 of size 18432
2019-10-30 00:37:49.691898: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065DD500 next 502 of size 18432
2019-10-30 00:37:49.692134: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065E1D00 next 500 of size 18432
2019-10-30 00:37:49.692369: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065E6500 next 544 of size 256
2019-10-30 00:37:49.692601: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065E6600 next 546 of size 256
2019-10-30 00:37:49.692892: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065E6700 next 542 of size 256
2019-10-30 00:37:49.693124: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065E6800 next 559 of size 256
2019-10-30 00:37:49.693354: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065E6900 next 553 of size 256
2019-10-30 00:37:49.693584: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065E6A00 next 563 of size 256
2019-10-30 00:37:49.693815: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065E6B00 next 558 of size 256
2019-10-30 00:37:49.694045: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065E6C00 next 565 of size 256
2019-10-30 00:37:49.694275: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065E6D00 next 554 of size 256
2019-10-30 00:37:49.694505: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065E6E00 next 543 of size 256
2019-10-30 00:37:49.694770: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065E6F00 next 548 of size 18432
2019-10-30 00:37:49.695005: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EB700 next 549 of size 512
2019-10-30 00:37:49.695236: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EB900 next 547 of size 1792
2019-10-30 00:37:49.695469: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EC000 next 577 of size 1792
2019-10-30 00:37:49.695804: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EC700 next 578 of size 256
2019-10-30 00:37:49.696036: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EC800 next 579 of size 256
2019-10-30 00:37:49.696265: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EC900 next 580 of size 256
2019-10-30 00:37:49.696493: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ECA00 next 582 of size 256
2019-10-30 00:37:49.696780: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ECB00 next 583 of size 256
2019-10-30 00:37:49.697020: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ECC00 next 584 of size 256
2019-10-30 00:37:49.697250: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ECD00 next 585 of size 256
2019-10-30 00:37:49.697480: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ECE00 next 586 of size 512
2019-10-30 00:37:49.697743: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ED000 next 587 of size 256
2019-10-30 00:37:49.697973: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ED100 next 588 of size 1792
2019-10-30 00:37:49.698204: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ED800 next 589 of size 256
2019-10-30 00:37:49.698431: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065ED900 next 590 of size 256
2019-10-30 00:37:49.698713: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EDA00 next 591 of size 256
2019-10-30 00:37:49.698943: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EDB00 next 592 of size 256
2019-10-30 00:37:49.699172: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EDC00 next 593 of size 256
2019-10-30 00:37:49.699399: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EDD00 next 594 of size 256
2019-10-30 00:37:49.699652: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EDE00 next 595 of size 256
2019-10-30 00:37:49.699896: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EDF00 next 596 of size 512
2019-10-30 00:37:49.700125: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EE100 next 597 of size 256
2019-10-30 00:37:49.700354: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EE200 next 598 of size 256
2019-10-30 00:37:49.700584: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EE300 next 599 of size 256
2019-10-30 00:37:49.700851: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EE400 next 600 of size 256
2019-10-30 00:37:49.701078: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EE500 next 601 of size 256
2019-10-30 00:37:49.701307: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EE600 next 602 of size 256
2019-10-30 00:37:49.701536: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EE700 next 603 of size 256
2019-10-30 00:37:49.701771: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EE800 next 604 of size 256
2019-10-30 00:37:49.702001: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EE900 next 605 of size 256
2019-10-30 00:37:49.702232: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EEA00 next 606 of size 256
2019-10-30 00:37:49.702462: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EEB00 next 607 of size 256
2019-10-30 00:37:49.702702: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EEC00 next 608 of size 256
2019-10-30 00:37:49.702975: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007065EED00 next 610 of size 256
2019-10-30 00:37:49.703265: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EEE00 next 613 of size 256
2019-10-30 00:37:49.703498: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007065EEF00 next 614 of size 256
2019-10-30 00:37:49.703728: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EF000 next 615 of size 256
2019-10-30 00:37:49.703956: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065EF100 next 616 of size 256
2019-10-30 00:37:49.704185: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007065EF200 next 431 of size 3840
2019-10-30 00:37:49.704416: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065F0100 next 73 of size 18432
2019-10-30 00:37:49.704696: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065F4900 next 581 of size 18432
2019-10-30 00:37:49.705029: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065F9100 next 555 of size 18432
2019-10-30 00:37:49.705268: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007065FD900 next 552 of size 18432
2019-10-30 00:37:49.705502: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000706602100 next 92 of size 12823040
2019-10-30 00:37:49.705740: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723CB00 next 94 of size 256
2019-10-30 00:37:49.705971: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723CC00 next 91 of size 256
2019-10-30 00:37:49.706197: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723CD00 next 85 of size 256
2019-10-30 00:37:49.706425: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723CE00 next 78 of size 256
2019-10-30 00:37:49.706720: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723CF00 next 95 of size 256
2019-10-30 00:37:49.706950: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723D000 next 96 of size 256
2019-10-30 00:37:49.707178: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723D100 next 98 of size 256
2019-10-30 00:37:49.707408: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723D200 next 100 of size 256
2019-10-30 00:37:49.707674: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723D300 next 101 of size 256
2019-10-30 00:37:49.707904: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723D400 next 102 of size 256
2019-10-30 00:37:49.708135: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723D500 next 103 of size 256
2019-10-30 00:37:49.708365: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723D600 next 187 of size 256
2019-10-30 00:37:49.708653: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723D700 next 199 of size 256
2019-10-30 00:37:49.708911: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723D800 next 196 of size 256
2019-10-30 00:37:49.709148: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723D900 next 131 of size 256
2019-10-30 00:37:49.709382: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723DA00 next 90 of size 256
2019-10-30 00:37:49.709631: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723DB00 next 93 of size 1792
2019-10-30 00:37:49.710000: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723E200 next 250 of size 1792
2019-10-30 00:37:49.710202: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723E900 next 223 of size 3328
2019-10-30 00:37:49.710387: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723F600 next 201 of size 256
2019-10-30 00:37:49.710571: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723F700 next 229 of size 256
2019-10-30 00:37:49.710973: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723F800 next 202 of size 256
2019-10-30 00:37:49.711205: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723F900 next 212 of size 256
2019-10-30 00:37:49.711435: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723FA00 next 107 of size 256
2019-10-30 00:37:49.711666: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723FB00 next 116 of size 256
2019-10-30 00:37:49.711895: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723FC00 next 108 of size 256
2019-10-30 00:37:49.712126: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723FD00 next 214 of size 256
2019-10-30 00:37:49.712354: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723FE00 next 210 of size 256
2019-10-30 00:37:49.712608: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070723FF00 next 111 of size 256
2019-10-30 00:37:49.712854: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707240000 next 110 of size 256
2019-10-30 00:37:49.713084: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707240100 next 205 of size 256
2019-10-30 00:37:49.713314: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707240200 next 213 of size 256
2019-10-30 00:37:49.713545: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707240300 next 206 of size 256
2019-10-30 00:37:49.713809: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707240400 next 200 of size 256
2019-10-30 00:37:49.714039: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707240500 next 209 of size 256
2019-10-30 00:37:49.714268: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707240600 next 113 of size 256
2019-10-30 00:37:49.714499: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707240700 next 208 of size 3328
2019-10-30 00:37:49.714767: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707241400 next 211 of size 1792
2019-10-30 00:37:49.714999: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707241B00 next 338 of size 256
2019-10-30 00:37:49.715230: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707241C00 next 336 of size 256
2019-10-30 00:37:49.715457: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707241D00 next 339 of size 256
2019-10-30 00:37:49.715723: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707241E00 next 335 of size 256
2019-10-30 00:37:49.715953: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707241F00 next 323 of size 256
2019-10-30 00:37:49.716183: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707242000 next 238 of size 256
2019-10-30 00:37:49.716411: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707242100 next 119 of size 256
2019-10-30 00:37:49.716643: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707242200 next 135 of size 256
2019-10-30 00:37:49.716870: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707242300 next 137 of size 256
2019-10-30 00:37:49.717101: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707242400 next 256 of size 256
2019-10-30 00:37:49.717329: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707242500 next 118 of size 256
2019-10-30 00:37:49.717558: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707242600 next 242 of size 256
2019-10-30 00:37:49.717840: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707242700 next 224 of size 256
2019-10-30 00:37:49.718082: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707242800 next 77 of size 256
2019-10-30 00:37:49.718314: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707242900 next 129 of size 256
2019-10-30 00:37:49.718546: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707242A00 next 99 of size 18432
2019-10-30 00:37:49.718817: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707247200 next 97 of size 18432
2019-10-30 00:37:49.719051: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070724BA00 next 132 of size 24320
2019-10-30 00:37:49.719286: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707251900 next 146 of size 256
2019-10-30 00:37:49.719518: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707251A00 next 142 of size 256
2019-10-30 00:37:49.719849: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707251B00 next 144 of size 256
2019-10-30 00:37:49.720150: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707251C00 next 148 of size 256
2019-10-30 00:37:49.720389: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707251D00 next 150 of size 256
2019-10-30 00:37:49.720654: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707251E00 next 139 of size 256
2019-10-30 00:37:49.720896: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707251F00 next 136 of size 256
2019-10-30 00:37:49.721141: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707252000 next 133 of size 256
2019-10-30 00:37:49.721381: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707252100 next 147 of size 256
2019-10-30 00:37:49.721620: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707252200 next 154 of size 256
2019-10-30 00:37:49.721862: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707252300 next 143 of size 256
2019-10-30 00:37:49.722102: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707252400 next 126 of size 256
2019-10-30 00:37:49.722341: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707252500 next 124 of size 256
2019-10-30 00:37:49.722581: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707252600 next 122 of size 256
2019-10-30 00:37:49.722821: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707252700 next 121 of size 256
2019-10-30 00:37:49.723060: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707252800 next 149 of size 256
2019-10-30 00:37:49.723300: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707252900 next 153 of size 2048
2019-10-30 00:37:49.723539: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707253100 next 155 of size 1792
2019-10-30 00:37:49.723781: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707253800 next 157 of size 35072
2019-10-30 00:37:49.724025: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070725C100 next 145 of size 13644288
2019-10-30 00:37:49.724272: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000707F5F300 next 165 of size 27180288
2019-10-30 00:37:49.724521: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070994B000 next 106 of size 13644288
2019-10-30 00:37:49.724770: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070A64E200 next 104 of size 13644288
2019-10-30 00:37:49.725017: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070B351400 next 134 of size 13644288
2019-10-30 00:37:49.725267: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 000000070C054600 next 160 of size 13644288
2019-10-30 00:37:49.725515: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070CD57800 next 183 of size 13644288
2019-10-30 00:37:49.725788: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070DA5AA00 next 188 of size 13644288
2019-10-30 00:37:49.726036: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000070E75DC00 next 83 of size 13644288
2019-10-30 00:37:49.726281: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 000000070F460E00 next 217 of size 13644288
2019-10-30 00:37:49.726527: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000710164000 next 226 of size 13644288
2019-10-30 00:37:49.726777: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000710E67200 next 152 of size 27288576
2019-10-30 00:37:49.727024: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071286D600 next 279 of size 13644288
2019-10-30 00:37:49.727272: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000713570800 next 275 of size 13644288
2019-10-30 00:37:49.727519: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714273A00 next 273 of size 13644288
2019-10-30 00:37:49.727765: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000714F76C00 next 328 of size 13644288
2019-10-30 00:37:49.728010: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000715C79E00 next 312 of size 13644288
2019-10-30 00:37:49.728259: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000071697D000 next 288 of size 13644288
2019-10-30 00:37:49.728505: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000717680200 next 388 of size 150087168
2019-10-30 00:37:49.728773: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007205A2800 next 386 of size 54577152
2019-10-30 00:37:49.729038: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007239AF000 next 363 of size 54577152
2019-10-30 00:37:49.729279: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000726DBB800 next 404 of size 109154304
2019-10-30 00:37:49.729517: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000072D5D4800 next 178 of size 109154304
2019-10-30 00:37:49.729758: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000733DED800 next 52 of size 54577152
2019-10-30 00:37:49.729994: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007371FA000 next 457 of size 54577152
2019-10-30 00:37:49.730232: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000073A606800 next 259 of size 54577152
2019-10-30 00:37:49.730470: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000073DA13000 next 417 of size 54577152
2019-10-30 00:37:49.730708: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000740E1F800 next 419 of size 163731456
2019-10-30 00:37:49.730947: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000074AA45000 next 523 of size 109154304
2019-10-30 00:37:49.731187: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000075125E000 next 509 of size 109154304
2019-10-30 00:37:49.731427: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000757A77000 next 507 of size 109154304
2019-10-30 00:37:49.731714: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000075E290000 next 561 of size 109154304
2019-10-30 00:37:49.731957: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000764AA9000 next 393 of size 109154304
2019-10-30 00:37:49.732198: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000076B2C2000 next 476 of size 109154304
2019-10-30 00:37:49.732437: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000771ADB000 next 332 of size 109154304
2019-10-30 00:37:49.732711: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007782F4000 next 425 of size 109154304
2019-10-30 00:37:49.732956: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000077EB0D000 next 86 of size 109154304
2019-10-30 00:37:49.733195: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000785326000 next 570 of size 109154304
2019-10-30 00:37:49.733434: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000078BB3F000 next 568 of size 109154304
2019-10-30 00:37:49.733706: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000792358000 next 609 of size 82301184
2019-10-30 00:37:49.733940: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007971D5100 next 611 of size 219469824
2019-10-30 00:37:49.734175: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A4322900 next 612 of size 219469824
2019-10-30 00:37:49.734415: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B1470100 next 617 of size 54770688
2019-10-30 00:37:49.734707: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B48ABD00 next 18446744073709551615 of size 157801472
2019-10-30 00:37:49.734980: I tensorflow/core/common_runtime/bfc_allocator.cc:914]      Summary of in-use Chunks by size: 
2019-10-30 00:37:49.735203: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 471 Chunks of size 256 totalling 117.8KiB
2019-10-30 00:37:49.735423: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 14 Chunks of size 512 totalling 7.0KiB
2019-10-30 00:37:49.735674: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 768 totalling 768B
2019-10-30 00:37:49.735886: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1280 totalling 1.3KiB
2019-10-30 00:37:49.736099: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 31 Chunks of size 1792 totalling 54.3KiB
2019-10-30 00:37:49.736313: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 2048 totalling 4.0KiB
2019-10-30 00:37:49.736528: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 2304 totalling 4.5KiB
2019-10-30 00:37:49.736739: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2560 totalling 2.5KiB
2019-10-30 00:37:49.736954: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 3 Chunks of size 3328 totalling 9.8KiB
2019-10-30 00:37:49.737172: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 21 Chunks of size 18432 totalling 378.0KiB
2019-10-30 00:37:49.737394: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 19200 totalling 18.8KiB
2019-10-30 00:37:49.737647: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 19968 totalling 19.5KiB
2019-10-30 00:37:49.737864: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 20480 totalling 20.0KiB
2019-10-30 00:37:49.738080: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 21760 totalling 21.3KiB
2019-10-30 00:37:49.738299: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 22784 totalling 22.3KiB
2019-10-30 00:37:49.738533: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 23808 totalling 23.3KiB
2019-10-30 00:37:49.738774: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 24064 totalling 23.5KiB
2019-10-30 00:37:49.738991: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 24320 totalling 23.8KiB
2019-10-30 00:37:49.739207: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 26368 totalling 25.8KiB
2019-10-30 00:37:49.739424: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 27392 totalling 26.8KiB
2019-10-30 00:37:49.739688: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 28160 totalling 27.5KiB
2019-10-30 00:37:49.739920: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 31232 totalling 30.5KiB
2019-10-30 00:37:49.740145: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 6 Chunks of size 35072 totalling 205.5KiB
2019-10-30 00:37:49.740369: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 17 Chunks of size 13644288 totalling 221.21MiB
2019-10-30 00:37:49.740600: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 27180288 totalling 25.92MiB
2019-10-30 00:37:49.740822: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 6 Chunks of size 54577152 totalling 312.29MiB
2019-10-30 00:37:49.741049: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 54770688 totalling 52.23MiB
2019-10-30 00:37:49.741270: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 82301184 totalling 78.49MiB
2019-10-30 00:37:49.741491: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 13 Chunks of size 109154304 totalling 1.32GiB
2019-10-30 00:37:49.742015: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 150087168 totalling 143.13MiB
2019-10-30 00:37:49.742248: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 157801472 totalling 150.49MiB
2019-10-30 00:37:49.742477: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 163731456 totalling 156.15MiB
2019-10-30 00:37:49.742759: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 219469824 totalling 418.61MiB
2019-10-30 00:37:49.743011: I tensorflow/core/common_runtime/bfc_allocator.cc:921] Sum Total of in-use chunks: 2.84GiB
2019-10-30 00:37:49.743232: I tensorflow/core/common_runtime/bfc_allocator.cc:923] total_region_allocated_bytes_: 3149043968 memory_limit_: 3149044121 available bytes: 153 curr_region_allocation_bytes_: 6298088448
2019-10-30 00:37:49.743623: I tensorflow/core/common_runtime/bfc_allocator.cc:929] Stats: 
Limit:                  3149044121
InUse:                  3054327296
MaxInUse:               3054397696
NumAllocs:                  273455
MaxAllocSize:           1191644416

2019-10-30 00:37:49.744149: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ***************x*********************x*************************************************************x
2019-10-30 00:37:49.744865: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at fused_batch_norm_op.cc:1108 : Resource exhausted: OOM when allocating tensor with shape[8,32,283,378] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
2019-10-30 00:37:49.745534: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Resource exhausted: OOM when allocating tensor with shape[8,32,283,378] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node model_14/batch_normalization_29/FusedBatchNormV3}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

2019-10-30 00:37:49.831368: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: 
WARNING:tensorflow:Can save best model only with val_loss available, skipping.
2019-10-30 00:37:49.833050: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 0 kernel records, 0 memcpy records.
Traceback (most recent call last):
  File "D:/OneDrive/My Research/Dr_Mosaad/Data 2/program/cnn_regression.py", line 92, in <module>
    , callbacks=clbs)
  File "C:\Users\DELL\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training.py", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File "C:\Users\DELL\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py", line 324, in fit
    total_epochs=epochs)
  File "C:\Users\DELL\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py", line 123, in run_one_epoch
    batch_outs = execution_function(iterator)
  File "C:\Users\DELL\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py", line 86, in execution_function
    distributed_function(input_fn))
  File "C:\Users\DELL\Anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py", line 457, in __call__
    result = self._call(*args, **kwds)
  File "C:\Users\DELL\Anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py", line 520, in _call
    return self._stateless_fn(*args, **kwds)
  File "C:\Users\DELL\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py", line 1823, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File "C:\Users\DELL\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py", line 1141, in _filtered_call
    self.captured_inputs)
  File "C:\Users\DELL\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File "C:\Users\DELL\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py", line 511, in call
    ctx=ctx)
  File "C:\Users\DELL\Anaconda3\lib\site-packages\tensorflow_core\python\eager\execute.py", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File "<string>", line 3, in raise_from
tensorflow.python.framework.errors_impl.ResourceExhaustedError:  OOM when allocating tensor with shape[8,32,283,378] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[node model_14/batch_normalization_29/FusedBatchNormV3 (defined at C:\Users\DELL\Anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py:1751) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
 [Op:__inference_distributed_function_167335]

Function call stack:
distributed_function


Process finished with exit code 1
